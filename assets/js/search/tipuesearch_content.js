var tipuesearch = {'pages': [
{
    'title': "AIP Purpose and Guidelines",
    'text': "AIP Purpose and Guidelines As the corpus of Google APIs has grown and the API Governance team has grown to meet the demand of supporting them, it is increasingly necessary to have a corpus of documentation for API producers, reviewers, and other interested parties to reference. The API style guide and introductory One Platform documentation are intentionally terse and high-level. The AIP collection provides a way to provide consistent documentation for API design guidance. What is an AIP? AIP stands for API Improvement Proposal, which is a design document providing high-level, concise documentation for API development. They are to serve as the source of truth for API-related documentation at Google and the means by which API teams discuss and come to consensus on API guidance. AIPs are maintained as Markdown files in the AIP GitHub repository. Types of AIPs There are several different types of AIPs, described below. The list of AIP types may evolve over time as necessary. Guidance These AIPs describe guidance on API design. These are provided as instruction for API producers to help write simple, intuitive, and consistent APIs, and are used by API reviewers as a basis for review comments. Process These AIPs describe a process surrounding API design. They often affect the AIP process itself and are used to enhance the way in which AIPs are handled. Stakeholders As with any process there are many different stakeholders when it comes to reviewing and working with AIPs. Below is a summary of the escalation path starting with the API producer. digraph d_front_back { rankdir=BT; ranksep=0.3; node [ style=\"filled,solid\" shape=box fontname=\"Roboto\" ]; producer [ label=\"API Producer\" ]; editors [ label=\"AIP Editors\" ]; tl_infra [ label=\"Infrastructure TL\" ]; tl_design [ label=\"Design TL\" ]; tl [ label=\"TL\" ]; producer -\u003e editors; editors -\u003e tl_infra -\u003e tl; editors -\u003e tl_design -\u003e tl; } Technical leads The current TL (technical lead) for APIs is Eric Brewer; he has delegated some responsibilities for API Infrastructure to Hong Zhang (@wora) and API Design to JJ Geewax (@jgeewax). As noted in the diagram above, the TL is the final decision-maker on the AIP process and the final point of escalation if necessary. Editors The editors are the set of people who make decisions on AIPs. The general goal is that the AIP process is collaborative and that we largely work on the basis of consensus. However, a limited number of designated approvers is necessary, and these Googlers will be approvers for each AIP in the general scope. The list of AIP editors is currently: Hong Zhang (@wora) JJ Geewax (@jgeewax) Jon Skeet (@jskeet) Luke Sneeringer (@lukesneeringer) The editors are also responsible for the administrative and editorial aspects of shepherding AIPs and managing the AIP pipeline and workflow. They approve PRs to AIPs, assign proposal numbers, manage the agenda, set AIP states, and so forth. They also ensure that AIPs are readable (proper spelling, grammar, sentence structure, markup, etc.). AIP editorship is by invitation of the current editors. Domain-specific AIPs Some AIPs may be specific to a particular domain (for example, only to APIs within a certain PA, or even a certain team). In this situation, the group will be given a particular block of AIPs to use in accordance with AIP-2, and the applicable AIPs will clearly indicate their scope. States At any given time, AIPs may exist in a variety of states as they work their way through the process. The following is a summary of each state. Draft The initial state for an AIP is the \"Draft\" state. This means that the AIP is being discussed and iterated upon, primarily by the original authors. While the editors may get involved at this stage, it is not necessary. Note: If significant, high-level iteration is required, it is recommended to draft AIPs in a Google doc instead of a PR. AIPs that are migrated into the AIP system from Google Docs may skip the draft state and go directly to reviewing provided there is sufficient approval. Reviewing Once discussion on an AIP has generally concluded, but before it is formally accepted it moves to the \"Reviewing\" state. This means that the authors have reached a general consensus on the proposal and the editors are now involved. At this stage the editors may request changes or suggest alternatives to the proposal before moving forward. Note: As a formal matter, one AIP approver (other than the author) must provide formal signoff to advance an AIP to the reviewing state. Additionally, there must not be formal objections (\"changes requested\" on the GitHub PR) from other approvers. Approved Once an approved AIP has been agreed upon, it enters \"approved\" state and is considered \"best current practice\". Note: As a formal matter, two AIP approvers (other than the author) must provide formal signoff to advance an AIP to the approved state. Additionally, there must not be formal objections (\"changes requested\" on the GitHub PR) from other approvers. Withdrawn If an AIP is withdrawn by the author or champion, it enters \"withdrawn\" state. AIPs that are withdrawn may be taken up by another champion. Rejected If an AIP is rejected by the AIP editors, it enters \"rejected\" state. AIPs that are rejected remain, and provide documentation and reference to inform future discussions. Deferred If an AIP has not been acted upon for a significant period of time, the editors may mark it as \"deferred\". Replaced If an AIP has been replaced by another AIP, it enters \"replaced\" state. AIP editors are responsible to provide a notice explaining the replacement and rationale (the replacement AIP should also clearly explain the rationale). In general, API producers should rely primarily on AIPs in the \"approved\" state. Workflow The following workflow describes the process for proposing an AIP, and moving an AIP from proposal to implementation to final acceptance. Overview digraph d_front_back { rankdir=LR; node [ style=\"filled,solid\" shape=box fontname=\"Roboto\" ]; draft [ label=\"Draft\" fillcolor=\"orange\" ]; reviewing [ label=\"Reviewing\" fillcolor=\"lightskyblue\" ]; approved [ label=\"Approved\" fillcolor=\"palegreen\" ]; withdrawn [ label=\"Withdrawn\" fillcolor=\"mistyrose\" ]; rejected [ label=\"Rejected\" fillcolor=\"mistyrose\" ]; deferred [ label=\"Deferred\" fillcolor=\"lightsteelblue\" ]; replaced [ label=\"Replaced\" fillcolor=\"lightsteelblue\" ]; draft -\u003e reviewing; draft -\u003e withdrawn [ style=dashed, color=mistyrose3 ]; draft -\u003e rejected [ style=dashed, color=mistyrose3 ]; reviewing -\u003e approved; reviewing -\u003e withdrawn [ style=dashed, color=mistyrose3 ]; reviewing -\u003e rejected [ style=dashed, color=mistyrose3 ]; draft -\u003e deferred [ style=dashed, color=lightsteelblue3 ]; reviewing -\u003e deferred [ style=dashed, color=lightsteelblue3 ]; approved -\u003e replaced [ style=dashed, color=lightsteelblue3 ]; reviewing -\u003e replaced [ style=dashed, color=lightsteelblue3 ]; } Proposing an AIP In order to propose an AIP, first open an issue to circulate the fundamental idea for initial feedback. It should generally be possible to describe the idea in a couple of pages. Once ready, create a PR with a new file in the AIP directory using a file titled aip/new.md. Ensure that the PR is editable by maintainers. In most circumstances, the editors will assign the proposal an AIP number and submit the PR with the AIP in the \"Reviewing\" state. The editors may reject an AIP outright if they have an obvious reason to do so (e.g. the proposal was already discussed and rejected in another AIP or is fundamentally unsound), in which case the PR is not merged. Discussing an AIP Once the PR is merged, the AIP author is responsible for championing the AIP on a follow-up approval pull request. This means that the author is responsible for pushing towards consensus around the proposal. This may involve a discussion at the regularly scheduled meetings for the API Governance team. The AIP author may modify the AIP over the course of discussion by submitting follow-up commits to the PR. Accepting an AIP The editors will work together to ensure that qualified proposals do not linger in review. To gain final approval, an AIP must be approved by, at minimum, the TL with responsibility over the domain covered by the AIP (either design or infrastructure) and at least one other editor, with no editors actively requesting changes. Note: If an AIP editor is the primary author of an AIP, then at least two other editors must approve it. Once the AIP is approved, the editors will update the state of the AIP to reflect this and submit the PR. Withdrawing or Rejecting an AIP The author of an AIP may decide, after further consideration, that an AIP should not advance. If so, the author may withdraw the AIP by updating the PR adding a notice of withdrawal with an explanation of the rationale. Additionally, the author may be unable to get consensus among the group and the AIP editors may elect to reject the AIP. In this situation, the AIP editors shall amend the PR adding a notice of rejection with an explanation of the rationale. In both cases, the AIP editors update the state accordingly and submit the PR. Replacing an AIP In rare cases, it may be necessary to replace an AIP with another one. This is not general practice: minor edits to approved AIPs are acceptable, and will be the common way to tweak guidance. However, if new guidance fundamentally alters the old guidance in some way, then the AIP editors shall create a new AIP that, once approved, will replace the old one. The old one then enters \"Replaced\" state, and will link to the new, current AIP. Changelog 2019-07-30: Further clarified AIP quorum requirements. 2019-05-12: Collapsed AIP approvers and editors into a single position, relaxed approval rules from full quorum. 2019-05-04: Updated the AIP to refer to GitHub processes, rather than internal processes.",
    'tags': '',
    'url': '/1',
  },
{
    'title': "AIP Numbering",
    'text': "AIP Numbering The AIP system provides a mechanism to index and have a single source of truth for API Improvement Proposals, as well as iterate on them collaboratively and transparently. This document describes the AIP numbering system. Assigning AIP Numbers The AIP editors (see AIP-1) are responsible for assigning a number to each AIP when it is accepted as a draft for review. Importantly, all AIPs have numbers, not just approved ones. The AIP Index clearly delineates which AIPs are approved and binding and which are under discussion. The editors may decide to reserve a specific block of numbers for groups of AIPs that are related in some way (for example, that are only scoped to a specific subset of APIs). Beyond this, AIP numbers are assigned arbitrarily. In general, the editors will take the next AIP number off of the stack to assign to a draft AIP, but occasionally may use a special/joke number if useful for mnemonic or other reasons. AIP Blocks Currently recognized blocks of AIP numbers are: Generally Applicable 1-99: Reserved for meta-AIPs (generally process-related). 100-999: General API design guidance Google Product Areas 2700-2799: Apps (GSuite) 2500-2599: Cloud 3000-3099: Actions on Google 3200-3299: Firebase 4100-4199: Auth libraries 4200-4299: Client libraries 4600-4699: Geo To request a block for a specific team that is publishing API guidance or documentation germane to that specific team, reach out to api-editors@. Changelog 2019-10-03: The 3000-3099 block was assigned to Actions on Google. 2019-01-26: The general API design guidance block was expanded to include 100-199. 2018-10-24: The 4600-4699 block was assigned to Google Geo. 2018-10-02: The 2500-2599 block was assigned to Google Cloud Platform. 2018-10-02: The 2700-2799 block was assigned to Google Apps.",
    'tags': '',
    'url': '/2',
  },
{
    'title': "AIP Style guide",
    'text': "AIP Style guide AIP stands for API Improvement Proposal, which is a design document providing high-level, concise documentation for API development. The goal is for these documents to serve as the source of truth for API-related documentation at Google and the way API teams discuss and come to consensus on API guidance. AIPs are most useful when they are clear and concise, and cover a single topic or inquiry well. In the same way that AIPs describe consistent patterns and style for use in APIs, they also follow consistent patterns and style. Guidance AIPs must cover a single, discrete topic, and should fundamentally answer the question, \"What do I do?\" with actionable guidance. AIPs may also cover what not to do, but should not cover only anti-patterns. While the length of AIPs will necessarily vary based on the complexity of the question, most AIPs should be able to cover their content in roughly two printed pages. File structure AIPs must be written in Markdown, and must be named using their four-digit number (example: 0008.md). AIPs that serve a specific scope must be in the subdirectory for that scope. AIPs must have appropriate front matter. --- aip: id: 8 state: reviewing created: 2019-05-28 permalink: /8 redirect_from: - /08 - /008 - /0008 --- Front matter for AIPs must include: The aip key: id: Required. The ID for the given AIP, as an integer. state: Required. The current state of the AIP, in all lower-case. The valid states are listed in AIP-1, and common states are draft, reviewing, and approved. created: Required. The ISO-8601 date (yyyy-mm-dd) when the AIP was originally drafted, with no quotes. updated: The ISO-8601 date (yyyy-mm-dd) when the AIP was last revised. scope: The scope for the AIP. This must match the directory name for that scope. Required for AIPs with IDs \u003e= 1000, prohibited otherwise. The permalink key (required): This must be set to /{aip.scope}/{aip.id}. If there is no scope, use /{aip.id} instead. The redirect_from key: This should include a list of any /{aip.id} permutations that a reader would be likely to enter, including: /{aip.id} (for AIPs where the permalink includes the scope) AIP IDs with zero-padding, for each level of zero-padding up to four digits (for example: /08, /008, /0008). Document structure AIPs must begin with a top-level heading with the AIP\u0027s title (# Title). The title should be a noun (not an imperative). For example, \"Bad API precedents\" not \"Avoid breaking API precedent\". AIPs should then begin with an introduction (with no additional heading), followed by a ## Guidance heading. If necessary, the AIP may include any of the following after the guidance, in the following order: \"Further reading\" is a bulleted list of links to other AIPs that are useful to fully understand the current AIP. \"Appendices\" covering further explanation in the same AIP. These are relatively rare but are important in cases where an AIP requires a lot of justification for the decision. Often this is primarily an explanation of alternatives considered to help explain the guidance. \"Changelog\" is a bulleted list of changes made to the AIP since the first writing. The guidance section may include subsections that elaborate further on details. Subsections will automatically create an entry in the table of contents, and an anchor for citations. Below is an example AIP shell that uses each major section: # AIP title The introductory text explains the background and reason why the AIP exists. It lays out the basic question, but does not tell the reader what to do. ## Guidance The \"guidance\" section helps the reader know what to do. A common format for the guidance section is a high-level imperative, followed by an example, followed by a bulleted list explaining the example. ### Subsection Individual subsections can be cited individually, and further elaborate details. ## Further reading A bulleted list of (usually) other AIPs, in the following format: - [AIP-1](/1): AIP purpose and guidelines ## Appendix An appendix is appropriate when a non-trivial side discussion is necessary. It may explain historical reasons for the guidance, alternatives considered, or other issues potentially of interest to the reader. ## Changelog A bulleted list of changes in reverse chronological order, using the following format: - **2020-02-18**: Specified ordering. - **2019-07-01**: Added a subsection clarifying XYZ. AIPs should attempt to follow this overall format if possible, but AIPs may deviate from it if necessary (in particular, if the AIP would be more difficult to understand, even for a reader already accustomed to reading AIPs in the usual format). Note: Except for the title, AIPs must only use the second heading level (##) and above. AIPs should only use the second and third heading levels (##, ###). Requirement keywords AIPs should use the following requirement level keywords: \"MUST\", \"MUST NOT\", \"SHOULD\", \"SHOULD NOT\", and \"MAY\", which are to be interpreted as described in RFC 2119. When using these terms in AIPs, they must be lower-case and bold. These terms should not be used in other ways. Important: If an appendix is used, it exists to provide background and a more complete understanding, but must not contain guidance (and RFC-2119 terms must not be used). Code examples API design examples in AIPs should use protocol buffers. Examples should cover only enough syntax to explain the concept. When using RPCs in examples, a google.api.http annotation should be included. Referencing AIPs When AIPs reference other AIPs, the prosaic text must use the format AIP-XXXX without zero-padding (e.g., [AIP-8](/8), not AIP-0008), and must link to the relevant AIP. AIP links may point to a particular section of the AIP if appropriate. Important: AIP links must use the relative path to the file in the repository (such as /8 for core AIPs, or /8 for AIPs in a subdirectory); this ensures that the link works both on the AIP site, when viewing the Markdown file on GitHub, using the local development server, or a branch. Changelog 2020-02-18: Specified reverse chronological ordering for changelog items. 2019-08-23: Added guidance for internal AIP links.",
    'tags': '',
    'url': '/8',
  },
{
    'title': "Glossary",
    'text': "Glossary In the name of brevity, this AIP defines some common terminology here rather than in each AIP individually. Guidance The following terminology should be used consistently throughout AIPs. API : Application Programming Interface. This can be a local interface (such as a client library) or a Network API (defined below). Network API : An API that operates across a network of computers. Network APIs communicate using network protocols including HTTP, and are frequently produced by organizations separate from those that consume them. Google API : A Network API exposed by a Google service. Most of these are hosted on the googleapis.com domain. It does not include other types of APIs, such as client libraries and SDKs. API Definition : The definition of an API, usually defined in a Protocol Buffer service. An API Definition can be implemented by any number of API Services. API Version : The version of an API or a group of APIs if they are defined together. An API Version is often represented by a string, such as \"v1\", and presents in API requests and Protocol Buffers package names. API Method : An individual operation within an API. It is typically represented in Protocol Buffers by an rpc definition, and is mapped to a function in the API in most programming languages. API Request : A single invocation of an API Method. It is often used as the unit for billing, logging, monitoring, and rate limiting. API Consumer : The entity that consumes an API Service. For Google APIs, it typically is a Google project that owns the client application or the server resource. API Producer : The entity that produces an API Service. For Google APIs, it typically is a Google team responsible for the API Service. API Backend : A set of servers and related infrastructure that implements the business logic for an API Service. An individual API backend server is often called an API server. API Frontend : A set of servers plus related infrastructure that provides common functionality across API Services, such as load balancing and authentication. An individual API frontend server is often called an API proxy. Note: the API frontend and the API backend may run next to each other or far away from each other. In some cases, they can be compiled into a single application binary and run inside a single process. API Service : A deployed implementation of one or more APIs, exposed on one or more network addresses, such as the Cloud Pub/Sub API. API Service Name : Refers to the logical identifier of an API Service. Google APIs use RFC 1035 DNS compatible names as their API Service Names, such as pubsub.googleapis.com. API Service Endpoint : Refers to a network address that an API Service uses to handle incoming API Requests. One API Service may have multiple API Service Endpoints, such as https://pubsub.googleapis.com and https://content-pubsub.googleapis.com. API Product : An API Service and its related components, such as Terms of Service, documentation, client libraries, and service support, are collectively presented to customers as a API Product. For example, Google Calendar API. Note: people sometimes refer to an API Product simply as an API. API Service Definition : The combination of API Definitions (.proto files) and API Service configurations (.yaml files) used to define an API Service. The schema for Google API Service Definition is google.api.Service.",
    'tags': '',
    'url': '/9',
  },
{
    'title': "API Design Review FAQ",
    'text': "API Design Review FAQ API design review exists to ensure a simple, intuitive, and consistent API experience throughout our API corpus. Do I need API design approval? TL;DR: You usually need API design approval if you are launching an API that users can code against (either now or in the future) at the beta or GA quality level. API design review is fundamentally about ensuring we provide a simple and consistent experience for our users, and therefore is only expected for APIs that users code directly against. The following flowchart illustrates whether or not your API needs to go through the design review process: digraph { node [ style=\"filled,solid\" shape=box fontname=\"Roboto\" ]; graph [ splines=ortho, nodesep=0.2 ]; audience [ label=\"Who should code directly\\nagainst this API?\" shape=diamond fillcolor=bisque ]; subgraph audience_responses { rank = \"same\"; node [ shape=oval fillcolor=orange ]; googlers [ label=\"Googlers\\nOnly\" fillcolor=lightcoral ]; public [ label=\"Anyone\" fillcolor=limegreen ]; partners [ label=\"Partners\\nOnly\" fillcolor=deepskyblue ]; partners -\u003e public -\u003e googlers [ style=invisible arrowhead=none ]; } subgraph and_ever { rank = \"same\"; node [ shape=diamond fillcolor=bisque ]; forever_partners [ label=\"Forever?\" shape=diamond fillcolor=bisque ]; forever_googlers [ label=\"Forever?\" shape=diamond fillcolor=bisque ]; } subgraph forever_responses { rank = \"same\"; node [ shape=oval fillcolor=orange ]; forever_partners_yes [ label=\"Yes\" fillcolor=deepskyblue ]; forever_no [ label=\"No, anyone\\neventually\" fillcolor=limegreen ]; forever_googlers_yes [ label=\"Yes\" fillcolor=lightcoral ]; } release_level [ label=\"What release\\nlevel?\" shape=diamond fillcolor=bisque ]; # Not required is not in the subgraph with the other outcomes because # it makes the graph much smaller if it can be higher in the image. subgraph release_levels { rank = \"same\"; node [ shape=oval ]; alpha [ label=\"Alpha\" fillcolor=darkorange ]; beta [ label=\"Beta\" fillcolor=goldenrod1 ]; ga [ label=\"GA\" fillcolor=limegreen ]; alpha -\u003e beta -\u003e ga [ style=invisible arrowhead=none ]; } changes [ label=\"Any changes\\nfrom beta?\" shape=diamond fillcolor=bisque ]; subgraph changes_bool { rank = \"same\"; node [ shape=oval ]; changes_yes [ label=\"Yes\" fillcolor=goldenrod1 ]; changes_no [ label=\"No\" fillcolor=limegreen ]; } subgraph outcome { rank = \"same\"; node [ style=\"rounded,filled\" ]; fyi [ label=\"FYI\" fillcolor=lightblue ]; recommended [ label=\"Recommended\" fillcolor=limegreen ]; required [ label=\"\u26a0 Required\" fillcolor=goldenrod1 ]; not_required [ label=\"Not Required\" fillcolor=lightgrey style=\"rounded,filled\" ]; recommended -\u003e required -\u003e fyi -\u003e not_required [style=invisible arrowhead=none]; } audience -\u003e googlers [ arrowhead=none style=dashed color=grey ]; audience -\u003e partners [ arrowhead=none ]; audience -\u003e public [ arrowhead=none ]; partners -\u003e forever_partners; googlers -\u003e forever_googlers [ style=dashed color=grey ]; public -\u003e release_level; forever_partners -\u003e forever_partners_yes [ arrowhead=none ]; forever_googlers -\u003e forever_googlers_yes [ arrowhead=none style=dashed color=grey ]; forever_partners -\u003e forever_no [ arrowhead=none ]; forever_googlers -\u003e forever_no [ arrowhead=none ]; forever_partners_yes -\u003e recommended; forever_googlers_yes -\u003e not_required [ style=dashed color=grey ]; forever_no -\u003e release_level; release_level -\u003e alpha [ arrowhead=none ]; release_level -\u003e beta [ arrowhead=none ]; release_level -\u003e ga [ arrowhead=none ]; alpha -\u003e recommended; beta -\u003e required; ga -\u003e changes; changes -\u003e changes_yes [ arrowhead=none ]; changes -\u003e changes_no [ arrowhead=none ]; changes_yes -\u003e required; changes_no -\u003e fyi; } Who should code directly against it? One of the more complex questions is, \"Who should code directly against this API?\" API design review is primarily concerned about the API\u0027s audience. This means we care about who is permitted to write their own HTTP/gRPC calls against the service, and who is able to see the documentation. (We do not care about questions such as whether the service is exposed on the public network.) Design review is expected if the general public is intended to read documentation and write code that interacts with the service. The following situations do not require design review: An API which will only ever be used by Googlers, or internal tools (for example, Pantheon). An API which will only ever be called by an executable program released by Google (even if the API could be reverse-engineered from the executable). An API which will only ever be called by a single customer or small set of customers under contract, and which will never be made more widely available. (Design review is still recommended in this case, but not required.) Alpha For alpha, API design review is optional but recommended. It may often make sense to endeavor to get initial feedback from customers quickly, and launching an alpha can be a way of gaining data to determine the best answer to some usability questions; therefore, bypassing review may be expedient. On the other hand, launching an alpha requires building an implementation which then takes engineering effort to update if the API design review at the beta stage raises concerns. Because API design review can precede implementation work, we recommend a design review for alpha. Why is design review important? TL;DR: Product excellence. Our design review process exists to ensure that the APIs that we present to customers are simple, intuitive, and consistent. Your reviewer approaches your API from the standpoint of a na\u00efve user, thinks through the resources and actions that your API provides, and attempts to make the surface as accessible and extensible as possible. Your design reviewer is not only evaluating your API, but also checking to ensure that your API is consistent with Google\u0027s existing corpus of APIs. Many customers use multiple APIs, and therefore it is important that our conventions and naming choices line up with customer expectations. What should I expect? How long does the review process take? Reviewers make an effort to keep up with their assigned reviews and offer feedback frequently, so as not to cause unnecessary delay, but it\u0027s generally best to begin the review process early in case there are delays. The design review process varies based on the size and complexity of the underlying API surface: Incremental changes to existing APIs generally take a few days. Small APIs usually take around a week. Entirely new APIs with large surfaces tend to take no less than a week. In cases with extraordinarily large surfaces (e.g., Cloud AutoML), reviews may take a month or more to go through design review. How do reviewers approach my API? API reviewers seek to approach your API the same way that your users will, by focusing primarily on the API surface and its user-facing documentation. In an ideal world, your API reviewer will ask the types of design questions that users will ask (and nudge the API toward raising fewer of those questions in the first place). What is precedent? In general, we want Google APIs to be as consistent as possible. Once customers learn their first Google API, it should be easier to learn the second (and then the third, and so on) because we are using the same patterns consistently. We refer to precedent to mean decisions that have already been made by previous APIs, which generally should be binding upon newer APIs in similar situations. The most common example of this is naming: we have a list of standard fields that dictate how we use common terms like name, create_time, and so forth, and which also dictates that we always attach the same name to the same concept. Precedent also applies to patterns. All APIs should implement pagination the same way. Ditto for long-running operations, import and export, and so on. Once a pattern has been established, we seek to implement that pattern the same way wherever it is germane. What should I do? ...if I have a launch on a tight deadline? The best thing that you can do is to engage design review as early as possible. Additionally, make your reviewers aware of your timeline so that they are aware, and can endeavor to provide you the best possible service. We want you to make your deadline if at all possible. For time-sensitive alpha launches, an API may launch without receiving design review approval. Such launches must be limited to a known set of users. In this case, the reviewers will provide notes for the API team to take under consideration for subsequent stages. Warning: Launching an API in alpha with an incomplete design review does not enshrine that API\u0027s decisions. Design review will be required to promote the API to beta, and API reviewers will block your beta launch if there are issues. For launch stages after alpha, the API design review is mandatory due to its impact on user experience across the board. Your team\u0027s inconsistencies affect more than just your team. In some cases, there is a difficult choice to be made between product excellence and either engineering effort or deadlines. These are difficult business decisions and we understand that they are sometimes necessary; however, a director or VP must make an explicit choice to put these other concerns ahead of product excellence when choosing to bypass design review or disregard reviewers\u0027 feedback. ...to make my review go faster? A few tips: Begin API review as early as possible, and follow up frequently. Run the API linter beforehand. (If you are disabling the linter at any point, explain why. Reviewers often find that the linter is disabled because it did its job.) Ensure that every message, RPC, and field is usefully commented. Comments should be in valid American English and say something meaningful. If your API reviewer asks you to explain something, add the explanation in the proto comments, rather than the code review conversation. This will very often save you a round trip. ...if one of my API reviewers is unresponsive? Reach out to the reviewer on Hangouts. If that fails, reach out to the other reviewer, who will coordinate accordingly. If that fails also, escalate according to AIP-1. ...if I have a design question? The first places to look at the API style guide, the AIP index, and other public APIs within Google. Other public APIs are particularly valuable; it is common that someone has encountered a situation that is germane to your question. ...if I have a question not covered there? Reach out to api-design@google.com with your question. This generally works best when you are seeking guidance on a specific question related to API design, and when you clearly explain your use case and provide examples. Note: The membership of this list comprises almost exclusively volunteers, who spend the majority of their time doing something else. We do our best to be responsive, but please be patient with us. ...if a question is complex and languishing in a CL? While the code review interface is the best way to resolve questions when practical, sometimes there are issues that are sufficiently complicated that working them out in the code review tool is not feasible. In this situation, reach out to your reviewers and ask to schedule a meeting. In general, most issues can be discussed in 30 minutes. When this happens, make sure that someone documents what is discussed in the CL, so that the history is preserved. ...if my API needs to violate a standard? Clearly document (using an internal comment in the proto) that you are violating an API design guideline and your rationale for doing so. This comment must be prefixed with aip.dev/not-precedent. In general, your rationale for the design guideline violation should be in accordance with one of the enumerated reasons listed in AIP-200. If it is not, work together with your API reviewer to determine the right thing to do. ...if a reviewer is bringing up a previously-settled issue? If you have a different reviewer from your API\u0027s previous stages, this might happen. In general, the best approach is simply to reference the code review where the issue was decided. Reviewers want to avoid causing you churn, and therefore usually give deference to previous reviews. This is usually sufficient to resolve the question promptly. Occasionally, the reviewer may believe that the previous reviewer made a significant mistake, and that correcting it is important. In this case, you and your reviewer should work together to determine the best course of action. ...if the team and the reviewers strongly disagree? Escalate according to AIP-1. Does my PA or team have any particular guidelines? The Cloud PA has specific guidelines to ensure additional consistency across Cloud, and Cloud APIs have their own reviewer pool. Other teams may adopt similar (but not necessarily identical) rules and systems. Some teams that produce multiple APIs (for example, machine learning) may also have guidelines that apply to that group of APIs. In all cases, we endeavor to make these guidelines available as AIPs; the higher AIP numbers are reserved for specific PA and team use (see AIP-2), and these AIPs are listed in the AIP index.",
    'tags': '',
    'url': '/100',
  },
{
    'title': "Resource-oriented design",
    'text': "Resource-oriented design Resource-oriented design is a pattern for specifying RPC APIs, based on several high-level design principles (most of which are common to recent public HTTP APIs): The fundamental building blocks of an API are individually-named resources (nouns) and the relationships and hierarchy that exist between them. A small number of standard methods (verbs) provide the semantics for most common operations. However, custom methods are available in situations where the standard methods do not fit. Stateless protocol: Each interaction between the client and the server is independent, and both the client and server have clear roles. Readers might notice similarities between these principles and some principles of REST; resource-oriented design borrows many principles from REST, while also defining its own patterns where appropriate. Guidance When designing an API, consider the following (roughly in logical order): The resources (nouns) the API will provide The relationships and hierarchies between those resources The schema of each resource The methods (verbs) each resource provides, relying as much as possible on the standard verbs. Resources A resource-oriented API should generally be modeled as a resource hierarchy, where each node is either a simple resource or a collection of resources. A collection contains resources of the same type. For example, a publisher has the collection of books that it publishes. A resource usually has fields, and resources may have any number of sub-resources (usually collections). Note: While there is some conceptual alignment between storage systems and APIs, a service with a resource-oriented API is not necessarily a database, and has enormous flexibility in how it interprets resources and methods. API designers should not expect that their API will be reflective of their database schema. In fact, having an API that is identical to the underlying database schema is actually an anti-pattern, as it tightly couples the surface to the underlying system. Methods Resource-oriented APIs emphasize resources (data model) over the methods performed on those resources (functionality). A typical resource-oriented API exposes a large number of resources with a small number of methods on each resource. The methods can be either the standard methods (Get, List, Create, Update, Delete), or custom methods. Note: A custom method in resource-oriented design does not entail defining a new or custom HTTP verb. Custom methods use traditional HTTP verbs (usually POST) and define the custom verb in the URI. APIs should prefer standard methods over custom methods; the purpose of custom methods is to define functionality that does not cleanly map to any of the standard methods. Custom methods offer the same design freedom as traditional RPC APIs, which can be used to implement common programming patterns, such as database transactions, import and export, or data analysis. Stateless protocol As with most public APIs available today, resource-oriented APIs must operate over a stateless protocol: The fundamental behavior of any individual request is independent of other requests made by the caller. In an API with a stateless protocol, the server has the responsibility for persisting data, which may be shared between multiple clients, while clients have sole responsibility and authority for maintaining the application state. Changelog 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/121',
  },
{
    'title': "Resource names",
    'text': "Resource names Most APIs expose resources (their primary nouns) which users are able to create, retrieve, and manipulate. Additionally, resources are named: each resource has a unique identifier that users use to reference that resource, and these names are what users should store as the canonical names for the resources. Guidance All resource names defined by an API must be unique within that API. (See the section on full resource names below for more information on referring to resources across APIs.) Resource names are formatted according to the URI path schema, but without the leading slash: publishers/123/books/les-miserables users/vhugo1802 Resource name components should usually alternate between collection identifiers (example: publishers, books, users) and resource IDs (example: 123, les-miserables, vhugo1802). Resource names must use the / character to separate individual segments of the resource name. Non-terminal segments of a resource name must not contain a / character. The terminal segment of a resource name should not contain a / character. Resource names should only use characters available in DNS names, as defined by RFC-1123. Additionally, resource IDs should not use upper-case letters. If additional characters are necessary, resource names should not use characters that require URL-escaping, or characters outside of ASCII. If Unicode characters can not be avoided, resource names must be stored in Normalization Form C (see AIP-210). Note: Resource names as described here are used within the scope of a single API (or else in situations where the owning API is clear from the context), and are only required to be unique within that scope. For this reason, they are sometimes called relative resource names to distinguish them from full resource names (discussed below). Collection identifiers The collection identifier segments in a resource name must be the plural form of the noun used for the resource. (For example, a collection of Publisher resources is called publishers in the resource name.) Collection identifiers must be concise American English terms. Collection identifiers must be in camelCase. Collection identifiers must begin with a lower-cased letter and contain only ASCII letters and numbers (/[a-z][a-zA-Z0-9]*/). Collection identifiers must be plural. In situations where there is no plural word (\"info\"), or where the singular and plural terms are the same (\"moose\"), the non-pluralized (singular) form is correct. Collection segments must not \"coin\" words by adding \"s\" in such cases (e.g, avoid \"infos\"). Nested collections If a resource name contains multiple levels of a hierarchy, and a parent collection\u0027s name is used as a prefix for the child resource\u0027s name, the child collection\u0027s name may omit the prefix. For example, given a collection of UserEvent resources that would normally be nested underneath users: users/vhugo1802/userEvents/birthday-dinner-226 An API should use the less-redundant form: users/vhugo1802/events/birthday-dinner-226 In this situation, the message is still called UserEvent; only the resource name is shortened. Note: APIs wishing to do this must follow this format consistently throughout the API, or else not at all. Resource ID segments A resource ID segment identifies the resource within its parent collection. In the resource name publishers/123/books/les-miserables, 123 is the resource ID for the publisher, and les-miserables is the resource ID for the book. Resource IDs may be either always set by users (required on resource creation), optionally set by users (optional on resource creation, server-generated if unset), or never set by users (not accepted at resource creation). They should be immutable once created. If resource IDs are user-settable, the API must document allowed formats. If resource IDs are not user-settable, the API should document the basic format, and any upper boundaries (for example, \"at most 256 characters\"). For more information, see the create standard method. Resource IDs should only use characters that do not require URL-escaping. Characters outside of ASCII are discouraged; however, if Unicode characters are necessary, APIs must follow guidance in AIP-210. Resource ID aliases It is sometimes valuable to provide an alias for common lookup patterns for resource IDs. For example, an API with users at the top of its resource hierarchy may wish to provide users/me as a shortcut for retrieving information for the authenticated user. APIs may provide programmatic aliases for common lookup patterns. However, all data returned from the API must use the canonical resource name. Full resource names In most cases, resource names are used within a single API only, or else they are used in contexts where the owning API is clear (for example, string pubsub_topic). However, sometimes it is necessary for APIs to refer to resources in an arbitrary API. In this situation, they should use the full resource name. The full resource name is a schemeless URI with the owning API\u0027s service endpoint, followed by the relative resource name: //library.googleapis.com/publishers/123/books/les-miserables //calendar.googleapis.com/users/vhugo1802 Resource URIs The full resource name is a schemeless URI, but slightly distinct from the full URIs we use to access a resource. The latter adds two components: the protocol (HTTPS) and the API version: https://library.googleapis.com/v1/publishers/123/books/les-miserables https://calendar.googleapis.com/v3/users/vhugo1802 The version is not included in the full resource name because the full resource name is expected to persist from version to version. Even though the API surface may change between major versions, multiple major versions of the same API are expected to use the same underlying data. Note: The correlation between the full resource name and the service\u0027s hostname is by convention. In particular, one service is able to have multiple hostnames (example use cases include regionalization or staging environments), and the full resource does not change between these. Fields representing resource names When defining a resource, the first field should be the resource name, which must be of type string and must be called name for the resource name. The message should include a google.api.resource annotation declaring the type (see AIP-123 for more on this). // A representation of a book in the library. message Book { option (google.api.resource) = { type: \"library.googleapis.com/Book\" pattern: \"publishers/{publisher}/books/{book}\" }; // The resource name of the book. // Format: publishers/{publisher}/books/{book} string name = 1; // Other fields... } When defining a method that retrieves or acts on an already-existing resource (such as GetBook or ArchiveBook), the first field of the request message should be the resource name, which must be of type string and must be called name for the resource name. The field should also be annotated with the google.api.resource_reference annotation, referencing the resource type (AIP-123). // Request message for ArchiveBook message ArchiveBookRequest { // The book to archive. // Format: publishers/{publisher}/books/{book} string name = 1 [(google.api.resource_reference) = { type: \"library.googleapis.com/Book\" }]; // Other fields... } Note: Fields must not be called name except for this purpose. For other use cases, either use a different term or prepend an adjective (for example: display_name). Fields representing a resource\u0027s parent When defining a method that retrieves resources from a collection or adds a new resource to a collection (such as ListBooks or CreateBook), the first field of the request message should be of type string and should be called parent for the resource name of the collection. The parent field should also be annotated with the google.api.resource_reference annotation, referencing the parent\u0027s resource type (AIP-123). // Request message for ListBooks. message ListBooksRequest { // The publisher to list books from. // Format: publishers/{publisher_id} string parent = 1 [(google.api.resource_reference) = { type: \"library.googleapis.com/Publisher\" }]; // Other fields (e.g. page_size, page_token, filter, etc.)... } If there is more than one possible parent type, the parent field should be annotated with the child_type key on google.api.resource_reference instead: // Request message for ListBooks. message ListBooksRequest { // The publisher to list books from. // Format: publishers/{publisher_id} string parent = 1 [(google.api.resource_reference) = { child_type: \"library.googleapis.com/Book\" }]; // Other fields (e.g. page_size, page_token, filter, etc.)... } Note: Fields should not be called parent except for this purpose. For other use cases, use a synonymous term if possible. Fields representing another resource When referencing a resource name for a different resource, the field should be of type string for the resource name, and the field name should be equivalent to the corresponding message\u0027s name in snake case. Field names may include a leading adjective if appropriate (such as string dusty_book). Field names should not use the _name suffix unless the field would be ambiguous without it (e.g., crypto_key_name) Fields representing another resource should provide the google.api.resource_reference annotation with the resource type being referenced. // A representation of a book in a library. message Book { option (google.api.resource) = { type: \"library.googleapis.com/Book\" pattern: \"publishers/{publisher}/books/{book}\" } // Name of the book. // Format is `publishers/{publisher}/books/{book}` string name = 1; // The shelf where the book currently sits. // Format is `shelves/{shelf}`. string shelf = 2 [(google.api.resource_reference) = { type: \"library.googleapis.com/Shelf\" }]; // Other fields... } Note: When referring to other resources in this way, we use the resource name as the value, not just the ID component. APIs should use the resource name to reference resources when possible. If using the ID component alone is strictly necessary, use an _id suffix (e.g. shelf_id). Further reading For evolving resource names over time, see AIP-180. For resource types, see AIP-123. Changelog 2020-05-19: Clarified that resource IDs avoid capital characters, not the entire resource name. 2020-04-27: Tighten the restriction on valid characters. 2019-12-05: Added guidance for resource annotations. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership. Also changed the final example from a Pub/Sub example to the usual Book example. 2019-07-30: Changed the nested collection brevity suggestion from \"may\" to \"should\"",
    'tags': '',
    'url': '/122',
  },
{
    'title': "Resource types",
    'text': "Resource types Most APIs expose resources (their primary nouns) which users are able to create, retrieve, and manipulate. APIs are allowed to name their resource types as they see fit, and are only required to ensure uniqueness within that API. This means that it is possible (and often desirable) for different APIs to use the same type name. For example, a Memcache and Redis API would both want to use Instance as a type name. When mapping the relationships between APIs and their resources, however, it becomes important to have a single, globally-unique type name. Additionally, tools such as Kubernetes or GraphQL interact with APIs from multiple providers. Terminology In the guidance below, we use the following terms: Service Name: This is the name defined in the service configuration. This usually (but not necessarily) matches the hostname that users use to call the service. Example: pubsub.googleapis.com. This is equivalent to an API Group in Kubernetes. Type: This is the name used for the type within the API. This usually (but not necessarily) matches the name of the protobuf message. This is equivalent to an Object in Kubernetes. Guidance APIs must define a resource type for each resource in the API, according to the following pattern: {Service Name}/{Type}. The type name must be singular and use PascalCase (UpperCamelCase). Examples Examples of resource types include: pubsub.googleapis.com/Topic pubsub.googleapis.com/Subscription spanner.googleapis.com/Database spanner.googleapis.com/Instance networking.istio.io/Instance Annotating resource types APIs should annotate the resource types for each resource in the API using the google.api.resource annotation: // A representation of a Pub/Sub topic. message Topic { option (google.api.resource) = { type: \"pubsub.googleapis.com/Topic\" pattern: \"projects/{project}/topics/{topic}\" }; // The resource name of the topic. string name = 1; // Other fields... } Patterns must correspond to the resource name. Pattern variables (the segments within braces) must use snake_case, and must not use an _id suffix. Pattern uniqueness When multiple patterns are defined within a resource, these patterns must be mutually unique, where uniqueness is defined as being by-character identical once all resource ID path segments have been removed, leaving all / separators. Therefore the following two patterns must not be defined within the same resource: user/{user} user/{user_part_1}~{user_part_2} Changelog 2020-05-14: Added pattern uniqueness. 2019-12-05: Added guidance on patterns. 2019-07-17: Fleshed out the annotation example somewhat.",
    'tags': '',
    'url': '/123',
  },
{
    'title': "Resource association",
    'text': "Resource association APIs sometimes have resource hierarchies that can not be cleanly expressed in the usual tree structure. For example, a resource may have a many-to-one relationship with two other resource types instead of just one. Alternatively, a resource may have a many-to-many relationship with another resource type. Guidance A resource must have at most one canonical parent, and List requests must not require two distinct \"parents\" to work. Multiple many-to-one associations If a resource has a many-to-one relationship with multiple resource types, it must choose at most one of them to be the canonical parent. The resource may be associated with other resources through other fields on the resource. message Book { // The resource name pattern for Book indicates that Publisher is the // canonical parent. option (google.api.resource) = { type: \"library.googleapis.com/Book\" pattern: \"publishers/{publisher}/books/{book}\" }; // The resource name for the book. string name = 1; // The resource name for the book\u0027s author. string author = 2 [(google.api.resource_reference) = { type: \"library.googleapis.com/Author\" }]; } When listing resources with multiple associations in this way, the RPC must treat the string parent field as required as discussed in AIP-132, and must not add additional required arguments. The RPC should include a string filter field that allows users to filter by other resource associations as discussed in AIP-160. Many-to-many associations Many-to-many associations are less common in APIs than they are in relational databases, in part because they are more difficult to model and present over network interfaces. An API may contain many-to-many relationships, and should use a repeated field containing a list of resource names, following the principles described for repeated fields in AIP-144. message Book { option (google.api.resource) = { type: \"library.googleapis.com/Book\" pattern: \"publishers/{publisher}/books/{book}\" }; string name = 1; // The resource names for the book\u0027s authors. repeated string authors = 2 [(google.api.resource_reference) = { type: \"library.googleapis.com/Author\" }]; } Note: See AIP-144 for more information on repeated fields, including how to handle common issues such as atomic changes. If the use of a repeated field is too restrictive, or if more metadata is required along with the association, an API may model a many-to-many relationship using a sub-resource with two one-to-many associations. message BookAuthor { // The resource pattern for BookAuthor indicates that Book is the // canonical parent. option (google.api.resource) = { type: \"library.googleapis.com/BookAuthor\" pattern: \"publishers/{publisher}/books/{book}/authors/{book_author}\" } // The resource name for the book-author association. string name = 1; // The resource name for the author. string author = 2 [(google.api.resource_reference) = { type: \"library.googleapis.com/Author\" }]; // Other fields... } Note: Using subresources to model an association between resources is only recommended if additional metadata is required in the relationship, or if the restrictions around the use of a repeated field preclude the use of that approach.",
    'tags': '',
    'url': '/124',
  },
{
    'title': "Enumerations",
    'text': "Enumerations It is common for a field to only accept or provide a discrete and limited set of values. In these cases, it can be useful to use enumerations (generally abbreviated \"enums\") in order to clearly communicate what the set of allowed values are. Guidance APIs may expose enum objects for sets of values that are expected to change infrequently: // A representation of a book. message Book { // Other fields... // Possible formats in which the book may be published. enum Format { // Default value. This value is unused. FORMAT_UNSPECIFIED = 0; // The printed format, in hardback. HARDBACK = 1; // The printed format, in paperback. PAPERBACK = 2; // An electronic book format. EBOOK = 3; // An audio recording. AUDIOBOOK = 4; } // The format of the book. Format format = 99; // Other fields... } All enum values must use UPPER_SNAKE_CASE. The first value of the enum should be the name of the enum itself followed by the suffix _UNSPECIFIED. An exception to this rule is if there is a clearly useful zero value. In particular, if an enum needs to present an UNKNOWN, it is usually clearer and more useful for it to be a zero value rather than having both. Enums which will only be used in a single message should be nested within that message. In this case, the enum should be declared immediately before it is used. If multiple enums are in the same namespace, they must not share any values. (This is because enums do not provide their own namespace for their values in some languages.) Enums should document whether the enum is frozen or they expect to add values in the future. When to use enums Enums can be more accessible and readable than strings or booleans in many cases, but they do add overhead when they change. Therefore, enums should receive new values infrequently. While the definition of \"infrequently\" may change based on individual use cases, a good rule of thumb is no more than once a year. For enums that change frequently, the API should use a string and document the format. Additionally, enums should not be used when there is a competing, widely-adopted standard representation (such as with language codes or media types). Note: If an enumerated value needs to be shared across APIs, an enum may be used, but the assignment between enum values and their corresponding integers must match. Alternatives For enumerated values where the set of allowed values changes frequently, APIs should use a string field instead, and must document the allowed values. String fields with enumerated values should use kebab-case for their values. For enumerated values where there is a competing, widely-adopted standard representation (generally, but not necessarily, a string), that standard representation should be used. This is true even if only a small subset of values are permitted, because using enums in this situation often leads to frustrating lookup tables when trying to use multiple APIs together. Boolean fields may be used in situations where it is clear that no further flexibility will be needed. The default value must be false. Note: When using protocol buffers, it is impossible to distinguish between false and unset. If this is a requirement, an enum may be a better design choice (although google.protobuf.BoolValue is also available). Further reading For states, a special type of enum, see AIP-216.",
    'tags': '',
    'url': '/126',
  },
{
    'title': "HTTP and gRPC Transcoding",
    'text': "HTTP and gRPC Transcoding APIs that follow resource-oriented design are defined using RPCs, but the resource-oriented design framework allows them to also be presented as APIs that largely follow REST/JSON conventions. This is important in order to help developers use their existing knowledge: over 80% of the public APIs available follow most REST conventions, and developers are accustomed to that pattern. Guidance APIs must provide HTTP definitions for each RPC that they define, except for bi-directional streaming RPCs, which can not be natively supported using HTTP/1.1. When providing a bi-directional streaming method, an API should also offer an alternative method that does not rely on bi-directional streaming. HTTP method and path When using protocol buffers, each RPC must define the HTTP method and path using the google.api.http annotation: rpc CreateBook(CreateBookRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books/*\" body: \"book\" }; } message CreateBookRequest { // The publisher who will publish this book. // When using HTTP/JSON, this field is automatically populated based // on the URI, because of the `{parent=publishers/*}` syntax. string parent = 1; // The book to create. // When using HTTP/JSON, this field is populated based on the HTTP body, // because of the `body: \"book\"` syntax. Book book = 2; // The user-specified ID for the book. // When using HTTP/JSON, this field is populated based on a query string // argument, such as `?book_id=foo`. This is the fallback for fields that // are not included in either the URI or the body. string book_id = 3; } The first key (post in this example) corresponds to the HTTP method. RPCs may use get, post, patch, or delete. RPCs must use the prescribed HTTP verb for each standard method, as discussed in AIP-131, AIP-132, AIP-133, AIP-134, and AIP-135 RPCs should use the prescribed HTTP verb for custom methods, as discussed in AIP-136. RPCs should not use put or custom. The corresponding value represents the URI. URIs must use the {foo=bar/*} syntax to represent a variable that should be populated in the request proto. When extracting a resource name, the variable must include the entire resource name, not just the ID component. URIs must use the * character to represent ID components, which matches all URI-safe characters except for /. URIs may use ** as the final segment of a URI if matching / is required. The body key defines which field in the request will be sent as the HTTP body. If the body is *, then this indicates that the request object itself is the HTTP body. The request body is encoded as JSON as defined by protocol buffers\u0027 canonical JSON encoding. RPCs must not define a body at all for RPCs that use the GET or DELETE HTTP verbs. RPCs must use the prescribed body for Create (AIP-133) and Update (AIP-134) requests. RPCs should use the prescribed body for custom methods (AIP-136). Fields should not use the json_name annotation to alter the field name in JSON, unless doing so for backwards-compatibility reasons. Note: Bi-directional streaming RPCs should not include a google.api.http annotation at all. If feasible, the service should provide non-streaming equivalent RPCs. Multiple URI bindings Occasionally, an RPC needs to correspond to more than one URI: rpc CreateBook(CreateBookRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books\" body: \"book\" additional_bindings: { post: \"/v1/{parent=authors/*}/books\" body: \"book\" } additional_bindings: { post: \"/v1/books\" body: \"book\" } } } RPCs may define any number of additional bindings. The structure is identical to the google.api.http annotation (in fact, it is a recursive reference). RPCs must not define an additional binding within an additional binding. The body clause must be identical in the top-level annotation and each additional binding. Changelog 2019-09-23: Added a statement about request body encoding, and guidance discouraging json_name.",
    'tags': '',
    'url': '/127',
  },
{
    'title': "Standard methods: Get",
    'text': "Standard methods: Get In REST APIs, it is customary to make a GET request to a resource\u0027s URI (for example, /v1/publishers/{publisher}/books/{book}) in order to retrieve that resource. Resource-oriented design (AIP-121) honors this pattern through the Get method. These RPCs accept the URI representing that resource and return the resource. Guidance APIs should generally provide a get method for resources unless it is not valuable for users to do so. The purpose of the get method is to return data from a single resource. Get methods are specified using the following pattern: rpc GetBook(GetBookRequest) returns (Book) { option (google.api.http) = { get: \"/v1/{name=publishers/*/books/*}\" }; option (google.api.method_signature) = \"name\"; } The RPC\u0027s name must begin with the word Get. The remainder of the RPC name should be the singular form of the resource\u0027s message name. The request message must match the RPC name, with a -Request suffix. The response message must be the resource itself. (There is no GetBookResponse.) The response should usually include the fully-populated resource unless there is a reason to return a partial response (see AIP-157). The HTTP verb must be GET. The URI should contain a single variable field corresponding to the resource name. This field should be called name. The URI should have a variable corresponding to this field. The name field should be the only variable in the URI path. All remaining parameters should map to URI query parameters. There must not be a body key in the google.api.http annotation. There should be exactly one google.api.method_signature annotation, with a value of \"name\". Request message Get methods implement a common request message pattern: message GetBookRequest { // The name of the book to retrieve. // Format: publishers/{publisher}/books/{book} string name = 1 [ (google.api.field_behavior) = REQUIRED, (google.api.resource_reference) = { type: \"library-example.googleapis.com/Book\" }]; } A resource name field must be included. It should be called name. The field should be annotated as required. The field should identify the resource type that it references. The comment for the name field should document the resource pattern. The request message must not contain any other required fields, and should not contain other optional fields except those described in another AIP. Note: The name field in the request object corresponds to the name variable in the google.api.http annotation on the RPC. This causes the name field in the request to be populated based on the value in the URL when the REST/JSON interface is used. Errors If the user does not have permission to access the resource, regardless of whether or not it exists, the service must error with PERMISSION_DENIED (HTTP 403). Permission must be checked prior to checking if the resource exists. If the user does have proper permission, but the requested resource does not exist, the service must error with NOT_FOUND (HTTP 404). Changelog 2020-06-08: Added guidance on returning the full resource. 2019-10-18: Added guidance on annotations. 2019-08-12: Added guidance for error cases. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership. 2019-05-29: Added an explicit prohibition on arbitrary fields in standard methods.",
    'tags': '',
    'url': '/131',
  },
{
    'title': "Standard methods: List",
    'text': "Standard methods: List In many APIs, it is customary to make a GET request to a collection\u0027s URI (for example, /v1/publishers/1/books) in order to retrieve a list of resources, each of which lives within that collection. Resource-oriented design (AIP-121) honors this pattern through the List method. These RPCs accept the parent collection (and potentially some other parameters), and return a list of responses matching that input. Guidance APIs should generally provide a List method for resources unless it is not valuable for users to do so. The purpose of the List method is to return data from a single, finite collection. List methods are specified using the following pattern: rpc ListBooks(ListBooksRequest) returns (ListBooksResponse) { option (google.api.http) = { get: \"/v1/{parent=publishers/*}/books\" }; option (google.api.method_signature) = \"parent\"; } The RPC\u0027s name must begin with the word List. The remainder of the RPC name should be the plural form of the resource being listed. The request and response messages must match the RPC name, with -Request and -Response suffixes. The HTTP verb must be GET. The collection whose resources are being listed should map to the URL path. The collection\u0027s parent resource should be called parent, and should be the only variable in the URI path. All remaining parameters should map to URI query parameters. The collection identifier (books in the above example) must be a literal string. The body key in the google.api.http annotation must be omitted. There should be exactly one google.api.method_signature annotation, with a value of \"parent\". Request message List methods implement a common request message pattern: message ListBooksRequest { // The parent, which owns this collection of books. // Format: publishers/{publisher} string parent = 1 [ (google.api.field_behavior) = REQUIRED, (google.api.resource_reference) = { child_type: \"library-example.googleapis.com/Book\" }]; // The maximum number of books to return. The service may return fewer than // this value. // If unspecified, at most 50 books will be returned. // The maximum value is 1000; values above 1000 will be coerced to 1000. int32 page_size = 2; // A page token, received from a previous `ListBooks` call. // Provide this to retrieve the subsequent page. // // When paginating, all other parameters provided to `ListBooks` must match // the call that provided the page token. string page_token = 3; } A parent field must be included unless the resource being listed is a top-level resource. It should be called parent. The field should be annotated as required. The field should identify the resource type of the resource being listed. The page_size and page_token fields, which support pagination, must be specified on all list request messages. For more information, see AIP-158. The comment above the page_size field should document the maximum allowed value, as well as the default value if the field is omitted (or set to 0). If preferred, the API may state that the server will use a sensible default. This default may change over time. If a user provides a value greater than the maximum allowed value, the API should coerce the value to the maximum allowed. If a user provides a negative or other invalid value, the API must send an INVALID_ARGUMENT error. The page_token field must be included on all list request messages. The request message may include fields for common design patterns relevant to list methods, such as string filter and string order_by. The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. Note: List methods should return the same results for any user that has permission to make a successful List request on the collection. Search methods are more relaxed on this. Response message List methods implement a common response message pattern: message ListBooksResponse { // The books from the specified publisher. repeated Book books = 1; // A token, which can be sent as `page_token` to retrieve the next page. // If this field is omitted, there are no subsequent pages. string next_page_token = 2; } The response message must include one repeated field corresponding to the resources being returned, and should not include any other repeated fields. The response should usually include fully-populated resources unless there is a reason to return a partial response (see [AIP-157][]). The next_page_token field, which supports pagination, must be included on all list response messages. It must be set if there are subsequent pages, and must not be set if the response represents the final page. For more information, see AIP-158. The message may include a int32 total_size (or int64 total_size) field with the number of items in the collection. The value may be an estimate (the field should clearly document this if so). If filtering is used, the total_size field should reflect the size of the collection after the filter is applied. Ordering List methods may allow clients to specify sorting order; if they do, the request message should contain a string order_by field. Values should be a comma separated list of fields. For example: \"foo,bar\". The default sorting order is ascending. To specify descending order for a field, users append a \" desc\" suffix; for example: \"foo desc, bar\". Redundant space characters in the syntax are insignificant. \"foo, bar desc\", \" foo , bar desc \", and \"foo,bar desc\" are all equivalent. Subfields are specified with a . character, such as foo.bar or address.street. Note: Only include ordering if there is an established need to do so. It is always possible to add ordering later, but removing it is a breaking change. Filtering List methods may allow clients to specify filters; if they do, the request message should contain a string filter field. Note: Only include filtering if there is an established need to do so. It is always possible to add filtering later, but removing it is a breaking change. Soft-deleted resources Some APIs need to \"soft delete\" resources, marking them as deleted or pending deletion (and optionally purging them later). APIs that do this should not include deleted resources by default in list requests. APIs with soft deletion of a resource should include a bool show_deleted field in the list request that, if set, will cause soft-deleted resources to be included. Further reading For details on pagination, see AIP-158. For listing across multiple parent collections, see AIP-159. Changelog 2020-06-08: Added guidance on returning the full resource. 2020-05-19: Removed requirement to document ordering behavior. 2020-04-15: Added guidance on List permissions. 2019-10-18: Added guidance on annotations. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership. 2019-07-30: Added guidance about documenting the ordering behavior. 2019-05-29: Added an explicit prohibition on arbitrary fields in standard methods.",
    'tags': '',
    'url': '/132',
  },
{
    'title': "Standard methods: Create",
    'text': "Standard methods: Create In REST APIs, it is customary to make a POST request to a collection\u0027s URI (for example, /v1/publishers/{publisher}/books) in order to create a new resource within that collection. Resource-oriented design (AIP-121) honors this pattern through the Create method. These RPCs accept the parent collection and the resource to create (and potentially some other parameters), and return the created resource. Guidance APIs should generally provide a create method for resources unless it is not valuable for users to do so. The purpose of the create method is to create a new resource in an already-existing collection. Create methods are specified using the following pattern: rpc CreateBook(CreateBookRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books\" body: \"book\" }; option (google.api.method_signature) = \"parent,book\"; } The RPC\u0027s name must begin with the word Create. The remainder of the RPC name should be the singular form of the resource being created. The request message must match the RPC name, with a -Request suffix. The response message must be the resource itself. There is no CreateBookResponse. The response should include the fully-populated resource, and must include any fields that were provided unless they are input only (see AIP-203). If the create RPC is long-running, the response message must be a google.longrunning.Operation which resolves to the resource itself. The HTTP verb must be POST. The collection where the resource is being added should map to the URL path. The collection\u0027s parent resource should be called parent, and should be the only variable in the URI path. The collection identifier (books in the above example) must be literal. There must be a body key in the google.api.http annotation, and it must map to the resource field in the request message. All remaining fields should map to URI query parameters. There should be exactly one google.api.method_signature annotation, with a value of \"parent,{resource}\" (unless the method supports user-specified IDs). Request message Create methods implement a common request message pattern: message CreateBookRequest { // The parent resource where this book will be created. // Format: publishers/{publisher} string parent = 1 [ (google.api.field_behavior) = REQUIRED, (google.api.resource_reference) = { child_type: \"library-example.googleapis.com/Book\" }]; // The book to create. Book book = 2 [(google.api.field_behavior) = REQUIRED]; } A parent field must be included unless the resource being created is a top-level resource. It should be called parent. The field should be annotated as required. The field should identify the resource type of the resource being created. The resource field must be included and must map to the POST body. The request message must not contain any other required fields and should not contain other optional fields except those described in this or another AIP. Long-running create Some resources take longer to create a resource than is reasonable for a regular API request. In this situation, the API should use a long-running operation instead: rpc CreateBook(CreateBookRequest) returns (google.longrunning.Operation) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books\" }; option (google.longrunning.operation_info) = { response_type: \"Book\" metadata_type: \"OperationMetadata\" } } The response type must be set to the resource (what the return type would be if the RPC was not long-running). Both the response_type and metadata_type fields must be specified. User-specified IDs Sometimes, an API needs to allow a client to specify the ID component of a resource (the last segment of the resource name) on creation. This is common if users are allowed to choose that portion of their resource names. For example: // Using user-settable IDs. publishers/lacroix/books/les-miserables // Using system-generated IDs. publishers/012345678-abcd-cdef/books/12341234-5678-abcd Create RPCs may support this behavior by providing a string {resource}_id field on the request message: message CreateBookRequest { // The parent resource where this book will be created. // Format: publishers/{publisher} string parent = 1 [ (google.api.field_behavior) = REQUIRED, (google.api.resource_reference) = { child_type: \"library-example.googleapis.com/Book\" }]; // The book to create. Book book = 2 [(google.api.field_behavior) = REQUIRED]; // The ID to use for the book, which will become the final component of // the book\u0027s resource name. // // This value should be 4-63 characters, and valid characters // are /[a-z][0-9]-/. string book_id = 3; } The {resource}_id field must exist on the request message, not the resource itself. The field may be required or optional. If it is required, it should include the corresponding annotation. The name field on the resource must be ignored. There should be exactly one google.api.method_signature annotation on the RPC, with a value of \"parent,{resource},{resource}_id\". The documentation should explain what the acceptable format is, and the format should follow the guidance for resource name formatting in AIP-122. If a user tries to create a resource with an ID that would result in a duplicate resource name, the service must error with ALREADY_EXISTS. However, if the user making the call does not have permission to see the duplicate resource, the service must error with FORBIDDEN instead. Further reading For ensuring idempotency in Create methods, see AIP-155. For naming resources involving Unicode, see AIP-210. Changelog 2020-06-08: Added guidance on returning the full resource. 2019-11-22: Added clarification on what error to use if a duplicate name is sent. 2019-10-18: Added guidance on annotations. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership. 2019-06-10: Added guidance for long-running create. 2019-05-29: Added an explicit prohibition on arbitrary fields in standard methods.",
    'tags': '',
    'url': '/133',
  },
{
    'title': "Standard methods: Update",
    'text': "Standard methods: Update In REST APIs, it is customary to make a PATCH or PUT request to a resource\u0027s URI (for example, /v1/publishers/{publisher}/books/{book}) in order to update that resource. Resource-oriented design (AIP-121) honors this pattern through the Update method (which mirrors the REST PATCH behavior). These RPCs accept the URI representing that resource and return the resource. Guidance APIs should generally provide an update method for resources unless it is not valuable for users to do so. The purpose of the update method is to make changes to the resources without causing side effects. Update methods are specified using the following pattern: rpc UpdateBook(UpdateBookRequest) returns (Book) { option (google.api.http) = { patch: \"/v1/{book.name=publishers/*/books/*}\" body: \"book\" }; option (google.api.method_signature) = \"book,update_mask\"; } The RPC\u0027s name must begin with the word Update. The remainder of the RPC name should be the singular form of the resource\u0027s message name. The request message must match the RPC name, with a -Request suffix. The response message must be the resource itself. (There is no UpdateBookResponse.) The response should include the fully-populated resource, and must include any fields that were sent and included in the update mask unless they are input only (see AIP-203). If the update RPC is long-running, the response message must be a google.longrunning.Operation which resolves to the resource itself. The method should support partial resource update, and the HTTP verb should be PATCH. If the method will only ever support full resource replacement, then the HTTP verb may be PUT. However, this is strongly discouraged because it becomes a backwards-incompatible change to add fields to the resource. The resource\u0027s name field should map to the URI path. The {resource}.name field should be the only variable in the URI path. There must be a body key in the google.api.http annotation, and it must map to the resource field in the request message. All remaining fields should map to URI query parameters. There should be exactly one google.api.method_signature annotation, with a value of \"{resource},update_mask\". Note: Unlike the other four standard methods, the URI path here references a nested field (book.name) in the example. If the resource field has a word separator, snake_case is used. Request message Update methods implement a common request message pattern: message UpdateBookRequest { // The book to update. // // The book\u0027s `name` field is used to identify the book to be updated. // Format: publishers/{publisher}/books/{book} Book book = 1 [(google.api.field_behavior) = REQUIRED]; // The list of fields to be updated. google.protobuf.FieldMask update_mask = 2; } The request message must contain a field for the resource. The field must map to the PATCH body. The field should be annotated as required. A name field must be included in the resource message. It should be called name. A field mask should be included in order to support partial update. It must be of type google.protobuf.FieldMask, and it should be called update_mask. The fields used in the field mask correspond to the resource being updated (not the request message). The field may be required or optional. If it is required, it should include the corresponding annotation. The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. Side effects In general, update methods are intended to update the data within the resource. Update methods should not trigger other side effects. Instead, side effects should be triggered by custom methods. In particular, this entails that state fields must not be directly writable in update methods. PATCH and PUT TL;DR: Google APIs generally use the PATCH HTTP verb only, and do not support PUT requests. We standardize on PATCH because Google updates stable APIs in place with backwards-compatible improvements. It is often necessary to add a new field to an existing resource, but this becomes a breaking change when using PUT. To illustrate this, consider a PUT request to a Book resource: PUT /v1/publishers/123/books/456 {\"title\": \"Mary Poppins\", \"author\": \"P.L. Travers\"} Next consider that the resource is later augmented with a new field (here we add rating): message Book { string title = 1; string author = 2; // Subsequently added to v1 in place... int32 rating = 3; } If a rating is set on a book and the existing PUT request was executed, it would wipe out the book\u0027s rating. In essence, a PUT request unintentionally wiped out data because the previous version did not know about it. Long-running update Some resources take longer to update a resource than is reasonable for a regular API request. In this situation, the API should use a long-running operation (AIP-151) instead: rpc UpdateBook(UpdateBookRequest) returns (google.longrunning.Operation) { option (google.api.http) = { patch: \"/v1/{book.name=publishers/*/books/*}\" }; option (google.longrunning.operation_info) = { response_type: \"Book\" metadata_type: \"OperationMetadata\" } } The response type must be set to the resource (what the return type would be if the RPC was not long-running). Both the response_type and metadata_type fields must be specified. Create or update If the API accepts client-assigned resource names, the server may allow the client to specify a non-existent resource name and create a new resource (effectively implementing the \"upsert\" concept). Otherwise, the Update method should fail with NOT_FOUND. An API with an update method that supports resource creation should also provide a create method, because otherwise it may not be clear to users how to create resources. Etags An API may sometimes need to allow users to send update requests which are guaranteed to be made against the most current data (a common use case for this is to detect and avoid race conditions). Resources which need to enable this do so by including a string etag field, which contains an opaque, server-computed value representing the content of the resource. In this situation, the resource should contain a string etag field: message Book { // The resource name of the book. // Format: publishers/{publisher}/books/{book} string name = 1; // The title of the book. // Example: \"Mary Poppins\" string title = 2; // The author of the book. // Example: \"P.L. Travers\" string author = 3; // The etag for this book. // If this is provided on update, it must match the server\u0027s etag. string etag = 4; } The etag field may be either required or optional. If it is set, then the request must succeed if and only if the provided etag matches the server-computed value, and must fail with a FAILED_PRECONDITION error otherwise. The update_mask field in the request does not affect the behavior of the etag field, as it is not a field being updated. Expensive fields APIs sometimes encounter situations where some fields on a resource are expensive or impossible to reliably return. This can happen in a few situations: A resource may have some fields that are very expensive to compute, and that are generally not useful to the customer on update requests. A single resource sometimes represents an amalgamation of data from multiple underlying (and eventually consistent) data sources. In these situations, it is impossible to return authoritative information on the fields that were not changed. In this situation, an API may return back only the fields that were updated, and omit the rest, and should document this behavior if they do so. Changelog 2020-06-08: Added guidance on returning the full resource. 2019-10-18: Added guidance on annotations. 2019-09-10: Added a link to the long-running operations AIP (AIP-151). 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership. 2019-06-10: Added guidance for long-running update. 2019-05-29: Added an explicit prohibition on arbitrary fields in standard methods.",
    'tags': '',
    'url': '/134',
  },
{
    'title': "Standard methods: Delete",
    'text': "Standard methods: Delete In REST APIs, it is customary to make a DELETE request to a resource\u0027s URI (for example, /v1/publishers/{publisher}/books/{book}) in order to delete that resource. Resource-oriented design (AIP-121) honors this pattern through the Delete method. These RPCs accept the URI representing that resource and usually return an empty response. Guidance APIs should generally provide a delete method for resources unless it is not valuable for users to do so. Delete methods are specified using the following pattern: rpc DeleteBook(DeleteBookRequest) returns (google.protobuf.Empty) { option (google.api.http) = { delete: \"/v1/{name=publishers/*/books/*}\" }; option (google.api.method_signature) = \"name\"; } The RPC\u0027s name must begin with the word Delete. The remainder of the RPC name should be the singular form of the resource\u0027s message name. The request message must match the RPC name, with a -Request suffix. The response message should be google.protobuf.Empty. If the resource is soft deleted, the response message should be the resource itself. If the delete RPC is long-running, the response message must be a google.longrunning.Operation which resolves to the correct response. The HTTP verb must be DELETE. The request message field receiving the resource name should map to the URL path. This field should be called name. The name field should be the only variable in the URI path. All remaining parameters should map to URI query parameters. There must not be a body key in the google.api.http annotation. There should be exactly one google.api.method_signature annotation, with a value of \"name\". If an etag or force field are used, they may be included in the signature. The Delete method should succeed if and only if a resource was present and was successfully deleted. If the resource did not exist, the method should send a NOT_FOUND error. Request message Delete methods implement a common request message pattern: message DeleteBookRequest { // The name of the book to delete. // Format: publishers/{publisher}/books/{book} string name = 1 [ (google.api.field_behavior) = REQUIRED, (google.api.resource_reference) = { type: \"library-example.googleapis.com/Book\" }]; } A name field must be included. It should be called name. The field should be annotated as required. The field should identify the resource type that it references. The comment for the field should document the resource pattern. The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. Soft delete APIs may support the ability to \"undelete\", to allow for situations where users mistakenly delete resources and need the ability to recover. If a resource needs to support undelete, the Delete method should simply mark the resource as having been deleted, but not completely remove it from the system. If the method behaves this way, it should return the updated resource (not google.protobuf.Empty), with its state set to DELETED. Soft-deleted resources should not show up in List requests by default (unless bool show_deleted is true). Get requests for soft-deleted resources should return the resource (rather than a NOT_FOUND error). The undelete functionality should be implemented through an \"undelete\" custom method. APIs that soft delete resources may choose a reasonable strategy for purging those resources, including automatic purging after a reasonable time (such as 30 days), allowing users to set an expiry time, or retaining the resources indefinitely. Regardless of what strategy is selected, the API should document when soft deleted resources will be completely removed. Long-running delete Some resources take longer to delete a resource than is reasonable for a regular API request. In this situation, the API should use a long-running operation instead: rpc DeleteBook(DeleteBookRequest) returns (google.longrunning.Operation) { option (google.api.http) = { delete: \"/v1/{name=publishers/*/books/*}\" }; option (google.longrunning.operation_info) = { response_type: \"google.protobuf.Empty\" metadata_type: \"OperationMetadata\" } } The response type must be set to the appropriate return type if the RPC was not long-running: google.protobuf.Empty for most Delete RPCs, or the resource itself for soft delete. Both the response_type and metadata_type fields must be specified (even if they are google.protobuf.Empty). Cascading delete Sometimes, it may be necessary for users to be able to delete a resource as well as all applicable child resources. However, since deletion is usually permanent, it is also important that users not do so accidentally, as reconstructing wiped-out child resources may be quite difficult. If an API allows deletion of a resource that may have child resources, the API should provide a bool force field on the request, which the user sets to explicitly opt in to a cascading delete. message DeletePublisherRequest { // The name of the publisher to delete. // Format: publishers/{publisher} string name = 1; // If set to true, any books from this publisher will also be deleted. // (Otherwise, the request will only work if the publisher has no books.) bool force = 2; } The API must fail with a FAILED_PRECONDITION error if the force field is false (or unset) and child resources are present. Protected delete Sometimes, it may be necessary for users to ensure that no changes have been made to a resource that is being deleted. If a resource provides an etag, the delete request may accept the etag (as either required or optional): message DeleteBookRequest { // The name of the book to delete. // Format: publishers/{publisher}/books/{book} string name = 1; // Optional. The etag of the book. // If this is provided, it must match the server\u0027s etag. string etag = 2; } If the etag is provided and does not match the server-computed etag, the request must fail with a FAILED_PRECONDITION error code. Errors If the user does not have permission to access the resource, regardless of whether or not it exists, the service must error with PERMISSION_DENIED (HTTP 403). Permission must be checked prior to checking if the resource exists. If the user does have proper permission, but the requested resource does not exist, the service must error with NOT_FOUND (HTTP 404). Changelog 2020-06-08: Added guidance for Get of soft-deleted resources. 2020-02-03: Added guidance for error cases. 2019-10-18: Added guidance on annotations. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership. 2019-06-10: Added guidance for long-running delete. 2019-05-29: Added an explicit prohibition on arbitrary fields in standard methods.",
    'tags': '',
    'url': '/135',
  },
{
    'title': "Custom methods",
    'text': "Custom methods Resource-oriented design uses custom methods to provide a means to express arbitrary actions that are difficult to model using only the standard methods. Custom methods are important because they provide a means for an API\u0027s vocabulary to adhere to user intent. Guidance Custom methods should only be used for functionality that can not be easily expressed via standard methods; prefer standard methods if possible, due to their consistent semantics. (Of course, this only applies if the functionality in question actually conforms to the normal semantics; it is not a good idea to contort things to endeavor to make the standard methods \"sort of work\".) While custom methods vary widely in how they are designed, many principles apply consistently: // Archives the given book. rpc ArchiveBook(ArchiveBookRequest) returns (ArchiveBookResponse) { option (google.api.http) = { post: \"/v1/{name=publishers/*/books/*}:archive\" body: \"*\" }; } Note: The pattern above shows a custom method that operates on a specific resource. Custom methods can be associated with resources, collections, or services. The bullets below apply in all three cases. The name of the method should be a verb followed by a noun. The name must not contain prepositions (\"for\", \"with\", etc.). The HTTP method for custom methods should usually be POST, unless the custom method maps more strongly to another HTTP verb. Custom methods that serve as an alternative to get or list methods (such as Search) should use GET. These methods must be idempotent and have no side effects. Custom methods should not use PATCH or DELETE. The HTTP URI must use a : character followed by the custom verb (:archive in the above example), and the verb in the URI must match the verb in the name of the RPC. If word separation is required, camelCase must be used. The body clause in the google.api.http annotation should be \"*\". However, if using GET or DELETE, the body clause must be absent. Custom methods should usually take a request message matching the RPC name, with a -Request suffix. Custom methods should usually return a response message matching the RPC name, with a -Response suffix. When operating on a specific resource, a custom method may return the resource itself. Collection-based custom methods While most custom methods operate on a single resource, some custom methods may operate on a collection instead: // Sorts the books from this publisher. rpc SortBooks(SortBooksRequest) returns (SortBooksResponse) { option (google.api.http) = { post: \"/v1/{publisher=publishers/*}/books:sort\" body: \"*\" }; } If the collection has a parent, the field name in the request message should be the target resource\u0027s singular noun (publisher in the above example). If word separators are necessary, snake_case must be used. The collection key (books in the above example) must be literal. Stateless methods Some custom methods are not attached to resources at all. These methods are generally stateless: they accept a request and return a response, and have no permanent effect on data within the API. // Translates the provided text from one language to another. rpc TranslateText(TranslateTextRequest) returns (TranslateTextResponse) { option (google.api.http) = { post: \"/v1/{project=projects/*}:translateText\" body: \"*\" }; } If the method runs in a particular scope (such as a project, as in the above example), the field name in the request message should be the name of the scope resource. If word separators are necessary, snake_case must be used. The URI should place both the verb and noun after the : separator (avoid a \"faux collection key\" in the URI in this case, as there is no collection). For example, :translateText is preferable to text:translate. Stateless methods must use POST if they involve billing. Changelog 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/136',
  },
{
    'title': "Field names",
    'text': "Field names Naming fields in a way that is intuitive to users can often be one of the most challenging aspects of designing an API. This is true for many reasons; often a field name that seems entirely intuitive to the author can baffle a reader. Additionally, users rarely use only one API; they use many APIs together. As a result, a single company using the same name to mean different things (or different names to mean the same thing) can often cause unnecessary confusion, because users can no longer take what they\u0027ve already learned from one API and apply that to another. In short, APIs are easiest to understand when field names are simple, intuitive, and consistent with one another. Guidance Field names should be in correct American English. Field names should clearly and precisely communicate the concept being presented and avoid overly general names that are ambiguous. That said, field names should avoid including unnecessary words. In particular, avoid including adjectives that always apply and add little cognitive value. For example, a proxy_settings field might be as helpful as shared_proxy_settings if there is no unshared variant. Case Field definitions in protobuf files must use lower_snake_case names. These names are mapped to an appropriate naming convention in JSON and in generated code. Additionally, each word in the field must not begin with a number, because it creates ambiguity when converting between snake case and camel case. Consistency APIs should endeavor to use the same name for the same concept and different names for different concepts wherever possible. This includes names across multiple APIs, in particular if those APIs are likely to be used together. Repeated fields Repeated fields must use the proper plural form, such as books or authors. On the other hand, non-repeated fields should use the singular form such as book or author. This implies that resource names should use the singular form as well, since the field name should follow the resource name (e.g., use repeated Book books, not Books books = 1). Prepositions Field names should not include prepositions (such as \"with\", \"for\", \"at\", \"by\", etc). For example: error_reason (not reason_for_error) author (not written_by) It is easier for field names to match more often when following this convention. Additionally, prepositions in field names may also indicate a design concern, such as an overly-restrictive field or a sub-optimal data type. This is particularly true regarding \"with\": a field named book_with_publisher likely indicates that the book resource may be improperly structured and worth redesigning. Note: The word \"per\" is an exception to this rule, particularly in two cases. Often \"per\" is part of a unit (e.g. \"miles per hour\"), in which case the preposition must be present to accurately convey the unit. Additionally, \"per\" is often appropriate in reporting scenarios (e.g. \"nodes per instance\" or \"failures per hour\"). Adjectives For consistency, field names that contain both a noun and an adjective should place the adjective before the noun. For example: collected_items (not items_collected) imported_objects (not objects_imported) Booleans Boolean fields should omit the prefix \"is\". For example: disabled (not is_disabled) required (not is_required) Note: Field names that would otherwise be reserved words are an exception to this rule. For example, is_new (not new). URIs Field names representing URLs or URIs should always use uri rather than url. This is because while all URLs are URIs, not all URIs are URLs. Field names may use a prefix in front of uri as appropriate. Reserved words Field names should avoid using names that are likely to conflict with keywords in common programming languages, such as new, class, function, import, etc. Reserved keywords can cause hardship for developers using the API in that language. Conflicts Messages should not include a field with the same name as the enclosing message (ignoring case transformations). This causes conflicts when generating code in some languages. Display names Many resources have a human-readable name, often used for display in UI. This field must generally be called display_name, and must not have a uniqueness requirement. If an entity has an official, formal name (such as a company name or the title of a book), an API may use title as the field name instead. The title field should not have a uniqueness requirement. Further reading For naming resource fields, see AIP-122. For naming fields representing quantities, see AIP-141. For naming fields representing time, see AIP-142. Changelog 2020-06-10: Added prohibition on starting any word with a number. 2020-05-29: Added guidance around URIs. 2020-03-24: Added guidance around conflicting field and message names. 2020-01-30: Added guidance around display_name and title.",
    'tags': '',
    'url': '/140',
  },
{
    'title': "Quantities",
    'text': "Quantities Many services need to represent a discrete quantity of items (number of bytes, number of miles, number of nodes, etc.). Guidance Quantities with a clear unit of measurement (such as bytes, miles, and so on) must include the unit of measurement as the suffix. When appropriate, units should use generally accepted abbreviations (for example, distance_km rather than distance_kilometers). // A representation of a non-stop air route. message Route { // The airport where the route begins. string origin = 1; // The destination airport. string destination = 2; // The distance between the origin and destination airports. // This value is also used to determine the credited frequent flyer miles. int32 distance_miles = 3; } If the quantity is a number of items (for example, the number of nodes in a cluster), then the field should use the suffix _count (not the prefix num_): // A cluster of individual nodes. message Cluster { // The number of nodes in the cluster. int32 node_count = 1; } Note: Fields must not use unsigned integer types, because many programming languages and systems do not support them well. Specialized messages It is sometimes useful to create a message that represents a particular quantity. This is particularly valuable in two situations: Grouping two or more individual quantities together. Example: google.protobuf.Duration Representing a common concept where the unit of measurement may itself vary. Example: google.type.Money APIs may create messages to represent quantities when appropriate. When using these messages as fields, APIs should use the name of the message as the suffix for the field name if it makes intuitive sense to do so. Changelog 2019-09-13: Added the prohibition on uint and fixed types.",
    'tags': '',
    'url': '/141',
  },
{
    'title': "Time and duration",
    'text': "Time and duration Many services need to represent the concepts surrounding time. Representing time can be challenging due to the intricacies of calendars and time zones, as well as the fact that common exchange formats (such as JSON) lack a native concept of time. Guidance Fields representing time should use the common, generally used components (such as google.protobuf.Timestamp or google.type.Date) for representing time or duration types. These types are common components, and using them consistently allows infrastructure and tooling to provide a better experience when interacting with time values. Timestamps Fields that represent an absolute point in time (independent of any time zone or calendar) should use the google.protobuf.Timestamp type, (which uses UNIX timestamps under the hood and hold nanosecond precision). These fields should have names ending in _time, such as create_time or update_time. For repeated fields, the names should end in _times instead. Many timestamp fields refer to an activity (for example, create_time refers to when the applicable resource was created). For these, the field should be named with the {imperative}_time form. For example, if a book is being published, the field storing the time when this happens would use the imperative form of the verb \"to publish\" (\"publish\") resulting in a field called publish_time. Fields should not be named using the past tense (such as published_time, created_time or last_updated_time). Durations Fields that represent a span between two points in time (independent of any time zone or calendar) should use the google.protobuf.Duration type. To illustrate the distinction between timestamps and durations, consider a flight record: // A representation of a (very incomplete) flight log. message FlightRecord { // The absolute point in time when the plane took off. google.protobuf.Timestamp takeoff_time = 1; // The length (duration) of the flight, from takeoff to landing. google.protobuf.Duration flight_duration = 2; } Note: Observant readers may notice that the timestamp and duration messages have the same structure (int64 seconds and int32 nanos). However, the distinction between these is important, because they have different semantic meaning. Additionally, tooling is able to base behavior off of which message is used. For example, a Python-based tool could convert timestamps to datetime objects and durations to timedelta objects. Relative time segments In some cases, it may be necessary to represent a time segment inside a stream. In these cases, the google.protobuf.Duration type should be used, and the field name should end with _offset. To ensure that the meaning is clear, the field must have a comment noting the point that the offset is relative to. To illustrate this, consider a resource representing a segment of an audio stream: message AudioSegment { // The duration relative to the start of the stream representing the // beginning of the segment. google.protobuf.Duration start_offset = 1; // The total length of the segment. google.protobuf.Duration segment_duration = 2; } Civil dates and times Fields that represent a calendar date or wall-clock time should use the appropriate common components: Civil date: google.type.Date Wall-clock time: google.type.TimeOfDay Fields representing civil dates should have names ending in _date, while fields representing civil times or datetimes should have names ending in _time. Note: Both the Date and TimeOfDay components are timezone-na\u00efve. Fields that require timezone-awareness should use DateTime (see below). Civil timestamps Fields that represent a civil timestamp (date and time, optionally with a time zone) should use the google.type.DateTime component, and the field name should end in _time. Compatibility Occasionally, APIs are unable to use the common structures for legacy or compatibility reasons. For example, an API may conform to a separate specification that mandates that timestamps be integers or ISO-8601 strings. In these situations, fields may use other types. If possible, the following naming conventions apply: For integers, include the meaning (examples: time, duration, delay, latency) and the unit of measurement (valid values: seconds, millis, micros, nanos) as a final suffix. For example, send_time_millis. For strings, include the meaning (examples: time, duration, delay, latency) but no unit suffix. In all cases, clearly document the expected format, and the rationale for its use.",
    'tags': '',
    'url': '/142',
  },
{
    'title': "Standardized codes",
    'text': "Standardized codes Many common concepts, such as spoken languages, countries, currency, and so on, have common codes (usually formalized by the International Organization for Standardization) that are used in data communication and processing. These codes address the issue that there are often different ways to express the same concept in written language (for example, \"United States\" and \"USA\", or \"Espa\u00f1ol\" and \"Spanish\"). Guidance For concepts where a standardized code exists and is in common use, fields representing these concepts should use the standardized code for both input and output. // A message representing a book. message Book { // Other fields... // The IETF BCP-47 language code representing the language in which // the book was originally written. // https://en.wikipedia.org/wiki/IETF_language_tag string language_code = 99; } Fields representing standardized concepts must use the appropriate data type for the standard code (usually string). Fields representing standardized concepts should not use enums, even if they only allow a small subset of possible values. Using enums in this situation often leads to frustrating lookup tables when using multiple APIs together. Fields representing standardized concepts must indicate which standard they follow, preferably with a link (either to the standard itself, the Wikipedia description, or something similar). The field name should end in _code or _type unless the concept has an obviously clearer suffix. When accepting values provided by users, validation should be case-insensitive unless this would introduce ambiguity (for example, accept both en-gb and en-GB). When providing values to users, APIs should use the canonical case (in the example above, en-GB). Content types Fields representing a content or media type must use IANA media types. For legacy reasons, the field should be called mime_type. Countries and regions Fields representing individual countries or nations must use the Unicode CLDR region codes (list), such as US or CH, and the field must be called region_code. Important: We use region_code and not country_code to include regions distinct from any country, and avoid political disputes over whether or not some regions are countries. Currency Fields representing currency must use ISO-4217 currency codes, such as USD or CHF, and the field must be called currency_code. Note: For representing an amount of money in a particular currency, rather than the currency code itself, use google.protobuf.Money. Language Fields representing spoken languages must use IETF BCP-47 language codes (list), such as en-US or de-CH, and the field must be called language_code. Time zones Fields representing a time zone should use the IANA TZ codes, and the field must be called time_zone. Fields also may represent a UTC offset rather than a time zone (note that these are subtly different). In this case, the field must use the ISO-8601 format to represent this, and the field must be named utc_offset. Changelog 2020-05-12: Replaced country_code guidance with region_code, correcting an original error.",
    'tags': '',
    'url': '/143',
  },
{
    'title': "Repeated fields",
    'text': "Repeated fields Representing lists of data in an API is trickier than it often appears. Users often need to modify lists in place, and longer data series within a single resource pose a challenge for pagination. Guidance Resources may use repeated fields where appropriate. message Book { string name = 1; repeated string authors = 2; } Repeated fields must use a plural field name. If the English singular and plural words are identical (\"moose\", \"info\"), the dictionary word must be used rather than attempting to coin a new plural form. Repeated fields should have an enforced upper bound that will not cause a single resource payload to become too large. A good rule of thumb is 100 elements. If repeated data has the chance of being too large, the API should use a sub-resource instead. Repeated fields must not represent the body of another resource inline. Instead, the message should provide the resource names of the associated resources. Scalars and messages Repeated fields should use a scalar type (such as string) if they are certain that additional data will not be needed in the future, as using a message type adds significant cognitive overhead and leads to more complicated code. However, if additional data is likely to be needed in the future, repeated fields should use a message instead of a scalar proactively, to avoid parallel repeated fields. Update strategies A resource may use two strategies to enable updating a repeated field: direct update using the standard Update method, or custom Add and Remove methods. A standard Update method has one key limitation: the user is only able to update the entire list. Field masks are unable to address individual entries in a repeated field. This means that the user must read the resource, make modifications to the repeated field value as needed, and send it back. This is fine for many situations, particularly when the repeated field is expected to have a small size (fewer than 10 or so) and race conditions are not an issue, or can be guarded against with ETags. If atomic modifications are required, the API should define custom methods using the verbs Add and Remove: rpc AddAuthor(AddAuthorRequest) returns (AddAuthorResponse) { option (google.api.http) = { post: \"/v1/{book=publishers/*/books/*}:addAuthor\" body: \"*\" }; } rpc RemoveAuthor(RemoveAuthorRequest) returns (RemoveAuthorResponse) { option (google.api.http) = { post: \"/v1/{book=publishers/*/books/*}:removeAuthor\" body: \"*\" }; } The data being added or removed should be a primitive (usually a string). For more complex data structures with a primary key, the API should use a map with the Update method instead. The HTTP verb must be POST, as is usual for custom methods. The HTTP variable should be the name of the resource (such as book) rather than name or parent. If the data being added in an Add RPC is already present, the method must error with ALREADY_EXISTS. If the data being removed in a Remove RPC is not present, the method must error with NOT_FOUND. Note: If both of these strategies are too restrictive, consider using a subresource instead.",
    'tags': '',
    'url': '/144',
  },
{
    'title': "Ranges",
    'text': "Ranges Services often need to represent ranges of discrete or continuous values. These have wide differences in meaning, and come in many types: integers, floats, and timestamps, just to name a few, and the expected meaning of a range can vary in subtle ways depending on the type of range being discussed. Guidance A resource or message representing a range should ordinarily use two separate fields of the same type, with prefixes start_ and end_: // A representation of a chapter in a book. message Chapter { string title = 1; // The page where this chapter begins. int32 start_page = 2; // The page where the next chapter or section begins. int32 end_page = 3; } Inclusive or exclusive ranges Fields representing ranges should use inclusive start values and exclusive end values (half-closed intervals) in most situations; in interval notation: [start_xxx, end_xxx). Exclusive end values are preferable for the following reasons: It conforms to user expectations, particularly for continuous values such as timestamps, and avoids the need to express imprecise \"limit values\" (e.g. 2012-04-20T23:59:59). It is consistent with most common programming languages, including C++, Java, Python, and Go. It is easier to reason about abutting ranges: [0, x), [x, y), [y, z), where values are chainable from one range to the next. Exceptions In some cases, there is significant colloquial precedent for inclusive start and end values (closed intervals), to the point that using an exclusive end value would be confusing even for people accustomed to them. For example, when discussing dates (not to be confused with timestamps), most people use inclusive end: a conference with dates \"April 21-23\" is expected to run for three days: April 21, April 22, and April 23. This is also true for days of the week: a business that is open \"Monday through Friday\" is open, not closed, on Fridays. In this situation, the prefixes first and last should be used instead: // A representation of a chapter in a book. message Chapter { string title = 1; // The first page of the chapter. int32 first_page = 2; // The last page of the chapter. int32 last_page = 3; } Fields representing ranges with significant colloquial precedent for inclusive start and end values should use inclusive end values with first_ and last_ prefixes for those ranges only. The service should still use exclusive end values for other ranges where this does not apply, and must clearly document each range as inclusive or exclusive.",
    'tags': '',
    'url': '/145',
  },
{
    'title': "Generic fields",
    'text': "Generic fields Most fields in any API, whether in a request, a resource, or a custom response, have a specific type or schema. This schema is part of the contract that developers write their code against. However, occasionally it is appropriate to have a generic or polymorphic field of some kind that can conform to multiple schemata, or even be entirely free-form. Guidance While generic fields are generally rare, a service may introduce generic field where necessary. There are several approaches to this depending on how generic the field needs to be; in general, services should attempt to introduce the \"least generic\" approach that is able to satisfy the use case. Oneof A oneof may be used to introduce a type union: the user or service is able to specify one of the fields inside the oneof. Additionally, a oneof may be used with the same type (usually strings) to represent a semantic difference between the options. Because the individual fields in the oneof have different keys, a developer can programmatically determine which (if any) of the fields is populated. A oneof preserves the largest degree of type safety and semantic meaning for each option, and services should generally prefer them over other generic or polymorphic options when feasible. However, the oneof construct is ill-suited when there is a large (or unlimited) number of potential options, or when there is a large resource structure that would require a long series of \"cascading oneofs\". Note: Adding additional possible fields to an existing oneof is a non-breaking change, but moving existing fields into or out of a oneof is breaking (it creates a backwards-incompatible change in Go protobuf stubs). Maps Maps may be used in situations where a situation where many values of the same type are needed, but the keys are unknown or user-determined. Maps are usually not appropriate for generic fields because the map values all share a type, but occasionally they are useful. In particular, a map can sometimes be suited to a situation where many objects of the same type are needed, with different behavior based on the names of their keys (for example, using keys as environment names). Struct The [google.protobuf.Struct][] object may be used to represent arbitrary nested JSON. Keys can be strings, and values can be floats, strings, booleans, arrays, or additional nested structs, allowing for an arbitrarily nested structure that can be represented as JSON (and is automatically represented as JSON when using REST/JSON). A Struct is most useful when the service does not know the schema in advance, or when a service needs to store and retrieve arbitrary but structured user data. Using a Struct is convenient for users in this case because they can easily get JSON objects that can be natively manipulated in their environment of choice. If a service needs to reason about the schema of a Struct, it should use JSONSchema for this purpose. Because JSONSchema is itself JSON, a valid JSONSchema document can itself be stored in a Struct. Any The [google.protobuf.Any][] object can be used to send an arbitrary serialized protocol buffer and a type definition. However, this introduces complexity, because an Any becomes useless for any task other than blind data propagation if the consumer does not have access to the proto. Additionally, even if the consumer does have the proto, the consumer has to ensure the type is registered and then deserialize manually, which is an often-unfamiliar process. Because of this, Any should not be used unless other options are infeasible.",
    'tags': '',
    'url': '/146',
  },
{
    'title': "Long-running operations",
    'text': "Long-running operations Occasionally, an API may need to expose a method that takes a significant amount of time to complete. In these situations, it is often a poor user experience to simply block while the task runs; rather, it is better to return some kind of promise to the user and allow the user to check back in later. The long-running operations pattern is roughly analogous to a [Python Future][], or a [Node.js Promise][]. Essentially, the user is given a token that can be used to track progress and retrieve the result. Guidance Individual API methods that might take a significant amount of time to complete should return a google.longrunning.Operation object instead of the ultimate response message. // Write a book. rpc WriteBook(WriteBookRequest) returns (google.longrunning.Operation) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books}:write\" body: \"*\" }; option (google.longrunning.operation_info) = { response_type: \"WriteBookResponse\" metadata_type: \"WriteBookMetadata\" }; } The response type must be google.longrunning.Operation. The Operation proto definition must not be copied into individual APIs. The method must include a google.longrunning.operation_info annotation, which must define both response and metadata types. The response and metadata types must be defined in the file where the RPC appears, or a file imported by that file. If the response and metadata types are defined in another package, the fully-qualified message name must be used. The response type should not be google.protobuf.Empty (except for Delete methods), unless it is certain that response data will never be needed. If response data might be added in the future, define an empty message for the RPC response and use that. The metadata type is used to provide information such as progress, partial failures, and similar information on each GetOperation call. The metadata type should not be google.protobuf.Empty, unless it is certain that metadata will never be needed. If metadata might be added in the future, define an empty message for the RPC metadata and use that. APIs with messages that return Operation must implement the Operations service. Individual APIs must not define their own interfaces for long-running operations to avoid inconsistency. Note: User expectations can vary on what is considered \"a significant amount of time\" depending on what work is being done. A good rule of thumb is 10 seconds. Standard methods APIs may return an Operation from the Create, Update, or Delete standard methods if appropriate. In this case, the response type in the operation_info annotation must be the standard and expected response type for that standard method. When creating or deleting a resource with a long-running operation, the resource should be included in List and Get calls; however, the resource should indicate that it is not usable, generally with a state enum. Parallel operations A resource may accept multiple operations that will work on it in parallel, but is not obligated to do so: Resources that accept multiple parallel operations may place them in a queue rather than work on the operations simultaneously. Resource that does not permit multiple operations in parallel (denying any new operation until the one that is in progress finishes) must return ABORTED if a user attempts a parallel operation, and include an error message explaining the situation. Expiration APIs may allow their operation resources to expire after sufficient time has elapsed after the operation completed. Note: A good rule of thumb for operation expiry is 30 days. Errors Errors that prevent a long-running operation from starting must return an error response (AIP-193), similar to any other method. Errors that occur over the course of an operation may be placed in the metadata message. The errors themselves must still be represented with a [google.rpc.Status][] object. Changelog 2020-06-24: Added guidance for parallel operations. 2020-03-20: Clarified that both response_type and metadata_type are required. 2019-11-22: Added a short explanation of what metadata_type is for. 2019-09-23: Added guidance on errors. 2019-08-23: Added guidance about fully-qualified message names when the message name is in another package. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/151',
  },
{
    'title': "Jobs",
    'text': "Jobs Occasionally, APIs may need to expose a task that takes significant time to complete, and where a transient long-running operation is not appropriate. For example, a task could need to run repeatedly, or have separate permissions for configuring the task as opposed to running it. Guidance An API may define a Job resource to represent a particular task with distinct setup, configuration, and execution: message WriteBookJob { // The resource name for the writing job. string name = 1 [(google.api.resource) = { type: \"library.googleapis.com/WriteBookJob\" pattern: \"publishers/{publisher}/writeBookJobs/{write_book_job}\" }]; // Additional configuration... } The name of the resource must end with the word \"Job\". The prefix should be a valid RPC name, with a verb and a noun. The service should define all five of the standard methods (AIP-131, AIP-132, AIP-133, AIP-134, AIP-135), and use them as the primary way to configure the job. Run method The service should define a Run custom method that executes the job immediately: rpc RunWriteBookJob(RunWriteBookJobRequest) returns (google.longrunning.Operation) { option (google.api.http) = { post: \"/v1/{name=publishers/*/writingJobs/*}:run\" body: \"*\" } option (google.longrunning.operation_info) = { response_type: \"RunWriteBookJobResponse\" metadata_type: \"RunWriteBookJobMetadata\" } } The HTTP method must be POST. The method should return a long-running operation, which must resolve to a response message that includes the result of running the job. The method may use any metadata message it wishes. Errors that prevent execution of the job from starting must return an error response (AIP-193), similar to any other method. Errors that occur over the course of the job execution may be placed in the metadata message. The errors themselves must still be represented with a [google.rpc.Status][] object. Executions and results Ordinarily, the API should provide results to the user as the final response of the Run method. However, this is sometimes insufficient; for example, a job that runs on a recurring schedule in the background can not deliver results to the user in this way. The service may store resources representing individual executions along with their result as a sub-collection of resources under the job, which allows the user to list past job executions. A service that does this should define the Get, List, and Delete methods for the execution resources: message WriteBookJobExecution { option (google.api.resource) = { type: \"library.googleapis.com/WriteBookJobExecution\" pattern: \"publishers/{publisher}/writeBookJobs/{write_book_job}/executions/{execution}\" }; string name = 1; // Other information about the execution, such as metadata, the result, // error information, etc. } In this case, the operation returned by job\u0027s Run method should refer to the child resource.",
    'tags': '',
    'url': '/152',
  },
{
    'title': "Import and export",
    'text': "Import and export Many users want to be able to load data into an API, or get their existing data out of an API. This is particularly important for enterprise users, who are often concerned about vendor lock. Guidance APIs may support import and export operations, which may create multiple new resources, or they may populate data into a single resource. Multiple resources Services may support importing and exporting multiple resources into or out of an API, and should implement a common pattern to do so: rpc ImportBooks(ImportBooksRequest) returns (google.longrunning.Operation) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books:import\" body: \"*\" }; option (google.longrunning.operation_info) = { response_type: \"ImportBooksResponse\" metadata_type: \"ImportBooksMetadata\" }; } rpc ExportBooks(ExportBooksRequest) returns (google.longrunning.Operation) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books:export\" body: \"*\" }; option (google.longrunning.operation_info) = { response_type: \"ExportBooksResponse\" metadata_type: \"ExportBooksMetadata\" }; } The method must return a long-running operation (see AIP-151) unless the service can guarantee that it will never need more than a few seconds to complete. The HTTP verb must be POST, and the body must be \"*\". A parent field should be included as part of the URI. If importing into or exporting from multiple resources is required, the API should keep the parent field and allow the user to use the - character to indicate multiple parents (see AIP-159). On import, if the user provides a specific parent, the API must reject any imported resources that would be added to a different parent. The URI suffix should be :import or :export. Data for a single resource Services may support importing and exporting data into or out of a single resource, and should implement a common pattern to do so: rpc ImportPages(ImportPagesRequest) returns (google.longrunning.Operation) { option (google.api.http) = { post: \"/v1/{book=publishers/*/books/*}:importPages\" body: \"*\" }; option (google.longrunning.operation_info) = { response_type: \"ImportPagesResponse\" metadata_type: \"ImportPagesMetadata\" }; } rpc ExportPages(ExportPagesRequest) returns (google.longrunning.Operation) { option (google.api.http) = { post: \"/v1/{book=publishers/*/books/*}:exportPages\" body: \"*\" }; option (google.longrunning.operation_info) = { response_type: \"ExportPagesResponse\" metadata_type: \"ExportPagesMetadata\" }; } The method must return a long-running operation (see AIP-151) unless the service can guarantee that it will never need more than a few seconds to complete. The HTTP verb must be POST, and the body must be \"*\". A field representing the resource that data is being imported into should be included as part of the URI. The field should be named after the resource (and should not be called name). The URI suffix should include both the verb and a noun for the data itself, such as :importPages or :exportPages. Request object Imports and exports often require two fundamentally different types of configuration: Configuration specific to the source or destination. Configuration regarding the imported or exported data itself. Source or destination configuration should be grouped into a single message and placed inside a oneof: message ImportBooksRequest { string parent = 1; oneof source { AuthorSource author_source = 2; TranslatorSource translator_source = 3; } string isbn_prefix = 4; } message ExportBooksRequest { string parent = 1; oneof destination { PrinterDestination printer_destination = 2; TranslatorDestination translator_destination = 3; } string filter = 4; } The source configuration messages must be placed within a oneof source (for import) or oneof destination (for export), even if there is only one. (This maintains flexibility to add more later.) Configuration related to the data itself (and therefore common across all sources) must be placed at the top-level of the request message. Note: The configuration for import and export may be different from one another. (For example, it would be sensible to import from a file but export to a directory.) Inline sources APIs may also permit import and export \"inline\", where the contents to be imported or exported are provided in the request or response. message InlineSource { repeated Book books = 1; } The source or destination should be named InlineSource or InlineDestination. The message should include a repeated field representing the resource. However, if the resource structure is complex, the API may use a separate inline representation. In this situation, the same format must be used for both import and export. Partial failures While partial failures are normally discouraged, import and export RPCs should include partial failure information in the metadata object. Each individual error should be a google.rpc.Status object describing the error. For more on errors, see AIP-193.",
    'tags': '',
    'url': '/153',
  },
{
    'title': "Resource freshness validation",
    'text': "Resource freshness validation APIs often need to validate that a client and server agree on the current state of a resource before taking some kind of action on that resource. For example, two processes updating the same resource in parallel could create a race condition, where the latter process \"stomps over\" the effort of the former one. ETags provide a way to deal with this, by allowing the server to send a checksum based on the current content of a resource; when the client sends that checksum back, the server can ensure that the checksums match before acting on the request. Guidance A resource may include an etag field on any resource where it is important to ensure that the client has an up to date resource before acting on certain requests: // A representation of a book. message Book { // Other fields... // This checksum is computed by the server based on the value of other // fields, and may be sent on update and delete requests to ensure the // client has an up-to-date value before proceeding. string etag = 99; } The etag field must be a string, and must be named etag. The etag field should not be given any behavior annotations The etag field must be provided by the server on output, and values should conform to RFC 7232. If a user sends back an etag which matches the current etag value, the service must permit the request (unless there is some other reason for failure). If a user sends back an etag which does not match the current etag value, the service must send a FAILED_PRECONDITION error response. If the user does not send an etag value at all, the service should permit the request. However, services with strong consistency or parallelism requirements may require users to send etags all the time and reject the request with an INVALID_ARGUMENT error in this case. Note: ETag values should include quotes as described in RFC 7232. For example, a valid etag is \"foo\", not foo. Strong and weak etags ETags can be either \"strongly validated\" or \"weakly validated\": A strongly validated etag means that two resources bearing the same etag are byte-for-byte identical. A weakly validated etag means that two resources bearing the same etag are equivalent, but may differ in ways that the service does not consider to be important. Resources may use either strong or weak etags, as it sees fit, but should document the behavior. Additionally, weak etags must have a W/ prefix as mandated by RFC 7232. Further reading For how to retry errors in client libraries, see Changelog 2019-09-23: Changed the title to \"resource freshness validation\".",
    'tags': '',
    'url': '/154',
  },
{
    'title': "Request identification",
    'text': "Request identification It is sometimes useful for an API to have a unique, customer-provided identifier for particular requests. This can be useful for several purposes, such as de-duplicating requests from parallel processes, ensuring the safety of retries, or auditing. The most important purpose for request IDs is to provide idempotency guarantees: allowing the same request to be issued more than once without subsequent calls having any effect. In the event of a network failure, the client can retry the request, and the server can detect duplication and ensure that the request is only processed once. Guidance APIs may add a string request_id parameter to request messages (including those of standard methods) in order to uniquely identify particular requests. message CreateBookRequest { // The parent resource where this book will be created. // Format: publishers/{publisher} string parent = 1; // The book to create. Book book = 2; // A unique identifier for this request. Restricted to 36 ASCII characters. // A random UUID is recommended. // This request is only idempotent if a `request_id` is provided. string request_id = 3; } Providing a request ID must guarantee idempotency. If a duplicate request is detected, the server should return the response for the previously successful request, because the client most likely did not receive the previous response. APIs may choose any reasonable timeframe for honoring request IDs. The request_id field must be provided on the request message to which it applies (and it must not be a field on resources themselves). Request IDs should be optional. Request IDs should be able to be UUIDs, and may allow UUIDs to be the only valid format. The format restrictions for request IDs must be documented. Stale success responses In some unusual situations, it may not be possible to return an identical success response. For example, a duplicate request to create a resource may arrive after the resource has not only been created, but subsequently updated; because the service has no other need to retain the historical data, it is no longer feasible to return an identical success response. In this situation, the method may return the current state of the resource instead. In other words, it is permissible to substitute the historical success response with a similar response that reflects more current data. Further reading For which codes to retry, see AIP-194. For how to retry errors in client libraries, see AIP-4221. Changelog 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/155',
  },
{
    'title': "Singleton resources",
    'text': "Singleton resources APIs sometimes need to represent a resource where exactly one instance of the resource always exists within any given parent. A common use case for this is for a settings object. Guidance An API may define singleton resources. A singleton resource must always exist by virtue of the existence of its parent, with one and exactly one per parent. rpc GetSettings(GetSettingsRequest) returns (Settings) { option (google.api.http) = { get: \"/v1/{name=users/*/settings}\" }; } rpc UpdateSettings(UpdateSettingsRequest) returns (Settings) { option (google.api.http) = { patch: \"/v1/{settings.name=users/*/settings}\" body: \"settings\" }; } Singleton resources must not have a user-provided or system-generated ID; their resource name includes the name of their parent followed by one static-segment. Example: users/1234/settings Singleton resources must not define the Create, List, or Delete standard methods. The singleton is implicitly created or deleted when its parent is created or deleted. Singleton resource should define the Get and Update methods, and may define custom methods as appropriate.",
    'tags': '',
    'url': '/156',
  },
{
    'title': "Partial responses",
    'text': "Partial responses Sometimes, a resource can be either large or expensive to compute, and the API needs to give the user control over which fields it sends back. Guidance APIs may support partial responses in one of two ways (but the same API must not use both): View enumeration View enums are useful for situations where an API only wants to expose a small number of permutations to the user: enum BookView { // The default / unset value. // The API will default to the BASIC view. BOOK_VIEW_UNSPECIFIED = 0; // Include basic metadata about the book, but not the full contents. // This is the default value (for both ListBooks and GetBook). BASIC = 1; // Include everything. FULL = 2; } The enum should be specified as a view field on List/Get RPC requests. The enum should be named something ending in -View The enum should at minimum have values named BASIC and FULL (although it may have values other than these). The UNSPECIFIED value must be valid (not an error), and the API must document what the unspecified value will do). For List RPCs, the effective default value should be BASIC. For Get RPCs, the effective default value should be either BASIC or FULL. The enum should be defined at the top level of the proto file (as it is needed in both the Get and List request). APIs may add fields to a given view over time. APIs must not remove a field from a given view (this is a breaking change). Read masks Read masks are useful for granting the user fine-grained control over what fields are returned, and are specified as a single field on the request message: google.protobuf.FieldMask read_mask. The field mask must be a google.protobuf.FieldMask and should be named read_mask. The field mask should be optional, and the API should provide and document an appropriate default if the field mask is not provided. An explicit value of \"*\" should be supported, and must return all fields. The default value may be something other than \"*\" (for example, if certain fields are expensive to compute and it is preferable to exclude them by default). The field mask may be designated as required if necessary. The default for List and Get may be different from each other. However, if they are, the default for Get must be a (non-strict) superset of the default for List. An API may allow read masks with non-terminal repeated fields (unlike update masks), but is not obligated to do so. Choosing a strategy Individual APIs have their own needs, and a partial response strategy that is appropriate for one API may not be appropriate for another. However, generally APIs should not be providing resource views unless they are truly needed. Benefits of view enums View enums allow an API to present the user with a limited number of choices, and are useful when presenting fine-grained control will be cumbersome, or in situations where the additional information returned represents a different tier of service. View enums allow the API to add fields to each view over time, if desired. View enums usually require less upkeep for users. View enums are effective when the API knows which fields are expensive to compute, and that this cost will not significantly change over time. Benefits of read masks Read masks allow the user fine-grained control, and are ideal when the user wants to get precisely a certain set of fields back, and there are too many combinations to reasonably represent with view enums. Read masks are beneficial when separate fields are independently expensive to compute, and an API wants to send back only the subset that the user needs. Note: If an API requires partial responses, it should generally decide to either support view enums or read masks across the board, but not mix and match. If an API does support both, it must not support both a view and a read mask on the same resource.",
    'tags': '',
    'url': '/157',
  },
{
    'title': "Pagination",
    'text': "Pagination APIs often need to provide collections of data, most commonly in the List standard method. However, collections can often be arbitrarily sized, and also often grow over time, increasing lookup time as well as the size of the responses being sent over the wire. Therefore, it is important that collections be paginated. Guidance RPCs returning collections of data must provide pagination at the outset, as it is a backwards-incompatible change to add pagination to an existing method. // The request structure for listing books. message ListBooksRequest { // The parent, which owns this collection of books. // Format: publishers/{publisher} string parent = 1; // The maximum number of books to return. The service may return fewer than // this value. // If unspecified, at most 50 books will be returned. // The maximum value is 1000; values above 1000 will be coerced to 1000. int32 page_size = 2; // A page token, received from a previous `ListBooks` call. // Provide this to retrieve the subsequent page. // // When paginating, all other parameters provided to `ListBooks` must match // the call that provided the page token. string page_token = 3; } // The response structure from listing books. message ListBooksResponse { // The books from the specified publisher. repeated Book books = 1; // A token that can be sent as `page_token` to retrieve the next page. // If this field is omitted, there are no subsequent pages. string next_page_token = 2; } Request messages for collections should define an int32 page_size field, allowing users to specify the maximum number of results to return. If the user does not specify page_size (or specifies 0), the API chooses an appropriate default, which the API should document. The API must not return an error. If the user specifies page_size greater than the maximum permitted by the API, the API should coerce down to the maximum permitted page size. If the user specifies a negative value for page_size, the API must send an INVALID_ARGUMENT error. The API may return fewer results than the number requested (including zero results), even if not at the end of the collection. Request messages for collections should define a string page_token field, allowing users to advance to the next page in the collection. If the user changes the page_size in a request for subsequent pages, the service must honor the new page size. The user is expected to keep all other arguments to the RPC the same; if any arguments are different, the API should send an INVALID_ARGUMENT error. Response messages for collections should define a string next_page_token field, providing the user with a page token that may be used to retrieve the next page. The field containing pagination results should be the first field in the message and have a field number of 1. It should be a repeated field containing a list of resources constituting a single page of results. If the end of the collection has been reached, the next_page_token field must be empty. This is the only way to communicate \"end-of-collection\" to users. If the end of the collection has not been reached (or if the API can not determine in time), the API must provide a next_page_token. Response messages for collections may provide an int32 total_size field, providing the user with the total number of items in the list. This total may be an estimate (but the API should explicitly document that). Opacity Page tokens provided by APIs must be opaque (but URL-safe) strings, and must not be user-parseable. This is because if users are able to deconstruct these, they will do so. This effectively makes the implementation details of your API\u0027s pagination become part of the API surface, and it becomes impossible to update those details without breaking users. Warning: Base-64 encoding an otherwise-transparent page token is not a sufficient obfuscation mechanism. For page tokens which do not need to be stored in a database, and which do not contain sensitive data, an API may obfuscate the page token by defining an internal protocol buffer message with any data needed, and send the serialized proto, base-64 encoded. Expiring page tokens Many APIs store page tokens in a database internally. In this situation, APIs may expire page tokens a reasonable time after they have been sent, in order not to needlessly store large amounts of data that is unlikely to be used. It is not necessary to document this behavior. Note: While a reasonable time may vary between APIs, a good rule of thumb is three days. Backwards compatibility Adding pagination to an existing RPC is a backwards-incompatible change. This may seem strange; adding fields to proto messages is generally backwards compatible. However, this change is behaviorally incompatible. Consider a user whose collection has 75 resources, and who has already written and deployed code. If the API later adds pagination fields, and sets the default to 50, then that user\u0027s code breaks; it was getting all resources, and now is only getting the first 50 (and does not know to advance pagination). Even if the API set a higher default limit, such as 100, the user\u0027s collection could grow, and then the code would break. For this reason, it is important to always add pagination to RPCs returning collections up front; they are consistently important, and they can not be added later without causing problems for existing users. Warning: This also entails that, in addition to presenting the pagination fields, they must be actually implemented with a non-infinite default value. Implementing an in-memory version (which might fetch everything then paginate) is reasonable for initially-small collections. Changelog 2020-06-24: Clarified that page size is always optional for users. 2019-02-12: Added guidance on the field being paginated over. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership. 2019-07-19: Update the opacity requirement from \"should\" to \"must\".",
    'tags': '',
    'url': '/158',
  },
{
    'title': "Reading across collections",
    'text': "Reading across collections Sometimes, it is useful for a user to be able to retrieve resources across multiple collections, or retrieve a single resource without needing to know what collection it is in. Guidance APIs may support reading resources across multiple collections by allowing users to specify a - (the hyphen or dash character) as a wildcard character in a standard List method: GET /v1/publishers/-/books?filter=... The URL pattern must still be specified with * and permit the collection to be specified; a URL pattern must not hard-code the - character. The method must explicitly document that this behavior is supported. The resources provided in the response must use the canonical name of the resource, with the actual parent collection identifiers (instead of -). Services may support reading across collections on List requests regardless of whether the identifiers of the child resources are guaranteed to be unique. However, services must not support reading across collections on Get requests if the child resources might have a collision. Cross-parent requests should not support order_by. If they do, the field must document that it is best effort. This is because cross-parent requests introduce ambiguity around ordering, especially if there is difficulty reaching a parent (see AIP-217). Important: If listing across multiple collections introduces the possibility of partial failures due to unreachable parents (such as when listing across locations), the method must indicate this following the guidance in AIP-217. Unique resource lookup Sometimes, a resource within a sub-collection has an identifier that is unique across parent collections. In this case, it may be useful to allow a Get method to retrieve that resource without knowing which parent collection contains it. In such cases, APIs may allow users to specify the wildcard collection ID - (the hyphen or dash character) to represent any parent collection: GET https://example.googleapis.com/v1/publishers/-/books/{book} The URL pattern must still be specified with * and permit the collection to be specified; a URL pattern must not hard-code the - character. The method must explicitly document that this behavior is supported. The resource name in the response must use the canonical name of the resource, with actual parent collection identifiers (instead of -). For example, the request above returns a resource with a name like publishers/123/books/456, not publishers/-/books/456. The resource ID must be unique within parent collections. Further reading For partial failures due to unreachable resources, see AIP-217. Changelog 2019-08-26: Added a reference to guidance for unreachable resources. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/159',
  },
{
    'title': "Filtering",
    'text': "Filtering Often, when listing resources (using a list method as defined in AIP-132 or something reasonably similar), it is desirable to filter over the collection and only return results that the user is interested in. It is tempting to define a structure to handle the precise filtering needs for each API. However, filtering requirements evolve frequently, and therefore it is prudent to use a string field with a structured syntax accessible to a non-technical audience. This allows updates to be able to be made transparently, without waiting for UI or client updates. Note: Because list filters are intended for a potentially non-technical audience, they sometimes borrow from patterns of colloquial speech rather than common patterns found in code. Guidance APIs may provide filtering to users on List methods (or similar methods to query a collection, such as Search). If they choose to do so, they should follow the common specification for filters discussed here. The syntax is formally defined in the EBNF grammar. When employing filtering, a request message should have exactly one filtering field, string filter. Filtering of related objects is handled through traversal or functions. Note: List Filters have fuzzy matching characteristics with support for result ranking and scoring. For developers interested in deterministic evaluation of list filters, see CEL. Literals A bare literal value (examples: \"42\", \"Hugo\") is a value to be matched against. Literals appearing alone (with no specified field) should usually be matched anywhere it may appear in an object\u0027s field values. However, a service may choose to only consider certain fields; if so, it must document which fields it considers. A service may include new fields over time, but should do so judiciously and consider impact on existing users. Note: Literals separated by whitespace are considered to have a fuzzy variant of AND. Therefore, Victor Hugo is roughly equivalent to Victor AND Hugo. Logical Operators Filtering implementations should provide the binary operators: | Operator | Example | Meaning | | -------- | ------------- | -------------------------------------- | | AND | a AND b | True if a and b are true. | | OR | a OR b OR c | True if any of a, b, c are true. | Note: To match common patterns of speech, the OR operator has higher precedence than AND, unlike what is found in most programming languages. The expression a AND b OR c evaluates: a AND (b OR c). API documentation and examples should encourage the use of explicit parentheses to avoid confusion, but should not require explicit parentheses. Negation Operators Filtering implementations should provide the unary operators NOT and -. These are used interchangeably, and a service that supports negation must support both formats. | Operator | Example | Meaning | | -------- | ------- | ------------------------ | | NOT | NOT a | True if a is not true. | | - | -a | True if a is not true. | Comparison Operators Filtering implementations should provide the binary comparison operators =, !=, \u003c, \u003e, \u003c=, and \u003e= for string, numeric, timestamp, and duration fields (but should not provide them for booleans or enums). | Operator | Example | Meaning | | -------- | ------------ | ----------------------------------------------- | | = | a = true | True if a is true. | | != | a != 42 | True unless a equals 42. | | \u003c | a \u003c 42 | True if a is a numeric value below 42. | | \u003e | a \u003e \"foo\" | True if a is lexically ordered after \"foo\". | | \u003c= | a \u003c= \"foo\" | True if a is \"foo\" or lexically before it. | | \u003e= | a \u003e= 42 | True if a is a numeric value of 42 or higher. | Note: Unlike in most programming languages, field names must appear on the left-hand side of a comparison operator; the right-hand side only accepts literals and logical operators. Because filters are accepted as query strings, type conversion takes place to translate the string to the appropriate strongly-typed value: Enums expect the enum\u0027s string representation (case-sensitive). Booleans expect true and false literal values. Numbers expect the standard integer or float representations. For floats, exponents are supported (e.g. 2.997e9). Durations expect a numeric representation followed by an s suffix (for seconds). Examples: 20s, 1.2s. Timestamps expect an RFC-3339 formatted string (e.g. 2012-04-21T11:30:00-04:00). UTC offsets are supported. Warning: The identifiers true, false, and null only carry intrinsic meaning when used in the context of a typed field reference. Additionally, when comparing strings for equality, services should support wildcards using the * character; for example, a = \"*.foo\" is true if a ends with \".foo\". Traversal operator Filtering implementations should provide the . operator, which indicates traversal through a message, map, or struct. | Example | Meaning | | --------------- | ----------------------------------------------------- | | a.b = true | True if a has a boolean b field that is true. | | a.b \u003e 42 | True if a has a numeric b field that is above 42. | | a.b.c = \"foo\" | True if a.b has a string c field that is \"foo\". | Traversal must be written using the field names from the resource. If a service wishes to support \"implicit fields\" of some kind, they must do so through well-documented functions. A service may specify a subset of fields that are supported for traversal. If a user attempts to traverse to a field that is not defined on the message, the service should return an error with INVALID_ARGUMENT. A service may permit traversal to undefined keys on maps and structs, and should document how it behaves in this situation. Important: The . operator must not be used to traverse through a repeated field or list, except for specific use with the : operator. Has Operator Filtering implementations must provide the : operator, which means \"has\". It is usable with collections (repeated fields or maps) as well as messages, and behaves slightly differently in each case. Repeated fields query to see if the repeated structure contains a matching element: | Example | Meaning | | ---------- | ----------------------------------------------------------- | | r:42 | True if r contains 42. | | r.foo:42 | True if r contains an element e such that e.foo = 42. | Important: Filters can not query a specific element on a repeated field for a value. For example, e.0.foo = 42 and e[0].foo = 42 are not valid filters. Maps, structs, messages can query either for the presence of a field in the map or a specific value: | Example | Meaning | | ---------- | ----------------------------------- | | m:foo | True if m contains the key \"foo\". | | m.foo:* | True if m contains the key \"foo\". | | m.foo:42 | True if m.foo is 42. | There are two slight distinctions when parsing messages: When traversing messages, a field is only considered to be present if it has a non-default value. When traversing messages, field names are snake case, although implementations may choose to support automatic conversion between camel case and snake case. Functions The filtering language supports a function call syntax in order to support API-specific extensions. An API may define a function using the call(arg...) syntax, and must document any specific functions it supports. Limitations A service may specify further structure or limitations for filter queries, above what is defined here. For example, a service may support the logical operators but only permit a certain number of them (to avoid \"queries of death\" or other performance concerns). Further structure or limitations must be clearly documented, must not violate requirements set forth in this document, and a non-compliant filter query must error with INVALID_ARGUMENT.",
    'tags': '',
    'url': '/160',
  },
{
    'title': "Resource Revisions",
    'text': "Resource Revisions Some APIs need to have resources with a revision history, where users can reason about the state of the resource over time. There are several reasons for this: Users may want to be able to roll back to a previous revision, or diff against a previous revision. An API may create data which is derived in some way from a resource at a given point in time. In these cases, it may be desirable to snapshot the resource for reference later. Note: We use the word revision to refer to a historical reference for a particular resource, and intentionally avoid the term version, which refers to the version of an API as a whole. Guidance APIs may store a revision history for a resource if it is useful to users. APIs implementing resources with a revision history must provide a revision_id field on the resource: message Book { // The name of the book. string name = 1; // Other fields\u2026 // The revision ID of the book. // A new revision is committed whenever the book is changed in any way. // The format is an 8-character hexadecimal string. string revision_id = 5 [ (google.api.field_behavior) = IMMUTABLE, (google.api.field_behavior) = OUTPUT_ONLY]; // The timestamp that the revision was created. google.protobuf.Timestamp revision_create_time = 6 [(google.api.field_behavior) = OUTPUT_ONLY]; } The resource must contain a revision_id field, which should be a string and contain a short, automatically-generated random string. A good rule of thumb is the last eight characters of a UUID4. The revision_id field must document when new revisions are created (see committing revisions below). The revision_id field should document the format of revision IDs. The resource must contain a revision_create_time field, which should be a google.protobuf.Timestamp (see AIP-142). Note: A randomly generated string is preferred over other methods, such as an auto-incrementing integer, because there is often a need to delete or revert revisions, and a randomly generated string holds up better in those situations. Referencing revisions When it is necessary to refer to a specific revision of a resource, APIs must use the following syntax: {resource_name}@{revision_id}. For example: publishers/123/books/les-miserables@c7cfa2a8 Note: The @ character is selected because it is the only character permitted by RFC 1738 \u00a72.2 for special meaning within a URI scheme that is not already used elsewhere. APIs should generally accept a resource reference at a particular revision in any place where they ordinarily accept the resource name. However, they must not accept a revision in situations that mutate the resource, and should error with INVALID_ARGUMENT if one is given. Important: APIs must not require a revision ID, and must default to the current revision if one is not provided, except in methods specifically dealing with the revision history (such as rollback) where failing to require it would not make sense (or lead to dangerous mistakes). Getting a revision APIs implementing resource revisions should accept a resource name with a revision ID in the standard Get method (AIP-131): message GetBookRequest { // The name of the book. // Example: publishers/123/books/les-miserables // // In order to retrieve a previous revision of the book, also provide // the revision ID. // Example: publishers/123/books/les-miserables@c7cfa2a8 string name = 1; } If the user passes a revision ID that does not exist, the API must fail with a NOT_FOUND error. APIs must return a name value corresponding to what the user sent. If the user sent a name with no revision ID, the returned name string must not include the revision ID either. Similarly, if the user sent a name with a revision ID, the returned name string must explicitly include it. Tagging revisions APIs implementing resource revisions may provide a mechanism for users to tag a specific revision with a user provided name by implementing a \"Tag Revision\" custom method: rpc TagBookRevision(TagBookRevisionRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{name=publishers/*/books/*}:tagRevision\" body: \"*\" } } message TagBookRevisionRequest { // The name of the book to be tagged, including the revision ID. string name = 1; // The tag to apply. // The tag should be at most 40 characters, and match `[a-z][a-z0-9-]{3,39}`. string tag = 2; } The name field should require an explicit revision ID to be provided. Once a revision is tagged, the API must support using the tag in place of the revision ID in name fields. If the user sends a tag, the API must return the tag in the resource\u0027s name field, but the revision ID in the resource\u0027s revision_id field. If the user sends a revision ID, the API must return the revision ID in both the name field and the revision_id field. If the user calls the Tag method with an existing tag, the request must succeed and the tag updated to point to the new requested revision ID. This allows users to write code against specific tags (e.g. published) and the revision can change in the background with no code change. Listing revisions APIs implementing resource revisions should provide a custom method for listing the revision history for a resource, with a structure similar to standard List methods (AIP-132): rpc ListBookRevisions(ListBookRevisionsRequest) returns (ListBookRevisionsResponse) { option (google.api.http) = { get: \"/v1/{name=publishers/*/books/*}:listRevisions\" } } message ListBookRevisionsRequest { // The name of the book to list revisions for. string name = 1; // The maximum number of revisions to return per page. int32 page_size = 2; // The page token, received from a previous ListBookRevisions call. // Provide this to retrieve the subsequent page. string page_token = 3; } message ListBookRevisionsResponse { // The revisions of the book. repeated Book books = 1; // A token that can be sent as `page_token` to retrieve the next page. // If this field is omitted, there are no subsequent pages. string next_page_token = 2; } While revision listing methods are mostly similar to standard List methods (AIP-132), the following important differences apply: The first field in the request message must be called name rather than parent (this is listing revisions for a specific book, not a collection of books). The URI must end with :listRevisions. Revisions must be ordered in reverse chronological order. An order_by field should not be provided. The returned resources must include an explicit revision ID in the resource\u0027s name field. If providing the full resource is expensive or infeasible, the revision object may only populate the string name, string revision_id, and google.protobuf.Timestamp revision_create_time fields instead. The string name field must include the resource name and an explicit revision ID, which can be used for an explicit Get request. The API must document that it will do this. Child resources Resources with a revision history may have child resources. If they do, there are two potential variants: Child resources where each child resource is a child of the parent resource as a whole. Child resources where each child resource is a child of a single revision of the parent resource. If a child resource is a child of a single revision, the child resource\u0027s name must always explicitly include the parent\u0027s resource ID: publishers/123/books/les-miserables@c7cfa2a8/pages/42 In List requests for such resources, the service should default to the latest revision of the parent if the user does not specify one, but must explicitly include the parent\u0027s revision ID in the name field of resources in the response. If necessary, APIs may explicitly support listing child resources across parent revisions by accepting the @- syntax. For example: GET /v1/publishers/123/books/les-miserables@-/pages APIs should not include multiple levels of resources with revisions, as this quickly becomes difficult to reason about. Committing revisions Depending on the resource, different APIs may have different strategies for when to commit a new revision, such as: Commit a new revision any time that there is a change Commit a new revision when something important happens Commit a new revision when the user specifically asks APIs may use any of these strategies. APIs that want to commit a revision on user request should handle this with a Commit custom method: rpc CommitBook(CommitBookRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{name=publishers/*/books/*}:commit\" body: \"*\" } } The method must use the POST HTTP verb. The method should return the resource, and the resource name must include the revision ID. The request message must include the name field. Rollback A common use case for a resource with a revision history is the ability to roll back to a given revision. APIs should handle this with a Rollback custom method: rpc RollbackBook(RollbackBookRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{name=publishers/*/books/*}:rollback\" body: \"*\" } } The method must use the POST HTTP verb. The method should return the resource, and the resource name must include the revision ID. message RollbackBookRequest { // The book being rolled back. string name = 1; // The revision ID to roll back to. // It must be a revision of the same book. // // Example: c7cfa2a8 string revision_id = 2; } The request message must include a revision_id field. The API must fail the request with NOT_FOUND if the revision does not exist on that resource. Note: When rolling back, the API should return a new revision of the resource with a new revision ID, rather than reusing the original ID. This avoids problems with representing the same revision being active for multiple ranges of time. Deleting revisions Revisions are sometimes expensive to store, and there are valid use cases to want to remove one or more revisions from a resource\u0027s revision history. APIs may define a method to delete revisions, with a structure similar to Delete (AIP-135) methods: rpc DeleteBookRevision(DeleteBookRevisionRequest) returns (google.protobuf.Empty) { option (google.api.http) = { delete: \"/v1/{name=publishers/*/books/*}:deleteRevision\" } } message DeleteBookRevisionRequest { // The name of the book revision to be deleted, with a revision ID explicitly // included. // // Example: publishers/123/books/les-miserables@c7cfa2a8 string name = 1; } The explicit resource ID must be required (the method must fail with INVALID_ARGUMENT if it is not provided, and must not default to the latest revision). The API must not overload the DeleteBook method to serve both purposes (this could lead to dangerous or confusing mistakes). If the resource supports soft delete, then revisions of that resource should also support soft delete. Appendix: Character Collision Most resource names have a restrictive set of characters, but some are very open. For example, Google Cloud Storage allows the @ character in filenames, which are part of the resource name, and therefore uses the # character to indicate a revision. APIs should avoid permitting the @ character in resource names, and if APIs that do permit it need to support resources with revisions, they should pick an appropriate separator depending on how and where the API is used, and must clearly document it.",
    'tags': '',
    'url': '/162',
  },
{
    'title': "Change validation",
    'text': "Change validation Occasionally, a user wants to validate an intended change to see what the result will be before actually making the change. For example, a request to provision new servers in a fleet will have an impact on the overall fleet size and cost, and could potentially have unexpected downstream effects. Guidance APIs may provide an option to validate, but not actually execute, a request, and provide the same response (status code, headers, and response body) that it would have provided if the request was actually executed. To provide this option, the method should include a bool validate_only field in the request message: message ReviewBookRequest { string name = 1 [(google.api.resource_reference) = { type: \"library-example.googleapis.com/Book\" }]; int32 rating = 2; string comment = 3; // If set, validate the request and preview the review, but do not actually // post it. bool validate_only = 4; } The API must perform permission checks and any other validation that would be performed on a \"live\" request; a request using validate_only must fail if it determines that the actual request would fail. Note: It may occasionally be infeasible to provide the full output. For example, if creating a resource would create an auto-generated ID, it does not make sense to do this on validation. APIs should omit such fields on validation requests in this situation.",
    'tags': '',
    'url': '/163',
  },
{
    'title': "Criteria-based delete",
    'text': "Criteria-based delete Occasionally, an API may need to provide a mechanism to delete a large number of resources based on some set of filter parameters, rather than requiring the individual resource name of the resources to be deleted. This is a rare case, reserved for situations where users need to delete thousands or more resources at once, in which case the normal Batch Delete pattern (AIP-235) becomes unwieldy and inconvenient. Guidance Important: Most APIs should use only Delete (AIP-135) or Batch Delete (AIP-235) for deleting resources, and should not implement deleting based on criteria. This is because deleting is generally irreversible and this type of operation makes it easy for a user to accidentally lose significant amounts of data. An API may implement a Purge method to permit deleting a large number of resources based on a filter string; however, this should only be done if the Batch Delete (AIP-235) pattern is insufficient to accomplish the desired goal: rpc PurgeBooks(PurgeBooksRequest) returns (google.longrunning.Operation) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books:purge\" body: \"*\" } option (google.longrunning.operation_info) = { response_type: \"PurgeBooksResponse\" metadata_type: \"PurgeBooksMetadata\" }; } The HTTP verb must be POST, and the body must be \"*\". The parent field should be included in the URI. If the API wishes to support deletion across multiple parents, it should accept the - character consistent with AIP-159. The response type must be a google.longrunning.Operation (see AIP-151). Request message Purge methods implement a common request message pattern: message PurgeBooksRequest { // The publisher to purge books from. // To purge books across publishers, send \"publishers/-\". string parent = 1 [ (google.api.field_behavior) = REQUIRED, (google.api.resource_reference) = { child_type: \"library-example.googleapis.com/Book\" }]; // A filter matching the books to be purged. string filter = 2 [(google.api.field_behavior) = REQUIRED]; // Actually perform the purge. // If `force` is set to false, the method will return a sample of // resource names that would be deleted. bool force = 3; } The filter field should be required, and must follow the same semantics as in List methods (see AIP-132). The force field must be included. If it is not set, the API must return a count of the resources that would be deleted as well as a sample of those resources, without actually performing the deletion. Response message Purge methods implement a common response message pattern: message PurgeBooksResponse { // The number of books that this request deleted (or, if `force` is false, // the number of books that will be deleted). int32 purge_count = 1; // A sample of the resource names of books that will be deleted. // Only populated if `force` is set to false. repeated string purge_sample = 2; } The purge_count field should be included, and provide the number of resources that were deleted (or would be deleted). This count may be an estimate similar to total_size in AIP-158 (but the service should document this if so). The purge_sample field should be included: If force is false, it should provide a sample of resource names that will be deleted. If force is true, this field should not be populated. The sample should be a sufficient size to catch clearly obvious mistakes: A good rule of thumb is 100. The API should document the size, and should document that it is a maximum (it is possible to send fewer). The sample may be random or may be deterministic (such as the first matched resource names). The API should document which approach is used. Note: Even if purge_count and purge_sample are not included, the force field must still be included in the request.",
    'tags': '',
    'url': '/165',
  },
{
    'title': "Backwards compatibility",
    'text': "Backwards compatibility APIs are fundamentally contracts with users, and users often write code against APIs that is then launched into a production service with the expectation that it continues to work (unless the API has a stability level that indicates otherwise). Therefore, it is important to understand what constitutes a backwards compatible change and what constitutes a backwards incompatible change. Guidance Existing client code must not be broken by a service updating to a new minor or patch release. Old clients must be able to work against newer servers (with the same major version number). Important: It is not always clear whether a change is compatible or not. The guidance here should be treated as indicative, rather than as a comprehensive list of every possible change. There are three distinct types of compatibility to consider: Source compatibility: Code written against a previous version must compile against a newer version, and successfully run with a newer version of the client library. Wire compatibility: Code written against a previous version must be able to communicate correctly with a newer server. In other words, not only are inputs and outputs compatible, but the serialization and deserialization expectations continue to match. Semantic compatibility: Code written against a previous version must continue to receive what most reasonable developers would expect. (This can be tricky in practice, however, and sometimes determining what users will expect can involve a judgment call.) Note: In general, the specific guidance here assumes use of protocol buffers and JSON as transport formats. Other transport formats may have slightly different rules. Adding components In general, new components (interfaces, methods, messages, fields, enums, or enum values) may be added to existing APIs in the same major version. However, keep the following guidelines in mind when doing this: Code written against the previous surface (and thus is unaware of the new components) must continue to be treated the same way as before. New required fields must not be added to existing request messages or resources. Any field being populated by clients must have a default behavior matching the behavior before the field was introduced. Any field previously populated by the server must continue to be populated, even if it introduces redundancy. For enum values specifically, be aware that it is possible that user code does not handle new values gracefully. Enum values may be freely added to enums which are only used in request messages. Enums that are used in response messages or resources and which are expected to receive new values should document this. Enum values still may be added in this situation; however, appropriate caution should be used. Note: It is possible when adding a component closely related to an existing component (for example, string foo_value when string foo already exists) to enter a situation where generated code will conflict. Service owners should be aware of subtleties in the tooling they or their users are likely to use (and tool authors should endeavor to avoid such subtleties if possible). Removing or renaming components Existing components (interfaces, methods, messages, fields, enums, or enum values) must not be removed from existing APIs in the same major version. Removing a component is a backwards incompatible change. Important: Renaming a component is semantically equivalent to \"remove and add\". In cases where these sorts of changes are desirable, a service may add the new component, but must not remove the existing one. In situations where this can allow users to specify conflicting values for the same semantic idea, the behavior must be clearly specified. Moving into oneofs Existing fields must not be moved into or out of a oneof. This is a backwards-incompatible change in the Go protobuf stubs. Changing the type of fields Existing fields and messages must not have their type changed, even if the new type is wire-compatible, because type changes alter generated code in a breaking way. Changing resource names A resource must not change its name. Unlike most breaking changes, this affects major versions as well: in order for a client to expect to use v2.0 access a resource that was created in v1.0 or vice versa, the same resource name must be used in both versions. More subtly, the set of valid resource names should not change either, for the following reasons: If resource name formats become more restrictive, a request that would previously have succeeded will now fail. If resource name formats become less restrictive than previously documented, then code making assumptions based on the previous documentation could break. Users are very likely to store resource names elsewhere, in ways that may be sensitive to the set of permitted characters and the length of the name. Alternatively, users might perform their own resource name validation to follow the documentation. For example, Amazon gave customers a lot of warning and had a migration period when they started allowing longer EC2 resource IDs. Semantic changes Code will often depend on API behavior and semantics, even when such behavior is not explicitly supported or documented. Therefore, APIs must not change visible behavior or semantics in ways that are likely to break reasonable user code, as such changes will be seen as breaking by those users. Note: This does involve some level of judgment; it is not always clear whether a proposed change is likely to break users, and an expansive reading of this guidance could ostensibly prevent any change (which is not the intent). Further reading For compatibility around pagination, see AIP-158. For understanding stability levels and expectations, see AIP-181. Changelog 2019-12-16: Clarified that moving existing fields into oneofs is breaking.",
    'tags': '',
    'url': '/180',
  },
{
    'title': "Stability levels",
    'text': "Stability levels While different organizations (both inside Google and outside) have different product life cycles, AIPs refer to the stability of an API component using the following terms. Note: These stability levels roughly correspond to the product launch stages (alpha, beta, GA) in Google Cloud, but are not identical. GCP imposes its own additional expectations and commitments on top of what is outlined here. Alpha An alpha component undergoes rapid iteration with a known set of users who must be tolerant of change. The number of users should be a whitelisted, manageable set, such that it is feasible to communicate with all of them individually. Breaking changes must be both allowed and expected in alpha components, and users must have no expectation of stability. Beta A beta component must be considered complete and ready to be declared stable, subject to public testing. Beta components should be exposed to an unknown and potentially large set of users. In other words, beta components should not be behind a whitelist; instead, they should be available to the public. Because users of beta components tend to have a lower tolerance of change, beta components should be as stable as possible; however, the beta component must be permitted to change over time. These changes should be minimal but may include backwards-incompatible changes to beta components. Backwards-incompatible changes must be made only after a reasonable deprecation period to provide users with an opportunity to migrate their code. This deprecation period must be defined at the time of being marked beta. Beta components should be time-boxed and promoted to stable if no issues are found in the specified timeframe, which should be specified at the time of being marked beta. A reasonable time period may vary, but a good rule of thumb is 90 days. Stable A stable component must be fully-supported over the lifetime of the major API version. Because users expect such stability from components marked stable, there must be no breaking changes to these components, subject to the caveats described below. Major versions When breaking changes become necessary, the API producer should create the next major version of the API, and start a deprecation clock on the existing version. Turn-down of any version containing stable components must have a formal process defined at the time of being marked stable. This process must specify a deprecation period for users which provides them with reasonable advance warning. Isolated changes On very rare occasions, it could be preferable to make a small, isolated breaking change, if this will only cause inconvenience to a small subset of users. (Creating a new major version is an inconvenience to all users.) In this case, the API producer may deprecate the component, but must continue to support the component for the normal turndown period for a stable component. Important: Making an in-place breaking change in a stable API is considered an extreme course of action, and should be treated with equal or greater gravity as creating a new major version. For example, at Google, this requires the approval of the API Governance team. Emergency changes In certain exceptional cases, such as security concerns or regulatory requirements, any API component may be changed in a breaking manner regardless of its stability level, and a deprecation is not promised in these situations.",
    'tags': '',
    'url': '/181',
  },
{
    'title': "File and directory structure",
    'text': "File and directory structure A consistent file and directory structure, while making minimal difference technically, makes API surface definitions easier for users and reviewers to read. Guidance Note: The following guidance applies to APIs defined in protocol buffers, such as those used throughout Google. While the spirit of this guidance applies to APIs defined using other specification languages or formats, some of the particular recommendations might be irrelevant. Single package APIs defined in protocol buffers must define each individual API in a single package, which must end in a version component. For example: syntax = \"proto3\"; package google.cloud.translation.v3; Google APIs must reside in a directory that matches the protocol buffer package directive. For example, the package above dictates that the directory be google/cloud/translation/v3. File names It is often useful to divide API definitions into multiple files. File names must use snake_case. APIs should have an obvious \"entry\" file, generally named after the API itself. An API with a small number of discrete services (Google Cloud Pub/Sub\u0027s Publisher and Subscriber is a good example) may have a separate entry file per service. APIs with only one file should use a filename corresponding to the name of the API. Bear in mind that the file names often become module names in client libraries, and customers use them in import or use statements. Therefore, choosing a descriptive and language keyword-free filename does matter. For example, a file called import.proto may be problematic in Python. Note: The version must not be used as a filename, because this creates bizarre imports in client libraries. Filenames such as v3.proto or v1beta1.proto are prohibited. File layout Individual files should place higher level and more important definitions before lower level and less important definitions. In a proto file, components should be in the following order, and each of these should be separated by a blank line: Copyright and license notice (if applicable). The proto syntax statement. The proto package statement. Any import statements, in alphabetical order. Any file-level option statements. Any service definitions. Methods should be grouped by the resource they impact, and standard methods should precede custom methods. Resource message definitions. A parent resource must be defined before its child resources. The RPC request and response message definitions, in the same order of the corresponding methods. Each request message must precede its corresponding response message (if any). Any remaining message definitions. Any top-level enum definitions. Packaging annotations Protocol buffers ships with annotations to declare the package or namespace (depending on the vocabulary of the target language) of the generated files. For example, setting go_package or csharp_namespace will override the inferred package name. When defining APIs, the following rules apply: Java The java_package annotation must be set. The correct value is usually the proto package with the appropriate TLD prefixed. Example: com.google.example.v1. The java_multiple_files annotation must be set to true. The java_outer_classname annotation must be set, and should be set to the name of the proto filename, in PascalCase, with Proto appended. Example: LibraryProto. Other languages Package or namespace directives for other languages must be set either in every file in the proto package, or none of them. If they are set, the values must be identical in every file. Important: While other languages have sensible defaults, be aware that adding this annotation (with a value not equivalent to the default) constitutes a breaking change in that language. When releasing protos, be sure that omissions are intentional. Changelog 2019-11-18: Added guidance on the packaging annotations.",
    'tags': '',
    'url': '/191',
  },
{
    'title': "Documentation",
    'text': "Documentation Documentation is one of the most critical aspects of API design. Users of your API are unable to dig into the implementation to understand the API better; often, the API surface definition and its corresponding documentation will be the only things a user has. Therefore, it is important that documentation be as clear, complete, and unambiguous as possible. Guidance In APIs defined in protocol buffers, public comments must be included over every component (service, method, message, field, enum, and enum value) using the protocol buffers comment format. This is important even in cases where the comment is terse and uninteresting, as numerous tools read these comments and use them. Services, in particular, should have descriptive comments that explain what the service is and what users are able to do with it. Note: Many readers will not be native English speakers. Comments should avoid jargon, slang, complex metaphors, pop culture references, or anything else that will not easily translate. Additionally, many readers will have different backgrounds and viewpoints; if writing examples involving people, comments should use people who are non-controversial and no longer alive. Style Comments should be in grammatically correct American English. However, the first sentence of each comment should omit the subject and be in the third-person present tense: // Creates a book under the given publisher. rpc CreateBook(CreateBookRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books\" body: \"book\" }; } Descriptions Descriptions of messages and fields should be brief but complete. Sometimes comments are necessarily perfunctory because there is little to be said; however, before jumping to that conclusion, consider whether some of the following questions are relevant: What is it? How do you use it? What does it do if it succeeds? What does it do if it fails? Is it idempotent? What are the units? (Examples: meters, degrees, pixels) What are the side effects? What are common errors that may break it? What is the expected input format? What range of values does it accept? (Examples: [0.0, 1.0), [1, 10]) Is the range inclusive or exclusive? For strings, what is the minimum and maximum length, and what characters are allowed? If a value is above the maximum length, do you truncate or send an error? Is it always present? (Example: \"Container for voting information. Present only when voting information is recorded.\") Does it have a default setting? (Example: \"If page_size is omitted, the default is 50.\") Formatting Any formatting in comments must be in CommonMark. Headings and tables must not be used, as these cause problems for several tools, and are unsuitable for client library reference documentation. Comments should use code font for property names and for literals (such as true). Raw HTML must not be used. Cross-references Comments may \"link\" to another component (service, method, message, field, enum, or enum value) by using the fully-qualified name of the element as a Markdown reference link. For example: [Book][google.example.v1.Book] External links Comments may link to external pages to provide background information beyond what is described in the public comments themselves. External links must use absolute (rather than relative) URLs, including the protocol (usually https), and should not assume the documentation is located on any particular host. For example: [Spanner Documentation](https://cloud.google.com/spanner/docs) Trademarked names When referring to the proper, trademarked names of companies or products in comments, acronyms should not be used, unless the acronym is such dominant colloquial use that avoiding it would obscure the reference (example: IBM). Comments should spell and capitalize trademarked names consistent with the trademark owner\u0027s current branding. Internal comments Comments may be explicitly marked as internal by wrapping internal content in (-- and --). Non-public links, internal implementation notes (such as TODO and FIXME directives), and other such material must be marked as internal. Note: Comments should use only leading comments (not trailing comments or detached comments). In particular, comments must not use both a leading and trailing comment to describe any component, because this is a common source of inadvertent omissions of the internal content annotation. Changelog 2020-04-01: Added guidance requiring absolute URLs for external links. 2020-02-14: Added guidance around the use of trademarked names. 2019-09-23: Added guidance about not using both leading and trailing comments. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/192',
  },
{
    'title': "Errors",
    'text': "Errors Error handling is an important part of designing simple and intuitive APIs. Consistent error handling allows developers to know how to expect to receive errors, and to reduce boilerplate by having common error-handling logic, rather than being expected to constantly add verbose error handling everywhere. Guidance Services must return a [google.rpc.Status][] message when an API error occurs, and must use the canonical error codes defined in [google.rpc.Code][]. More information about the particular codes is available in the gRPC status code documentation. Error messages should help a reasonably technical user understand and resolve the issue, and should not assume that the user is an expert in your particular API. Additionally, error messages must not assume that the user will know anything about its underlying implementation. Error messages should be brief but actionable. Any extra information should be provided in the details field. If even more information is necessary, you should provide a link where a reader can get more information or ask questions to help resolve the issue. Details Google defines a set of standard detail payloads for error details, which cover most common needs for API errors. Services should use these standard details payloads when feasible. Structured details with machine-readable identifiers must be used if users will need to write code against a specific aspect of the error. Error message strings may change over time; however, if an error message does not have a machine-readable identifier in addition to the code field, changing the error message must be considered a backwards-incompatible change. Note: The [ErrorInfo][] message is the recommended way to send a machine-readable identifier. Localization Error messages must be in English. If a localized error message is also required, the service should use google.rpc.LocalizedMessage as the details field. Partial errors APIs should not support partial errors. Partial errors add significant complexity for users, because they usually sidestep the use of error codes, or move those error codes into the response message, where the user must write specialized error handling logic to address the problem. However, occasionally partial errors are necessary, particularly in bulk operations where it would be hostile to users to fail an entire large request because of a problem with a single entry. Methods that require partial errors should use long-running operations, and the method should put partial failure information in the metadata message. The errors themselves must still be represented with a [google.rpc.Status][] object. Further reading For which error codes to retry, see AIP-194. For how to retry errors in client libraries, see AIP-4221. Changelog 2020-01-22: Added a reference to the [ErrorInfo][] message. 2019-10-14: Added guidance restricting error message mutability to if there is a machine-readable identifier present. 2019-09-23: Added guidance about error message strings being able to change.",
    'tags': '',
    'url': '/193',
  },
{
    'title': "Automatic retry configuration",
    'text': "Automatic retry configuration RPCs sometimes fail. When one does, the client performing the RPC needs to know whether it is safe to retry the operation. When status codes are used consistently across multiple APIs, clients can respond to failures appropriately. Guidance Clients should automatically retry requests for which repeated runs would not cause unintended state changes, which are non-transactional, and which are unary. Clients should not automatically retry transactional requests; instead these requests should have application-level retry logic that retries the entire transaction block from the start. Clients should not automatically retry requests in which repeated runs would cause unintended state changes. Note: This AIP does not cover client streaming or bi-directional streaming. Retryable codes For methods listed as retryable above, clients should retry the following error codes: UNAVAILABLE: This code generally results from network hiccups, and is generally transient. It is retryable under the expectation that the connection will become available (soon). Appendix Non-retryable codes The following codes should not be automatically retried for any request: OK: The request succeeded. CANCELLED: An application can cancel a request, which must be honored. DEADLINE_EXCEEDED: An application can set a deadline, which must be honored. INVALID_ARGUMENT: Retrying a request with an invalid argument will never succeed. DATA_LOSS: This is an unrecoverable error and must immediately be surfaced to the application. Generally non-retryable codes: The following codes generally should not be automattically retried for any request: RESOURCE_EXHAUSTED: This code may be a signal that quota is exhausted. Retries therefore may not be expected to work for several hours; meanwhile the retries may have billing implications. If RESOURCE_EXHAUSTED is used for other reasons than quota and the expected time for the resource to become available is much shorter, it may be retryable. INTERNAL: This code generally means that some internal part of the system has failed, and usually means a bug should be filed against the system. These should immediately be surfaced to the application. UNKNOWN: Unlike INTERNAL, this code is reserved for truly unknown-to-the-system errors, and therefore may not be safe to retry. These should immediately be surfaced to the application. ABORTED: This code typically means that the request failed due to a sequencer check failure or transaction abort. These should not be retried for an individual request; they should be retried at a level higher (the entire transaction, for example). Some codes may be automatically retried if a system is designed without synchronization or signaling between various components. For example, client might retry NOT_FOUND on a read operation, which is designed to hang forever until the resource is created. However, these types of systems are generally discouraged. Therefore, the following codes should not be automatically retried for any request: NOT_FOUND: A client should not retry until a resource is created. ALREADY_EXISTS: A client should not retry until a resource is deleted. PERMISSION_DENIED: A client should not retry until it has permission. UNAUTHORIZED: A client should not retry until it is authorized. UNAUTHENTICATED: A client should not retry until it is authenticated. FAILED_PRECONDITION: A client should not retry until system state changes. OUT_OF_RANGE: A client should not retry until the range is extended. UNIMPLEMENTED: A client should not retry until the RPC is implemented. Further reading For parallel or retried request disambiguation, see AIP-154.",
    'tags': '',
    'url': '/194',
  },
{
    'title': "Precedent",
    'text': "Precedent Many times, APIs are written in ways that do not match new guidance that is added to these standards after those APIs have already been released. Additionally, sometimes it can make sense to intentionally violate standards for particular reasons, such as maintaining consistency with established systems, meeting stringent performance requirements, or other practical concerns. Finally, as carefully as everyone reviews APIs before they are released, sometimes mistakes can slip through. Since it often is not feasible to fix past mistakes or make the standards serve every use case, APIs may be stuck with these exceptions for quite some time. Further, since new APIs often base their designs (names, types, structures, etc) on existing APIs, it is possible that a standards violation in one API could spill over into other APIs, even if original reason for the exception is not applicable to the other APIs. As a result of this problem, it is important to \"stop the bleeding\" of these standards exceptions into new APIs, and additionally document the reasons for each exception so that historical wisdom is not lost. Guidance If an API violates the AIP standards for any reason, there must be an internal comment linking to this document using its descriptive link (aip.dev/not-precedent) to ensure others do not copy the violations or cite the errors as precedent of a \"previously approved API\". The comment should also include an explanation of what violates standards and why it is necessary. For example: message DailyMaintenanceWindow { // Time within the maintenance window to start the maintenance operations. // It must use the format \"HH MM\", where HH : [00-23] and MM : [00-59] GMT. // (-- aip.dev/not-precedent: This was designed for consistency with crontab, // and preceded the AIP standards. // Ordinarily, this type should be `google.type.TimeOfDay`. --) string start_time = 2; // Output only. Duration of the time window, automatically chosen to be // smallest possible in the given scenario. // (-- aip.dev/not-precedent: This preceded the AIP standards. // Ordinarily, this type should be `google.protobuf.Duration`. --) string duration = 3; } Important: APIs should only be considered to be precedent-setting if they are in beta or GA. Local consistency If an API violates a standard throughout, it would be jarring and frustrating to users to break the existing pattern only for the sake of adhering to the global standard. For example, if all of an API\u0027s resources use creation_time (instead of the standard field create_time described in AIP-142), a new resource in that API should continue to follow the local pattern. However, others who might otherwise copy that API should be made aware that this is contra-standard and not something to cite as precedent when launching new APIs. // ... message Book { // (-- aip.dev/not-precedent: This field was present before there was a // standard field. // Ordinarily, it should be spelled `create_time`. --) google.protobuf.Timestamp creation_time = 1; } // ... message Author { // (-- aip.dev/not-precedent: `Book` had `creation_time` before there was // a standard field, so we match that here for consistency. Ordinarily, // this would be spelled `create_time`. --) google.protobuf.Timestamp creation_time = 1; } Pre-existing functionality Standards violations are sometimes overlooked before launching, resulting in APIs that become stable and therefore can not easily be modified. Additionally, a stable API may pre-date a standards requirement. In these scenarios, it is difficult to make the API fit the standard. However, the API should still cite that the functionality is contra-standard so that other APIs do not copy the mistake and cite the existing API as a reason why their design should be approved. Adherence to external spec Occasionally, APIs must violate standards because specific requests are implementations of an external specification (for example, OAuth), and their specification may be at odds with AIP guidelines. In this case, it is likely to be appropriate to follow the external specification. Adherence to existing systems Similar to the example of an external specification above, it may be proper for an API to violate AIP guidelines to fit in with an existing system in some way. This is a fundamentally similar case where it is wise to meet the customer where they are. A potential example of this might be integration with or similarity to a partner API. Expediency Sometimes there are users who need an API surface by a very hard deadline or money walks away. Since most APIs serve a business purpose, there will be times when an API could be better but cannot get it that way and into users\u0027 hands before the deadline. In those cases, API review councils may grant exceptions to ship APIs that violate guidelines due to time and business constraints. Technical concerns Internal systems sometimes have very specific implementation needs (e.g., they rely on operation transforms that speak UTF-16, not UTF-8) and adhering to AIP guidelines would require extra work that does not add significant value to API consumers. Future systems which are likely to expose an API at some point should bear this in mind to avoid building underlying infrastructure which makes it difficult to follow AIP guidelines. Changelog 2020-03-27: Reworded much of this AIP to follow AIP-8, and remove first and second person. No semantic changes. 2019-05-04: Changed to a public link (aip.dev/not-precedent), and changed references to \"the style guide\" to use the more generic term \"standards\" (to account for a general shift to AIPs).",
    'tags': '',
    'url': '/200',
  },
{
    'title': "Field behavior documentation",
    'text': "Field behavior documentation When defining fields in protocol buffers, it is customary to explain to users certain aspects of the field\u0027s behavior (such as whether it is required or optional). Additionally, it can be useful for other tools to understand this behavior (for example, to optimize client library signatures). Guidance APIs should use the google.api.field_behavior annotation to describe well-understood field behavior, such as a field\u0027s being required, immutable, or output only: // The audio data to be recognized. RecognitionAudio audio = 2 [(google.api.field_behavior) = REQUIRED]; Additionally, APIs may use the OPTIONAL value to describe none of the above. However, it is never mandatory to explicitly describe a field as optional. Note: The vocabulary given in this document is for descriptive purposes only, and does not itself add any validation. The purpose is to consistently document this behavior for users. Vocabulary Required The use of REQUIRED indicates that the field must be present (and set to a non-empty value) on the request or resource. A field should only be described as required if either: It is a field on a resource that a user provides somewhere as input. In this case, the resource is only valid if a truthy value is stored. When creating the resource, a value must be provided for the field on the create request. When updating the resource, the user may omit the field provided that the field is also absent from the field mask, indicating no change to the field (otherwise it must be provided). It is a field on a request message (a message that is an argument to an RPC, with a name usually ending in Request). In this case, a value must be provided as part of the request, and failure to do so must cause an error (usually INVALID_ARGUMENT). Fields should not be described as required in order to signify: A field which will always be present in a response. A field which is conditionally required in some situations. A field on any message (including messages that are resources) which is never used as user input. Note: In most cases, empty values (such as false for booleans, 0 for integers, or the unspecified value for enums) are indistinguishable from unset values, and therefore setting a required field to a falsy value yields an error. A corollary to this is that a required boolean must be set to true. Output only The use of OUTPUT_ONLY indicates that the field is provided in responses, but that including the field in a message in a request does nothing (the server must ignore it and must not throw an error as a result of the presence of a value in this field on input). Similarly, services must ignore the presence of output only fields in update field masks. Additionally, a field should only be described as output only if it is a field in a resource message, or a field of a message farther down the tree. Notably, fields in response messages (a message which only ever acts as a return value to an RPC, usually ending in Response) should not be described as output only because this is already implied. Output only fields may be set to empty values if appropriate to the API. Potential use cases for output only fields (this is not an exhaustive list) are: Create or update timestamps. Derived or structured information based on original user input. Properties of a resource assigned by the service which can not be altered. Input only The use of INPUT_ONLY indicates that the field is provided in requests and that the corresponding field will not be included in output. Additionally, a field should only be described as input only if it is a field in a resource message or a field of a message included within a resource message. Notably, fields in request messages (a message which only ever acts as an argument to an RPC, with a name usually ending in Request) should not be described as input only because this is already implied. Potential use cases for input only fields (this is not an exhaustive list) are: The ttl field as described in AIP-214. Warning: Input only fields are rare and should be considered carefully before use. Immutable The use of IMMUTABLE indicates that a field may be set once in a request to create a resource but may not be changed thereafter. Additionally, a field should only be described as immutable if it is a field on a request message (a message that is an argument to an RPC, usually ending in Request), or a field of a message included within a request message. When a service receives an immutable field in an update request (or similar), even if included in the update mask, the service should ignore the field if the value matches, but should error with INVALID_ARGUMENT if a change is requested. Potential use cases for immutable fields (this is not an exhaustive list) are: Names or IDs which are set on creation and then used as a primary key. Note: Fields which are \"conditionally immutable\" must not be given the immutable annotation. Optional The use of OPTIONAL indicates that a field is not required, nor covered by any of the above descriptions. A field may be described as optional if none of the above vocabulary applies, and it is a field on a request message (a message that is an argument to an RPC, usually ending in Request), or a field on a submessage, but it is not mandatory to describe optional fields in this way. If you do choose to explicitly describe a field as optional, ensure that every optional field on the message has this indicator. Within a single message, either all optional fields should be indicated, or none of them should be. Changelog 2020-05-27: Clarify behavior when receiving an immutable field in an update. 2019-12-05: Added guidance on output only fields in field masks. 2019-06-18: Use the machine-readable annotation, not comments.",
    'tags': '',
    'url': '/203',
  },
{
    'title': "Beta-blocking changes",
    'text': "Beta-blocking changes APIs often release an Alpha version of their API in order to get early feedback from customers. This API is provisional and can change many times before the important feedback is incorporated and the API is made stable for Beta. Since the purpose of Alpha is to gather feedback, the API does not need to be perfect yet, and it\u0027s not strictly necessary for API authors to address every usability concern or address every point in the API standards. Often, API authors and API reviewers will not agree on the best design, and the best way to find out is by having users try out the API. However, once the feedback has been collected and the API is going to be promoted to Beta, usability concerns and style issues do need to be addressed. In order to ensure that these issues are not forgotten, they should be explicitly documented in the API. Guidance If an API has usability concerns or violates API standards, and the present design should receive additional scrutiny before being carried through to the Beta version, there must be an internal comment linking to this document using its descriptive link (aip.dev/beta-blocker) to ensure that the design is corrected before the API is released to Beta. The comment must also indicate what kind of change should be made for Beta. For example: message InputConfig { // Parameters for input. // (-- aip.dev/beta-blocker: Convert well-known parameters into explicit // fields before the Beta launch. --) map\u003cstring, string\u003e parameters = 1; } If an exception to API standards does need to be carried through to Beta and GA, see AIP-200.",
    'tags': '',
    'url': '/205',
  },
{
    'title': "Unicode",
    'text': "Unicode APIs should be consistent on how they explain, limit, and bill for string values and their encodings. This ranges from little ambiguities (like fields \"limited to 1024 characters\") all the way to billing confusion (are names and values of properties in Datastore billed based on characters or bytes?). In general, if we talk about limits measured in bytes, we are discriminating against non-ASCII text since it takes up more space. On the other hand, if we talk about \"characters\", we are ambiguous about whether those are Unicode \"code points\", \"code units\" for a particular encoding (e.g. UTF-8 or UTF-16), \"graphemes\", or \"grapheme clusters\". Unicode primer Character encoding tends to be an area we often gloss over, so a quick primer: Strings are just bytes that represent numbers according to some encoding format. When we talk about characters, we sometimes mean Unicode code points, which are numbers in the Unicode spec (up to 21 bits). Other times we might mean graphemes or grapheme clusters, which may have multiple numeric representations and may be represented by more than one code point. For example, \u00e1 may be represented as a composition of U+0061 + U+0301 (the a + the accent combining mark) or as a single code point, U+00E1. Protocol buffers uses UTF-8 (\"Unicode Transformation Format\") which is a variable-length encoding scheme using up to 4 code units (8-bit bytes) per code point. Guidance Character definition TL;DR: In our APIs, \"characters\" means \"Unicode code points\". In API documentation (e.g., API reference documents, blog posts, marketing documentation, billing explanations, etc), \"character\" must be defined as a Unicode code point. Length units TL;DR: Set size limits in \"characters\" (as defined above). All string field length limits defined in API comments must be measured and enforced in characters as defined above. This means that there is an underlying maximum limit of (4 * characters) bytes, though this limit will only be hit when using exclusively characters that consist of 4 UTF-8 code units (32 bits). If you use a database system (e.g. Spanner) which allows you to define a limit in characters, it is safe to assume that this byte-defined requirement is handled by the underlying storage system. Billing units APIs may use either code points or bytes (using the UTF-8 encoding) as the unit for billing or quota measurement (e.g., Cloud Translation chooses to use characters). If an API does not define this, the assumption is that the unit of billing is characters (e.g., $0.01 per character, not $0.01 per byte). Unique identifiers TL;DR: Unique identifiers should limit to ASCII, generally only letters, numbers, hyphens, and underscores, and should not start with a number. Strings used as unique identifiers should limit inputs to ASCII characters, typically letters, numbers, hyphens, and underscores ([a-zA-Z][a-zA-Z0-9_-]*). This ensures that there are never accidental collisions due to normalization. If an API decides to allow all valid Unicode characters in unique identifiers, the API must reject any inputs that are not in Normalization Form C. Generally, unique identifiers should not start with a number as that prefix is reserved for Google-generated identifiers and gives us an easy way to check whether we generated a unique numeric ID for or whether the ID was chosen by a user. Unique identifiers should use a maximum length of 64 characters, though this limit may be expanded as necessary. 64 characters should be sufficient for most purposes as even UUIDs only require 36 characters. Normalization TL;DR: Unicode values should be stored in Normalization Form C. Values should always be normalized into Normalization Form C. Unique identifiers must always be stored in Normalization Form C (see the next section). Imagine we\u0027re dealing with Spanish input \"estar\u00e9\" (the accented part will be bolded throughout). This text has what we might visualize as 6 \"characters\" (in this case, they are grapheme clusters). It has two possible Unicode representations: Using 6 code points: U+0065 U+0073 U+0074 U+0061 U+0072 U+00E9 Using 7 code points: U+0065 U+0073 U+0074 U+0061 U+0072 U+0065 U+0301 Further, when encoding to UTF-8, these code points have two different serialized representations: Using 7 code-units (7 bytes): 0x65 0x73 0x74 0x61 0x72 0xC3 0xA9 Using 8 code-units (8 bytes): 0x65 0x73 0x74 0x61 0x72 0x65 0xCC 0x81 To avoid this discrepancy in size (both code units and code points), use Normalization Form C which provides a canonical representation for strings. Uniqueness TL;DR: Unicode values must be normalized to Normalization Form C before checking uniqueness. For the purposes of unique identification (e.g., name, id, or parent), the value must be normalized into Normalization Form C (which happens to be the most compact). Otherwise we may have what is essentially \"the same string\" used to identify two entirely different resources. In our example above, there are two ways of representing what is essentially the same text. This raises the question about whether the two representations should be treated as equivalent or not. In other words, if someone were to use both of those byte sequences in a string field that acts as a unique identifier, would it violate a uniqueness constraint? The W3C recommends using Normalization Form C for all content moving across the internet. It is the most compact normalized form on Unicode text, and avoids most interoperability problems. If we were to treat two Unicode byte sequences as different when they have the same representation in NFC, we\u0027d be required to reply to possible \"Get\" requests with content that is not in normalized form. Since that is definitely unacceptable, we must treat the two as identical by transforming any incoming string data into Normalized Form C or rejecting identifiers not in the normalized form. There is some debate about whether we should view strings as sequences of code points represented as bytes (leading to uniqueness determined based on the byte-representation of said string) or to interpret strings as a higher level abstraction having many different possible byte-representations. The stance taken here is that we already have a field type for handling that: bytes. Fields of type string already express an opinion of the validity of an input (it must be valid UTF-8). As a result, treating two inputs that have identical normalized forms as different due to their underlying byte representation seems to go against the original intent of the string type. This distinction typically doesn\u0027t matter for strings that are opaque to our services (e.g., description or display_name), however when we rely on strings to uniquely identify resources, we are forced to take a stance. Put differently, our goal is to allow someone with text in any encoding (ASCII, UTF-16, UTF-32, etc) to interact with our APIs without a lot of \"gotchas\". References Unicode normalization forms Datastore pricing \"name and value of each property\" doesn\u0027t clarify this. Natural Language pricing uses charges based on UTF-8 code points rather than code units. Text matching and normalization",
    'tags': '',
    'url': '/210',
  },
{
    'title': "Common components",
    'text': "Common components In general, API reviewers encourage API producers to keep their APIs mostly self-contained, except for a relatively small set of common protos which are safe to import (e.g. google.protobuf.Timestamp). This is for good reason: APIs generally need to be able to move forward independently of one another, and mutual dependencies can cause downstream APIs to be forced into taking major version changes or even lead to dependency conflicts. However, there are also cases where common structures are valuable, especially where a concept is well-known and it is sufficiently clear that it will not change. Common protos serve this use case. Guidance The public representation of APIs should be self-contained, meaning that all protos used by the API originate in the same proto package, except for common protos, which may be used freely in any API. APIs must not define a set of API-specific common protos which live outside of its versioning structure. This prevents independent movement of particular versions and also causes problems for client libraries in many languages that compile the proto messages into classes. APIs should not directly depend on protos defined in other APIs. Instead, they should copy and paste the applicable messages into their own API. When doing so, APIs should keep the field names and numbers the same. Existing common protos The common protos, which public-facing protos for an API may safely import, are as follows: google.api.http google.longrunning.Operation google.protobuf.* google.rpc.Code google.rpc.Status google.type.* Note that some common protos may have internal-only fields. APIs should generally only rely on fields which have been released into open source. Google APIs may also import google.iam.v1.*, which provides the IAM messages used throughout Google. Note: Many APIs also import protos from other packages for internal-only use (e.g. to apply visibility labels or provide instructions to internal infrastructure). This is acceptable provided that the public protos do not contain such references. Protobuf types The google.protobuf package is somewhat special in that it is shipped with protocol buffers itself, rather than with API tooling. (For most API designers, this should be an implementation detail). This package includes a small library of types useful for representing common programming language constructs: google.protobuf.Duration: Durations, with nanosecond-level precision. The protobuf runtime provides helper functions to convert to and from language-native duration objects where applicable (such as Python\u0027s timedelta). google.protobuf.Struct: JSON-like structures (a dictionary of primitives, lists, and other dictionaries). The protobuf runtime provides helper functions in most languages to convert struct objects to and from JSON. google.protobuf.Timestamp: Timestamps, with nanosecond-level precision. The protobuf runtime provides helper functions in most languages to convert to and from language-native timestamp objects (such as Python\u0027s datetime). API Types The google.type package provides a \"standard library\" of types useful for representing common concepts in APIs. While types are added from time to time and the definitive list is always the code, several types deserve note: google.type.Color: RGB or RGBA colors. google.type.Date: Calendar dates, with no time or time zone component. google.type.DayOfWeek: The day of the week, with no other date, time, or time zone component. google.type.LatLng: Geographic coordinates. google.type.Money: Currency. google.type.PostalAddress: Postal addresses in most countries. google.type.TimeOfDay: Wall-clock time, with no date or time zone component. Appendix: Adding to common protos Occasionally, it may be useful to add protos to these packages or to add to the list of commonly-available protos. In order to do this, open an issue on the AIP repository in GitHub. However, some general guidelines are worth noting for this: Protos should only be promoted to common status if we are certain that they will never change (at all -- even in ways that would normally be considered backwards compatible). Common protos are generally not versioned, and it must be the case that we can rely on the proto to be a complete and accurate representation indefinitely. The exception to this is protos describing our infrastructure, which may have rare, backwards-compatible changes. Protos must be applicable to a significant number of APIs for consideration as common protos. It is okay for those APIs to be clustered together (e.g. all in a single PA). There is no good way to \"stage\" a common proto, because moving references to them is effectively not possible. (In other words, it is infeasible to add a proto to google.geo.type.* and then \"graduate\" it to google.type.* later.) Adding a common proto requires coordination between several teams, and it may take time between when an addition is approved and when it is available for use. Even after a common proto is added, APIs using local versions must continue to do so until they go to the next major version. In the event that you believe adding a common proto is appropriate, please open an issue.",
    'tags': '',
    'url': '/213',
  },
{
    'title': "Resource expiration",
    'text': "Resource expiration Customers often want to provide the time that a given resource or attribute of a resource is no longer useful or should be deleted. Currently we recommend that customers do this by specifying an exact \"expiration time\" into a google.protobuf.Timestamp expire_time field; however, this adds additional strain on the user when they want to specify a relative time offset until expiration rather than a specific time until expiration. Furthermore, the world understands the concept of a \"time-to-live\", often abbreviated to TTL, but the typical format of this field (an integer, measured in seconds) results in a sub-par experience when using an auto-generated client library. Guidance APIs wishing to convey an expiration must rely on a google.protobuf.Timestamp field called expire_time. APIs wishing to allow a relative expiration time must define a oneof called expiration (or {something}_expiration) containing both the expire_time field and a separate google.protobuf.Duration field called ttl, the latter marked as input only. APIs must always return the expiration time in the expire_time field and leave the ttl field blank when retrieving the resource. APIs that rely on the specific semantics of a \"time to live\" (e.g., DNS which must represent the TTL as an integer) may use an int64 ttl field (and should provide an aip.dev/not-precedent comment in this case). Example message ExpiringResource { // The name of the resource; the format is: ... string name = 1; oneof expiration { // Timestamp in UTC of when this resource is considered expired. // This is *always* provided on output, regardless of what was sent // on input. google.protobuf.Timestamp expire_time = 2; // Input only. The TTL for this resource. google.protobuf.Duration ttl = 3 [(google.api.field_behavior) = INPUT_ONLY]; } } Alternatives considered A new standard field called ttl We considered allowing a standard field called ttl as an alternative way of defining the expiration, however doing so would require that API services continually update the field, like a clock counting down. This could potentially cause problems with the read-modify-write lifecycle where a resource is being processed for some time, and effectively has its life extended as a result of that processing time. Always use expire_time This is the current state of the world with a few exceptions. In this scenario, we could potentially push the computation of now + ttl = expire_time into client libraries; however, this leads to a somewhat frustrating experience in the command-line and using REST/JSON. Leaving things as they are is typically the default, but it seems many customers want the ability to define relative expiration times as it is quite a bit easier and removes questions of time zones, stale clocks, and other silly mistakes.",
    'tags': '',
    'url': '/214',
  },
{
    'title': "Common component versions",
    'text': "Common component versions Many APIs may support more than one version at the same time. Often, our first instinct is to create protos which are intended to be shared between API versions, and place them in an unversioned \"common\" directory. A similar variant to this is an omitted version: a message or service that is implicitly v1, but has no version in the proto package. When protos are unversioned, changing them safely (that is, in a backwards compatible way) is very difficult. For example, adding a field to an unversioned proto effectively adds the field to all existing versions, which do not actually support it. This is surprising to users, and creates a situation where the proto files are not accurate representations of the API surface. Additionally, client library generators usually generate a class for each message in your protos in a language-appropriate namespace. In several languages, each version of your API is shipped as a separate client library, and the code generator needs to generate the common messages for your API in order to ensure a complete package. This makes it difficult to use multiple APIs with similar dependent messages together. For omitted versions, the version is effectively hidden, and it becomes more difficult to reason about release phases (alpha, beta, GA), with no substantive benefit. Guidance All protos specific to an API should be within the versioned package (e.g., yourapi.v1.SharedProtoMessage). In scenarios where an API doesn\u0027t consider itself to have a version, the API must use v1. (Omitted-version protos are prohibited.) When a shared proto is identical, that proto should be duplicated to the other versioned package (e.g., copied and pasted into yourapi.v2.SharedProtoMessage). What if a proto will never change? There are some situations where it is useful to have an unversioned proto. These should generally apply to a complete product area or suite of APIs, not just a single API. In these situations, it may be possible to add it to our collections of common protos. Common protos are able to be used by many APIs, and are always unversioned. Common protos shall always have a package structure ending in type (e.g. google.type, google.cloud.type). Warning: This is a relatively rare occurrence. If you find yourself adding protos to your PA\u0027s type directory frequently, double-check that this is actually where they belong. For more information on common protos, consult AIP-213.",
    'tags': '',
    'url': '/215',
  },
{
    'title': "States",
    'text': "States Many API resources carry a concept of \"state\": ordinarily, the resource\u0027s place in its life cycle. For example, a virtual machine may be being provisioned, available for use, being spun down, or potentially be in one of several other situations. A job or query may be preparing to run, be actively running, have completed, and so on. Guidance Resources needing to communicate their state should use an enum, which should be called State (or, if more specificity is required, end in the word State). This enum should be nested within the message it describes when only used as a field within that message. Important: We use the term State, and not Status (which is reserved for the HTTP and gRPC statuses). Enum values Ideally, Google APIs use the same terminology throughout when expressing the same semantic concepts. There are usually many words available to express a given state, but our customers often use multiple APIs together, and it is easier for them when our terms are consistent. At a high level: Resources that are available for use are ACTIVE (preferred over terms such as \"ready\" or \"available\"). Resources that have completed a (usually terminal) requested action use past participles (usually ending in -ED), such as SUCCEEDED (not \"successful\"), FAILED (not \"failure\"), DELETED, SUSPENDED, and so on. Resources that are currently undergoing a state change use present participles (usually ending in -ING), such as RUNNING, CREATING, DELETING, and so on. In this case, it is expected that the state is temporary and will resolve to another state on its own, with no further user action. Note: Remember to only add states that are useful to customers. Exposing a large number of states simply because they exist in your internal system is unnecessary and adds confusion for customers. Each state must come with a use case for why it is necessary. A list of commonly used enum values for states is in the appendix of this document. Output only The field referencing the State enum in a resource should behave and be documented as \"Output only\", in accordance with AIP-203. APIs should not allow a State enum to be directly updated through an \"update\" method, and should instead use a custom state transition method. This is because update methods are generally not expected to have side effects, and also because updating state directly implies that it is possible to set the state to any available value, whereas states generally reflect a resource\u0027s progression through a lifecycle. State transition methods State transition methods are a special type of custom method that are responsible for transitioning a state field from one enum value to another. As part of the transition, other fields may also change, e.g. an update_time field. The method definition should look like the following: // Publishes a book. // The `state` of the book after publishing will be PUBLISHED. // `PublishBook` can be called on Books in the state DRAFT; Books in a // different state (including PUBLISHED) will return an error. rpc PublishBook(PublishBookRequest) returns (Book) { option (google.api.http) = { post: \"/v1/{name=publishers/*/books/*}:publish\" body: \"*\" }; } The name of the method should be a verb followed by the singular form of the resource\u0027s message name. The request message must match the RPC name, with a -Request suffix. The response message should be the resource itself. If the RPC is long-running, the response message should be a google.longrunning.Operation which resolves to the resource itself. The HTTP verb must be POST. The HTTP URI must use a : character followed by the custom verb (:publish in the above example), and the verb in the URI must match the verb in the name of the RPC. If word separation is required, camelCase must be used. The body clause in the google.api.http annotation must be \"*\". The request message field receiving the resource name should map to the URL path. This field should be called name. The name field should be the only variable in the URI path. All remaining parameters should map to URI query parameters. If the state transition is not allowed, the service must error with FAILED_PRECONDITION (HTTP 400). The request message should look like this: message PublishBookRequest { // The name of the book to publish. // Format: publishers/{publisher}/books/{book} string name = 1; } A resource name field must be included. It should be called name. The comment for the field should document the resource pattern. Other fields may be included. Additional Guidance Default value The zero value of each state enum should adhere to the following convention: enum State { // The default value. This value is used if the state is omitted. STATE_UNSPECIFIED = 0; // Other values... } Resources should not provide an unspecified state to users, and this value should not actually be used. Value uniqueness Multiple top-level enums within the same package must not share the same values. This is because the C++ protoc code generator flattens top-level enum values into a single namespace. State enums should live inside the resource definition. Breaking changes TL;DR: Clearly communicate to users that state enums may receive new values in the future, and be conscientious about adding states to an existing enum. Even though adding states to an existing states enum can break existing user code, adding states is not considered a breaking change. Consider a state with only two values: ACTIVE and DELETED. A user may add code that checks if state == ACTIVE, and in the else cases simply assumes the resource is deleted. If the API later adds a new state for another purpose, that code will break. We ultimately can not control this behavior, but API documentation should actively encourage users to code against state enums with the expectation that they may receive new values in the future. APIs may add new states to an existing State enum when appropriate, and adding a new state is not considered a breaking change. When to avoid states Sometimes, a State enum may not be what is best for your API, particularly in situations where a state has a very small number of potential values, or when states are not mutually exclusive. Consider the example of a state with only ACTIVE and DELETED, as discussed above. In this situation, the API may be better off exposing a google.protobuf.Timestamp delete_time, and instructing users to rely on whether it is set to determine deletion. Appendix: Common states The following is a list of states in common use. APIs should consider prior art when determining state names, and should value local consistency above global consistency in the case of conflicting precedent. Resting states \"Resting states\" are lifecycle states that, absent user action, are expected to remain indefinitely. However, the user can initiate an action to move a resource in a resting state into certain other states (resting or active). ACCEPTED ACTIVE CANCELLED DELETED FAILED SUCCEEDED SUSPENDED VERIFIED Active states \"Active states\" are lifecycle states that typically resolve on their own into a single expected resting state. Note: Remember only to expose states that are useful to customers. Active states are valuable only if the resource will be in that state for a sufficient period of time. If state changes are immediate, active states are not necessary. CREATING (usually becomes ACTIVE) DELETING (usually becomes DELETED) PENDING (usually becomes RUNNING) REPAIRING (usually becomes ACTIVE) RUNNING (usually becomes SUCCEEDED) SUSPENDING (usually becomes SUSPENDED) Further reading For information on enums generally, see AIP-126. Changelog 2019-12-05: Changed guidance on state transition methods, downgrading must to should on the response type. 2019-08-16: Added guidance for state transition methods. 2019-07-18: Added explicit guidance on the unspecified value.",
    'tags': '',
    'url': '/216',
  },
{
    'title': "Unreachable resources",
    'text': "Unreachable resources Occasionally, a user may ask for a list of resources, and some set of resources in the list are temporarily unavailable. For example, a user may ask to list resources across multiple parent locations, but one of those locations is temporarily unreachable. In this situation, it is still desirable to provide the user with all the available resources, while indicating that something is missing. Guidance If a method to retrieve data is capable of partially failing due to one or more resources being temporarily unreachable, the response message must include a field to indicate this: message ListBooksResponse { // The books matching the request. repeated Book books = 1; // The next page token, if there are more books matching the // request. string next_page_token = 2; // Unreachable resources. repeated string unreachable = 3; } The field must be a repeated string, and should be named unreachable. The field must be set to the names of the resources which are the cause of the issue, such as the parent or individual resources that could not be reached. The objects listed as unreachable may be parents (or higher ancestors) rather than the individual resources being requested. For example, if a location is unreachable, the location is listed. The response must not provide any other information about the issue, such as error details or codes. To discover what the underlying issue is, users should send a more specific request. The service must provide a way for the user to get an error with additional information, and should allow the user to repeat the original call with more restrictive parameters in order to do so. The resource names provided in this field may be heterogeneous. The field should document what potential resources may be provided in this field, and note that it might expand later. Important: If a single unreachable location or resource prevents returning any data by definition (for example, a list request for a single publisher where that publisher is unreachable), the service must fail the entire request with an error. Pagination When paginating over a list, it is likely that the service will not know that there are unreachable parents or resources initially. Further, parents may alternate between being available and unavailable in unpredictable ways throughout the process of listing all the requested resources. These facts lead to the following guidance: The response must provide any outstanding unreachable locations or resources in the unreachable field on pages following the final page that contains a resource. The response should not include both requested data and unreachable resources on the same page. For example, if there are two pages of books and one unavailable publisher, there should be three pages total: first the two pages of books, and then a final page with no books and the unavailable publisher. If the number of unreachable resources to list is very large, the response should honor the page_size field in the same way as for resources. In this case, all pages with requested information should precede all pages with unavailable resources or locations. The final page\u0027s unreachable field must only include resources or parents that were partially provided (or missing completely) across the entirety of the pagination process. For example, if a parent or resource was unreachable at the beginning of pagination and it became reachable again and the entire set of previously unreachable data was provided to the user on any page, the unreachable field must not include the intermittently-unreachable parent or resource. On the other hand, if only some of the resources for a given parent are provided during such an incident as described above, the parent or resource must be included in the unreachable field. Further reading For listing across collections, see AIP-159.",
    'tags': '',
    'url': '/217',
  },
{
    'title': "Batch methods: Get",
    'text': "Batch methods: Get Some APIs need to allow users to get a specific set of resources at a consistent time point (e.g. using a read transaction). A batch get method provides this functionality. Guidance APIs may support Batch Get using the following pattern: rpc BatchGetBooks(BatchGetBooksRequest) returns (BatchGetBooksResponse) { option (google.api.http) = { get: \"/v1/{parent=publishers/*}/books:batchGet\" }; } The RPC\u0027s name must begin with BatchGet. The remainder of the RPC name should be the plural form of the resource being retrieved. The request and response messages must match the RPC name, with -Request and -Response suffixes. The HTTP verb must be GET. The HTTP URI must end with :batchGet. The URL path should represent the collection for the resource, matching the collection used for simple CRUD operations. If the operation spans parents, a dash (-) may be accepted as a wildcard. There must not be a body key in the google.api.http annotation. The operation must be atomic: it must fail for all resources or succeed for all resources (no partial success). For situations requiring partial failures, List (AIP-132) methods should be used. If the operation covers multiple locations and at least one location is down, the operation must fail. Request message The request for a batch get method should be specified with the following pattern: message BatchGetBooksRequest { // The parent resource shared by all books being retrieved. // Format: publishers/{publisher} // If this is set, the parent of all of the books specified in `names` // must match this field. string parent = 1; // The names of the books to retrieve. // A maximum of 1000 books can be retrieved in a batch. // Format: publishers/{publisher}/books/{book} repeated string names = 2; } A parent field should be included to facilitate inclusion in the URI as well to permit a single permissions check. If a caller sets this field, and the parent collection in the name of any resource being retrieved does not match, the request must fail. This field should be required if only 1 parent per request is allowed. The request message must include a repeated field which accepts the resource names specifying the resources to retrieve. The field should be named names. If no resource names are provided, the API should error with INVALID_ARGUMENT. Other fields besides name may be \"hoisted\" from the standard Get request. There is no way to allow for these fields to accept different values for different resources; if this is needed, use the alternative request message form. Batch get should not support pagination because transactionality across API calls would be extremely difficult to implement or enforce, and the request defines the exact scope of the response anyway. The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. The comment above the names field should document the maximum number of requests allowed. Response message The response for a batch get method should be specified with the following pattern: message BatchGetBooksResponse { // Books requested. repeated Book books = 1; } The response message must include one repeated field corresponding to the resources being retrieved. The order of books in the response must be the same as the names in the request. Nested request objects If the standard Get request message contains a field besides the resource name that needs to be different between different resources being requested, the batch message may alternatively hold a repeated field of the standard Get request message. This is generally discouraged unless your use case really requires it. The request for a batch get method using this approach should be specified with the following pattern: message BatchGetBooksRequest { // The parent resource shared by all books being retrieved. // Format: publishers/{publisher} // If this is set, the parent field in the GetBookRequest messages // must either be empty or match this field. string parent = 1; // The requests specifying the books to retrieve. // A maximum of 1000 books can be retrieved in a batch. repeated GetBookRequest requests = 2; } A parent field should be included. If a caller sets this field, and the parent collection in the name of any resource being retrieved does not match, the request must fail. This field should be required if only 1 parent per request is allowed. The request message must include a repeated field which accepts the request messages specifying the resources to retrieve, as specified for standard Get methods. The field should be named requests. Other fields may be \"hoisted\" from the standard Get request, which means that the field can be set at either the batch level or child request level. Similar to parent, if both the batch level and child request level are set for the same field, the values must match. Batch get should not support pagination because transactionality across API calls would be extremely difficult to implement or enforce, and the request defines the exact scope of the response anyway. The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. The comment above the requests field should document the maximum number of requests allowed. Changelog 2020-03-24: Clarified behavior if no resource names are sent. 2019-09-11: Changed the primary recommendation to specify a repeated string instead of a repeated standard Get request message. Moved the original recommendation into its own section. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/231',
  },
{
    'title': "Batch methods: Create",
    'text': "Batch methods: Create Some APIs need to allow users to create multiple resources in a single transaction. A batch create method provides this functionality. Guidance APIs may support Batch Create using the following pattern: rpc BatchCreateBooks(BatchCreateBooksRequest) returns (BatchCreateBooksResponse) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books:batchCreate\" body: \"*\" }; } The RPC\u0027s name must begin with BatchCreate. The remainder of the RPC name should be the plural form of the resource being created. The request and response messages must match the RPC name, with -Request and -Response suffixes. However, in the event that the request may take a significant amount of time, the response message must be a google.longrunning.Operation which ultimately resolves to the -Response type. The HTTP verb must be POST. The HTTP URI must end with :batchCreate. The URL path should represent the collection for the resource, matching the collection used for simple CRUD operations. If the operation spans parents, a dash (-) may be accepted as a wildcard. The body clause in the google.api.http annotation should be \"*\". The operation must be atomic: it must fail for all resources or succeed for all resources (no partial success). If the operation covers multiple locations and at least one location is down, the operation must fail. Request message The request for a batch create method should be specified with the following pattern: message BatchCreateBooksRequest { // The parent resource shared by all books being created. // Format: publishers/{publisher} // If this is set, the parent field in the CreateBookRequest messages // must either be empty or match this field. string parent = 1; // The request message specifying the resources to create. // A maximum of 1000 books can be created in a batch. repeated CreateBookRequest requests = 2; } A parent field should be included. If a caller sets this field, and the parent field of any child request message does not match, the request must fail. The parent field of child request messages can be omitted if the parent field in this request is set. This field should be required if only 1 parent per request is allowed. The request message must include a repeated field which accepts the request messages specifying the resources to create, as specified for standard Create methods. The field should be named requests. Other fields may be \"hoisted\" from the standard Create request, which means that the field can be set at either the batch level or child request level. Similar to parent, if both the batch level and child request level are set for the same field, the values must match. Fields which must be unique cannot be hoisted (e.g. Customer-provided id fields). The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. The comment above the requests field should document the maximum number of requests allowed. Response message The response for a batch create method should be specified with the following pattern: message BatchCreateBooksResponse { // Books created. repeated Book books = 1; } The response message must include one repeated field corresponding to the resources that were created. Changelog 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/233',
  },
{
    'title': "Batch methods: Update",
    'text': "Batch methods: Update Some APIs need to allow users to modify a set of resources in a single transaction. A batch update method provides this functionality. Guidance APIs may support Batch Update using the following pattern: rpc BatchUpdateBooks(BatchUpdateBooksRequest) returns (BatchUpdateBooksResponse) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books:batchUpdate\" body: \"*\" }; } The RPC\u0027s name must begin with BatchUpdate. The remainder of the RPC name should be the plural form of the resource being updated. The request and response messages must match the RPC name, with -Request and -Response suffixes. However, in the event that the request may take a significant amount of time, the response message must be a google.longrunning.Operation which ultimately resolves to the -Response type. The HTTP verb must be POST. The HTTP URI must end with :batchUpdate. The URL path should represent the collection for the resource, matching the collection used for simple CRUD operations. If the operation spans parents, a dash (-) may be accepted as a wildcard. The body clause in the google.api.http annotation should be \"*\". The operation must be atomic: it must fail for all resources or succeed for all resources (no partial success). If the operation covers multiple locations and at least one location is down, the operation must fail. Request message The request for a batch update method should be specified with the following pattern: message BatchUpdateBooksRequest { // The parent resource shared by all books being updated. // Format: publishers/{publisher} // If this is set, the parent field in the UpdateBookRequest messages // must either be empty or match this field. string parent = 1; // The request message specifying the resources to update. // A maximum of 1000 books can be modified in a batch. repeated UpdateBookRequest requests = 2; } A parent field should be included. If a caller sets this field, and the parent collection in the name of any resource being updated does not match, the request must fail. This field should be required if only 1 parent per request is allowed. The request message must include a repeated field which accepts the request messages specifying the resources to update, as specified for standard Update methods. The field should be named requests. Other fields may be \"hoisted\" from the standard Update request, which means that the field can be set at either the batch level or child request level. Similar to parent, if both the batch level and child request level are set for the same field, the values must match. The update_mask field is a good candidate for hoisting. The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. The comment above the names field should document the maximum number of requests allowed. Response message The response for a batch update method should be specified with the following pattern: message BatchUpdateBooksResponse { // Books updated. repeated Book books = 1; } The response message must include one repeated field corresponding to the resources that were updated. Changelog 2019-09-11: Fixed the wording about which child field the parent field should match. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/234',
  },
{
    'title': "Batch methods: Delete",
    'text': "Batch methods: Delete Some APIs need to allow users to delete a set of resources in a single transaction. A batch delete method provides this functionality. Guidance Batch delete methods are specified using the following pattern: rpc BatchDeleteBooks(BatchDeleteBooksRequest) returns (google.protobuf.Empty) { option (google.api.http) = { post: \"/v1/{parent=publishers/*}/books:batchDelete\" body: \"*\" }; } The RPC\u0027s name must begin with BatchDelete. The remainder of the RPC name should be the plural form of the resource being deleted. The request message must match the RPC name, with a -Request suffix. The response message should be google.protobuf.Empty. If the resource is soft deleted, the response message should be a response message containing the updated resources. In the event that the request may take a significant amount of time, the response message must be a google.longrunning.Operation which resolves to the correct response. The HTTP verb must be POST (not DELETE). The HTTP URI must end with :batchDelete. The URL path should represent the collection for the resource, matching the collection used for simple CRUD operations. If the operation spans parents, a dash (-) may be accepted as a wildcard. The body clause in the google.api.http annotation should be \"*\". The operation should be atomic: it should fail for all resources or succeed for all resources (no partial success). If the operation covers multiple locations and at least one location is down, the operation must fail. Request message The request for a batch delete method should be specified with the following pattern: message BatchDeleteBooksRequest { // The parent resource shared by all books being deleted. // Format: publishers/{publisher} // If this is set, the parent of all of the books specified in `names` // must match this field. string parent = 1; // The names of the books to delete. // A maximum of 1000 books can be deleted in a batch. // format: publishers/{publisher}/books/{book} repeated string names = 2; } A parent field should be included. If a caller sets this field, and the parent collection in the name of any resource being deleted does not match, the request must fail. This field should be required if only 1 parent per request is allowed. The request message must include a repeated field which accepts the resource names specifying the resources to delete. The field should be named names. Other fields besides name may be \"hoisted\" from the standard Delete request. There is no way to allow for these fields to accept different values for different resources; if this is needed, use the alternative request message form. The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. The comment above the names field should document the maximum number of requests allowed. Filter-based matching must not be supported. Request message containing standard delete request messages If the standard Delete request message contains a field besides the resource name that needs to be different between different resources being requested, the batch message may alternatively hold a repeated field of the standard Delete request message. This is generally discouraged unless your use case really requires it. The request for a batch delete method should be specified with the following pattern: message BatchDeleteBooksRequest { // The parent resource shared by all books being deleted. // Format: publishers/{publisher} // If this is set, the parent of all of the books specified in the // DeleteBookRequest messages must match this field. string parent = 1; // The requests specifying the books to delete. // A maximum of 1000 books can be deleted in a batch. repeated DeleteBookRequest requests = 2; } A parent field should be included. If a caller sets this field, and the parent collection in the name of any resource being deleted does not match, the request must fail. This field should be required if only 1 parent per request is allowed. The request message must include a repeated field which accepts the request messages specifying the resources to delete, as specified for standard Delete methods. The field should be named requests. Other fields may be \"hoisted\" from the standard Delete request, which means that the field can be set at either the batch level or child request level. Similar to parent, if both the batch level and child request level are set for the same field, the values must match. Fields which must be unique cannot be hoisted (e.g. etag). The request message must not contain any other required fields, and should not contain other optional fields except those described in this or another AIP. The comment above the requests field should document the maximum number of requests allowed. Filter-based matching must not be supported unless it is infeasible to support critical use cases without it, because it makes it too easy for users to accidentally delete important data. If it is unavoidable, see AIP-165. Response message (soft-delete only) In the case where a response message is necessary because the resource is soft-deleted, the response should be specified with the following pattern: message BatchDeleteBooksResponse { // Books deleted. repeated Book books = 1; } The response message must include one repeated field corresponding to the resources that were soft-deleted. Changelog 2020-03-27: Added reference to AIP-165 for criteria-based deletion. 2019-10-11: Changed the primary recommendation to specify a repeated string instead of a repeated standard Delete message. Moved the original recommendation into its own section. 2019-09-11: Fixed the wording about which child field the parent field should match. 2019-08-01: Changed the examples from \"shelves\" to \"publishers\", to present a better example of resource ownership.",
    'tags': '',
    'url': '/235',
  },
{
    'title': "Project identifiers",
    'text': "Project identifiers Historically, Google had two kinds of projects: API projects and App Engine projects. API projects used project numbers (e.g. 12345) as identifiers, and App Engine projects used project IDs (e.g. happy-armadillo-789) as identifiers. Later, Google converged API projects and App Engine projects, so now each project has both unique and immutable identifiers. The two types of identifiers are used differently in different contexts, and create a lot of complexity for application development. One critical issue is that applications cannot reliably join data from different services, because different services use different project identifiers. Guidance TL;DR: The project number is the canonical identifier, and the project ID is an alias, and behaves as such. Additionally, third-party services are unable to accept project IDs. The rationale for this is: Each resource should always have one canonical identifier. Because Google\u0027s privacy policy restricts the use of project IDs, both internally and with partners, only the project number can be the canonical identifier. Translating from an alias to a canonical identifier should be consistent everywhere, including referring to projects. Returning resources with project numbers increases the chances that these are what users store, which may be important if using third-party services. Google APIs Externally-facing Google APIs should accept both project IDs and project numbers for incoming API requests. However, the project number is the canonical identifier, and therefore APIs must use project numbers in responses, regardless of whether they were sent a project ID or a project number. There are two exceptions to this rule: Error responses must return the originally-provided value without modification. Error responses must not perform any translation between project IDs and project numbers. If a service receives a resource name for a resource that the service does not own, it should not perform any translation between project IDs and project numbers for those resource names. Internal Google services Internal Google services must use project numbers for internal data storage and for output. Project identifiers are widely used as storage keys, which often appear in logs and metrics. Project IDs are user-settable and thus considered PII and user data, but project numbers are not. Therefore, when an internal service calls an external Google APIs, it should use project numbers for making API requests. Third-party services Third-party services that are integrated with Google Cloud Platform must only store or provide project numbers. Google\u0027s privacy policy prohibits sharing project IDs with third-party services, or providing a service for third-party services to translate between project IDs and project numbers at runtime. Project identifier format APIs must use project resource names as defined by the Resource Manager API to refer to projects, such as projects/123456. This allows the same API to work with other resources similar to projects, such as organizations and folders. Changelog 2019-08-11: Add an exception for resources that a service does not own. 2019-06-19: Clarify how error messages should be treated 2019-06-10: Minor language and organization tweaks",
    'tags': '',
    'url': '/cloud/2510',
  },
{
    'title': "Parameter-dependent arguments",
    'text': "Parameter-dependent arguments When designing CLI commands, a common scenario is that a command corresponding to some conceptual action may take different, largely non-overlapping arguments depending on the value of a particular parameter. For instance, suppose we\u0027re designing a new gcloud surface for managing images, and we need a command that formats an image as JPEG, GIF, or PNG. Regardless of the image format, the command will need arguments for the source and destination files, but otherwise depending on the format, an entirely different set of options will apply. JPEG, for example, might take arguments for smoothing, subsampling, and DCT method, which are only relevant for JPEG images. GIF, on the other hand, might take arguments for controlling animated gifs e.g. whether to loop forever, and a delay time in between frames. Finally, PNG might take arguments for color type and bits per channel. Guidance When the parameter-specific arguments are numerous relative to the other arguments, create a command group for the action, with separate subcommands named after each of the parameter values. In the example above, we would thus create a gcloud images format command group, with subcommands called jpeg, gif, and png. These subcommands can then take their own format-specific flags. Example usage: $ gcloud images format jpeg --help $ gcloud images format jpeg --source-file=foo --destination-file=bar \\ --dct-method=integer --smoothing=0.1 --subsampling=4:4:4 $ gcloud images format png --source-file=foo --destination-file=bar \\ --color-type=0 --bits-per-channel=16 $ gcloud images format gif --source-file=foo --destination-file=bar \\ --loop-forever --frame-delay=1ms It\u0027s possible that over time more and more arguments are added that are common to all parameters. In that case, it may make sense to instead use a single command that takes an argument for the parameter. This can be done without breaking backward compatibility by making the parameter a positional argument. In the example above, this would involve changing format from a command group to a command, and having it take a positional image format argument which can be one of: jpeg, gif, or png. Note that all the example commands above would still function identically (except for the first one, but since it only affects help text it\u0027s not considered a breaking change.) Alternatives considered There are several other possibilities for the design of such a command, outlined below: Single command with an explicit flag corresponding to the parameter In the example, this would involve a --type flag to specify the image format: $ gcloud images format --source-file=source --destination-file=dest \\ --type=JPEG --dct-method=integer --smoothing=0.1 --subsampling=4:4:4 $ gcloud images format --source-file=source --destination-file=dest \\ --type=GIF --loop-forever --frame-delay=1ms $ gcloud images format --source-file=source --destination-file=dest \\ --type=PNG --color-type=0 --bits-per-channel=16 Conceptually it makes the most sense to just have a single format command. However, this approach has several drawbacks: Unnecessary help text. The user will see all of the format-specific options, most of which will be irrelevant since they apply to different formats. In graphical image editing programs such as Photoshop or GIMP, the UI can selectively show these format-specific options once the user chooses the desired format from a dropdown. On the CLI, however, we have no such capability because the help text is statically generated. Additional logic needed for validation. Since some arguments will be invalid depending on the format, the command author needs to ensure specifying invalid combinations returns an appropriate error. While this can be accomplished with appropriately nested mutex groups, the nesting has the potential to become overly deep and complex. Multiple commands named after the action hyphenated with the parameter value In the example, this would look like: $ gcloud images format-jpeg ... $ gcloud images format-gif ... $ gcloud images format-png ... This is similar to the recommended design in that each parameter value gets its own command. However, there are disadvantages: Backward compatibility. If in the future it becomes desirable to make the parameter value an argument to a single command, this would necessitate a breaking change. It\u0027s less elegant from a command tree layout perspective. Grouping the parameter-specific commands into a command group allows for a natural decomposition of the command space, in keeping with gcloud\u0027s CLI design philosophy, and allows for progressive disclosure in the help text and in autocompletion.",
    'tags': '',
    'url': '/cloud/2602',
  },
{
    'title': "List command arguments",
    'text': "List command arguments Some list requests take argument(s) for the parent collection in which to list resources. For example, suppose an API has book resources belonging to shelf resources, and consider a request to list books in a shelf: message ListBooksRequest { // Required. The shelf containing the books to list, for example, // \"projects/project1/shelves/shelf1\". string parent = 1; // The maximum number of items to return. int32 page_size = 2; // The next_page_token value returned from a previous List request, if any. string page_token = 3; } For the corresponding gcloud list command, we have the choice between gcloud shelves books list SHELF (positional) and gcloud shelves books list --shelf=SHELF (flag). Guidance All list command arguments should be flags, not positionals. In gcloud\u0027s resource model, command groups generally correspond to resources, and the positional arguments for commands in a group are reserved for those resources. In the case of a list command that takes an argument, the argument will refer to the parent resource and not the command group\u0027s resource; therefore, it should be a flag instead of a positional. In the example above, the list command takes an argument for a shelf. Commands in the books command group should reserve positional arguments for book resources. Thus, the shelf argument for the list command should be a flag: gcloud shelves books list --shelf=SHELF",
    'tags': '',
    'url': '/cloud/2603',
  },
{
    'title': "Numeric arguments",
    'text': "Numeric arguments Some API fields refer to either a percentage or a fixed number. For example, in GCE a group can be created with a configurable limit for either the percentage or number of instances in the group that can undergo maintenance simultaneously: message ConcurrencyControl { enum LimitType { INVALID = 0; PERCENT = 1; FIXED = 2; } optional int32 concurrency_limit = 1; optional LimitType limit_type = 2; } Guidance Flag layout In gcloud, such API fields should correspond to a mutually exclusive group consisting of two flags: one for specifying a number, and the other for specifying a percentage. The API field in the example above would thus correspond to the following surface specification in gcloud: - group: mutex: true arguments: - name: concurrency-limit help_text: | Maximum number of instances in the group that can undergo maintenance simultaneously. - name: concurrency-limit-percent help_text: | Integer from 0 to 100 representing the maximum percentage of instances in the group that can undergo maintenance simultaneously. Flag naming Any flag taking a percentage should end with -percent (not -percentage). Flag type Any flag taking a percentage should take an integer from 0 to 100. If more precision is required, it is acceptable to take a float from 0 to 100. Alternatives considered One flag, where percentage is specified if the flag value ends with \u0027%\u0027, and number is assumed otherwise In other words, to specify 10% one would use --concurrency-limit=10%, and to specify 10 instances one would use --concurrency-limit=10. This would be a cleaner design since it naturally maps a single concept (the limit) to a single flag (--concurrency-limit), avoiding the need for additional flags that clutter the help text. However, the main reason not to prefer this approach is that it significantly increases the risk of user error. For instance, suppose a group currently contains 20 instances with a concurrency limit of 10%, and a user wishes to update the limit to 20%. If the user issues a describe command (or performs a GET request) to see the existing limit, the API response will contain something like: concurrencyControl: concurrencyLimit: 10 limitType: PERCENT It\u0027s easy for the user to gloss over limitType and just assume that --concurrency-limit=20 will update the limit to 20%. However, in reality this would set the limit to 20 instances (100% of the group), potentially leading to catastrophic consequences. The recommend approach avoids this ambiguity at the expense of some elegance, but we deem this tradeoff necessary. One flag, where percentage is specified if the flag value ends with \u0027%\u0027, and number is specified if the flag value ends with \u0027n\u0027 In other words, to specify 10% one would use --concurrency-limit=10%, and to specify 10 instances one would use --concurrency-limit=10n. It would be an error to provide a value that doesn\u0027t end in \u0027%\u0027 or \u0027n\u0027. While this avoids the potential for a user to confuse percentages and numbers, requiring \u0027n\u0027 at the end of a number is inelegant UX. A number should obviously resemble a number, and the choice of \u0027n\u0027 is also rather arbitrary. Exceptions This CIP does not apply for API fields like timestamps, where we allow the user to enter either absolute times or durations in the same flag. This is because absolute times and durations have natural formats that differ, and thus there\u0027s no potential for a user to confuse the two. In general if this is the case, one flag that accepts both formats should be preferred for the sake of UX simplicity.",
    'tags': '',
    'url': '/cloud/2604',
  },
{
    'title': "Application Default Credentials",
    'text': "Application Default Credentials Google auth libraries use a strategy called Application Default Credentials (ADC) to detect and select credentials based on environment or context. With ADC, developers should be able to run the code in different environments and the supporting systems fetch the appropriate credentials based on each environment in an effortless manner. Auth libraries following the standards in these AIPs are known as \"Google Unified Auth Clients\", or GUAC for short. The resulting libraries are colloquially called GUACs. Note: Because this AIP describes guidance and requirements in a language-neutral way, it uses generic terminology which may be imprecise or inappropriate in certain languages or environments. Guidance Credential Types This section outlines the supported credential types of the ADC. Gcloud Credential: A credential provided by the Gcloud tool that identifies a human user that needs to authenticate to access Google APIs. The auth libraries must support this credential type. Service Account Key: A credential that identifies a non-human user that needs to authenticate to access Google APIs. The auth libraries must support this credential type. OAuth Client ID: A credential that identifies the client application which allows human users to sign-in through 3-legged OAuth flow, which grants the permissions to the application to access Google APIs on behalf of the human user. The auth libraries may support this credential type. Environment Variables The auth libraries must support the following environment variables to allow developers to provide authentication configuration for their application: GOOGLE_APPLICATION_CREDENTIALS: The specified value will be used as the full path for ADC to locate the credentials file. The credentials file should be one of the following types: - Gcloud credentials - Service account key The credentials **may** be the OAuth Client ID if it is supported by the auth library. Credentials file path specified at the program level (e.g. via client options) **must** have priority over the value of this environment variable. GOOGLE_API_KEY: API keys are a simple encrypted string that identifies an application, which are useful for accessing public data anonymously. The specified value of this environment variable should be used as the API key for the API requests. This value must be overridden by any user specified credentials at the programming level (e.g. through client options). And it must be ignored if GOOGLE_APPLICATION_CREDENTIALS is specified. GOOGLE_API_USE_CLIENT_CERTIFICATE: The specified value must be either true or false. The client certificate must be ignored if this variable is set to false. The default value is false if the value is unset. GOOGLE_API_USE_CLIENT_CERTIFICATE=[true|false] Inputs \u0026 Outputs From the input/output perspective, the inputs of ADC should be the credentials as well as the underlying environment such as environment variables or metadata service that provides these credentials. For example, the GOOGLE_APPLICATION_CREDENTIALS environment variable can provide the default credential JSON as the input here, or the well-known path that gCloud uses to store the default user credential JSON. The output is the access token that application can use to access the Google APIs. This access token may be a bearer token, a certificate bound token or STS depending on the chosen authentication flow. Expected Behavior This section outlines the expected behavior of the ADC. Auth libraries must implement these concepts in order to be considered complete. digraph d_front_back { rankdir=TB; ranksep=0.3; node [ style=\"filled,solid\" shape=box fontname=\"Roboto\" ]; check_env_var [ label=\"1. Check Environment Variables\" ]; load_credentials [ label=\"2. Load Credentials\" ]; check_metadata [ label=\"3. Check Metadata Service Credentials\" ]; auth_flows [ label=\"4. Determine Auth Flows\" ]; execute [ label=\"5. Execute Auth Flows\" ]; sts [ label=\"6. Apply STS\" ]; check_env_var -\u003e load_credentials -\u003e check_metadata -\u003eauth_flows -\u003e execute -\u003e sts; load_credentials -\u003e auth_flows; } Check environment variables Check GOOGLE_APPLICATION_CREDENTIALS 1. If set, go to step (2.2) Check GOOGLE_API_KEY 1. If set, use the provided API key [END] If neither of above is set, go to step (2) Load credentials Check gcloud default credentials through its default path 1. If found go to step (2.2) 2. Otherwise go to step (3) Check the provided credential type 1. If the credential is gcloud credentials, go to step (4) 2. If the credential is a service account key JSON, go to step (4) 3. If the credential is unknown type, return an error saying that [END] Credentials not found [END] Check Metadata Service Credentials If true, use the metadata service flow to get an access token associated with the current environment [END] If false, go to step (2.3) Determine auth flows If the credential is gcloud credential go to step (5.3) If scope is provided by the developer go to step (5.1) Otherwise, go to step (5.2) Execute auth flows Use 2LO flow to exchange for an access token 1. If client certificate is presented, the exchanged token will be a certificate bind token and then go to step (6) Use self-signed JWT flow to create an access token locally. 1. If certificate is presented, embed the certificate into the JWT and then go to step (6). 2. Otherwise, use the regular self-signed JWT flow and then go to step (6) Use user identity flow to exchange for an access token and then go to step (6) Check if STS is needed If the given TLD is not a googleapis.com domain and extra system parameters are provided (e.g. quota project override), call STS to exchange for a STS token. (a.k.a. UAT). [END] Otherwise, use the access token directly. [END]",
    'tags': '',
    'url': '/auth/4110',
  },
{
    'title': "Self-signed JWT-based Access Token",
    'text': "Self-signed JWT-based Access Token JWT access token for Google APIs was introduced in 2014 to provide a more efficient auth stack for Cloud APIs being accessed via service accounts by bypassing the intermediate step of exchanging client assertions for OAuth tokens. It becomes a standard authentication method, such that many Cloud APIs accept JWT-based access tokens that are locally signed by the service account private key. Note: Because this AIP describes guidance and requirements in a language-neutral way, it uses generic terminology which may be imprecise or inappropriate in certain languages or environments. Guidance This section describes the general guidance of supporting a self-signed JWT-based token. Default Authentication Method For Service Account Keys Considering its efficiency (bypassing the exchanging step), ADC should use self-signed JWT as the default authentication flow for service account keys. In other words, ADC should choose the OAuth flow over self-signed JWT only if the scope is explicitly provided to the auth library. Expected Behavior To support the self-signed JWT-based token, the auth libraries must follow the steps below: Load the service account ID JSON file. Please note that the self-signed JWT-based token only supports service account ID credential type. Using any standard JWT library, such as one found at jwt.io, create a JWT with a header and payload like the following example: ```json { \"alg\": \"RS256\", \"typ\": \"JWT\", \"kid\": \"abcdef1234567890\" } { \"iss\": \"123456-compute@developer.gserviceaccount.com\", \"sub\": \"123456-compute@developer.gserviceaccount.com\", \"aud\": \"https://firestore.googleapis.com/\", \"iat\": 1511900000, \"exp\": 1511903600 } ``` _ For the `kid` field in the header, specify the service account\u0027s private key ID. You can find this value in the `private_key_id` field of the service account JSON file. _ For the `iss` and `sub` fields, specify the service account\u0027s email address. You can find this value in the `client_email` field of the service account JSON file. _ For the `aud` field, specify the audience. The default audience value **should** be `https://[API_ENDPOINT]/`. (e.g. `https://pubsub.googleapis.com/`) _ For the `iat` field, specify the current Unix time, and for the `exp` field, the value **must** be exactly 3600 seconds later, when the JWT will expire. Sign the JWT with RSA-256 using the private key found in the service account JSON file.",
    'tags': '',
    'url': '/auth/4111',
  },
{
    'title': "Client library generators",
    'text': "Client library generators API guidelines exist in order to promote simple, intuitive, and consistent APIs. Users familiar with APIs that generally adhere to AIP guidance are able to take what they learn in prior APIs and apply it to new ones. Client libraries provide a mechanism for users to get started with APIs more quickly, by simplifying common concerns (such as auth) and by a language-native way to call API endpoints and receive language-native responses. However, for these libraries to provide the most value, they also must be simple, intuitive, and consistent. Code generators provide a means for producing consistent client libraries at scale. Code generators following the standards in these AIPs are known as \"generated API client generators\", or GAPIC generators for short. The resulting libraries are colloquially called GAPICs. Note: Because this AIP describes guidance and requirements in a language-neutral way, it uses generic terminology which may be imprecise or inappropriate in certain languages or environments (for example, the use of the term class even though languages such as Go do not have classes). This AIP\u0027s particular use of vocabulary is best understood as an explanation of principles, and precise adherence to exact vocabulary in this AIP is not an expectation. Guidance Protobuf plugins Code generators must be implemented as plugins to protoc, the protocol buffer compiler. The plugin system allows plugins to be written in any language, and plugins should ordinarily be written in the language being targeted, in order to take advantage of in-language tooling, and to ensure that experts in the target environment are able to meaningfully contribute. protoc expects plugins to be an executable in $PATH, and named protoc-gen-{plugin_name}, corresponding to the --{plugin_name}_out option sent to the protoc executable. For a plugin creating client libraries for a specific language, the option name should follow the convention --{lang}_gapic_out (meaning the corresponding plugin executable is named protoc-gen-{lang}_gapic). Plugins must accept a serialized CodeGeneratorRequest object (defined in plugin.proto) on stdin; the bulk of this is a series of FileDescriptorProto messages (defined in descriptor.proto). Plugins must emit a serialized CodeGeneratorResponse object (defined in plugin.proto) on stdout. CLI options Code generators should be able to run without any options or flags if at all possible, and be able to generate a valid library from only the protos. If options are required, protoc allows them to be passed as --{plugin_name}_opt, and the string provided here becomes set as the parameter string on the CodeGeneratorRequest. Code generators must not rely on environment variables for configuration. Expected behavior This section outlines the expected behavioral attributes of the output of the client library generator (in other words: the libraries that the generators write). Client libraries must implement these concepts in order to be considered complete. Services and methods Each of the service and rpc directives in the requested protos must be represented in the client library output, unless the language or transport is unable to support it. Note: While how to accomplish this may vary from language to language, in most classical languages it is probably a class for each service, containing methods for each RPC. The classes generated for each service directive must honor the google.api.default_host annotation if it is provided, and use that host as the default hostname. These classes should provide a mechanism for the end user to override the hostname. If the google.api.default_host annotation is not present on the service directive, then the generated class should require a hostname when it is instantiated. Additionally, if the classes generated for each service support using OAuth and service credentials, they must honor the google.api.oauth_scopes annotation (if it is provided), and use these scopes by default. Finally, service classes must also accept credentials, which are used appropriately when requests are made. (Accepting a custom gRPC channel satisfies this requirement.) Long-running operations An RPC is considered to be a \"long-running\" RPC if (and only if) the RPC\u0027s return type is google.longrunning.Operation. Any API which has one or more RPCs returning an Operation is expected to implement the Operations service. Because the response and metadata fields in Operation are of the type google.protobuf.Any, it is necessary to know what message to use to deserialize them. This is annotated on the RPC using the google.longrunning.operation_info annotation. Note: The values in this struct are strings, not message objects; the code generator uses the string to determine the appropriate message to use. Strings with no period (.) character refer to a message in the same proto package. Code generators should fail with an error if a type is provided in the operation_info annotation which was not imported, or if no response type or metadata type is provided. Code generators should fail with an error if either the response_type or metadata_type keys are omitted. Client libraries must honor the LRO interface; if an RPC has an Operation as its return type, the generated method must intercept it and return an appropriate idiomatic object for resolving the LRO (such as a Future or Promise bound to the underlying Operation object). Streaming Client libraries must implement streaming to the extent that their supporting transports allow. An RPC is considered to be streaming if the stream keyword is present on the argument or response type. This is present in the MethodDescriptorProto message using the client_streaming and server_streaming keys.",
    'tags': '',
    'url': '/client-libraries/4210',
  },
{
    'title': "Client-side retry",
    'text': "Client-side retry Many APIs have error modes that a client should retry. These error modes vary across APIs, leaving users to hand-write retry logic around client libraries based on available documentation. Client libraries have the opportunity to help by implementing automatic client-side retries of well-known error modes. Guidance Client libraries should provide automatic, client-side retry logic. Client libraries with automatic client-side retry logic should provide a mechanism for users to specify error codes to be retried and delays for those retries. Client libraries for API systems that support remotely-resolved client retry configuration should respect the remotely-resolved configuration. However, user configuration must be honored. Client library generators implementing this feature must accept a retry configuration. This retry configuration may be supplied via a protoc plugin option. In the absence of a given retry configuration, client library generators should not generate a default retry configuration. Retry implementation Client libraries should make client-side retry transparent to the user. The user should not have to opt-in to client-side retry explicitly, but the user must have a way to disable client-side retry altogether. Retry configuration mechanisms Client libraries should surface a mechanism through which users may control the client-side retry configuration, including disabling client-side retry altogether. For example, Go client libraries for gRPC services can supply an option, WithDisableRetry, at client initialization to disable the use of the automatic client-side retry logic. opts := []grpc.DialOption{ grpc.WithDisableRetry(), grpc.WithTransportCredentials(creds), } cc, err := grpc.Dial(\"my.api.net:443\", opts...) if err != nil { // ... } Remotely-resolved client configuration Some API systems have built-in mechanisms for clients to retrieve a remotely-defined configuration that includes client-side retry configuration. For example, gRPC supports the resolution of client configuration that includes configuration for automatic client-side retry. Client libraries should respect the remotely-resolved configuration, except when a user overrides it via the aforementioned client library retry configuration mechanisms. Client library generator retry configuration Client library generators that implement client-side retry must accept a retry configuration. This is to enable API producers to supply a retry configuration that best-suits their service. For example, gRPC client-side retry is configured with a RetryPolicy within a gRPC Service Config. Here is a configuration that applies the RetryPolicy to all methods in the google.example.library.v1.LibraryService service, except for those that are explicitly named which get no RetryPolicy. { \"methodConfig\": [{ \"name\": [{ \"service\": \"google.example.library.v1.LibraryService\" }], \"waitForReady\": true, \"timeout\": \"60s\", \"retryPolicy\": { \"maxAttempts\": 3, \"initialBackoff\": \"0.01s\", \"maxBackoff\": \"60s\", \"backoffMultiplier\": 1.3, \"retryableStatusCodes\": [\"UNAVAILABLE\", \"UNKNOWN\"] } }, { \"name\": [ { \"service\": \"google.example.library.v1.LibraryService\", \"method\": \"CreateShelf\" }, { \"service\": \"google.example.library.v1.LibraryService\", \"method\": \"DeleteShelf\" }, { \"service\": \"google.example.library.v1.LibraryService\", \"method\": \"MergeShelves\" }, { \"service\": \"google.example.library.v1.LibraryService\", \"method\": \"CreateBook\" }, { \"service\": \"google.example.library.v1.LibraryService\", \"method\": \"DeleteBook\" }, { \"service\": \"google.example.library.v1.LibraryService\", \"method\": \"UpdateBook\" }, { \"service\": \"google.example.library.v1.LibraryService\", \"method\": \"MoveBook\" } ], \"waitForReady\": true, \"timeout\": \"60s\" }] } The retry configuration may be a protoc plugin option. For example, a generator could accept the file path of the configuration with an option like: --{plugin_name}_opt=\"retry-config=/path/to/config.file\" In the absence of a retry configuration, a generator should not generate a \"default\" retry configuration. This results in a generated client library that does not retry anything unless configured to do so by the user. Further reading For which error codes to retry, see AIP-194.",
    'tags': '',
    'url': '/client-libraries/4221',
  },
{
    'title': "Routing headers",
    'text': "Routing headers In some situations, a gRPC API backend is able to route traffic more efficiently if it knows about some values in the request; however, the request payload can not be reasonably deconstructed on the wire to perform that routing. Guidance Code generators should look at URL-based variables declared in the google.api.http annotation and transcribe these into the x-goog-request-params header in unary calls. A URL-based variable is a variable declared as a key in curly braces in the URI string. For example: rpc CreateTopic(CreateTopicRequest) { option (google.api.http).post = \"{parent=projects/*}/topics\"; } Note: the ommission of a path segment in the variable template, {parent} for example, is equivalent to {parent=*} and should be parsed. In this case, the applicable variable is parent, and it refers to the parent field in CreateTopicRequest. When the user provides an instance of CreateTopicRequest to the method (or once the client library has built it, in the case of method overloads), the client library must extract the key and value, and append them to the x-goog-request-params header. Both the key and the value must be URL-encoded per RFC 6570 \u00a73.2.2. This can be done with standard library URL encoding. For example, adding this header to a gRPC request in Go: md := metadata.Pairs(\"x-goog-request-params\", url.QueryEscape(\"parent\") + \"=\" + url.QueryEscape(req.GetParent())) Much like URL parameters, if there is more than one key-value pair, the \u0026 character is used as the separator. At runtime, if a named parameter is unset on the request message, it should not be included in the headers. If the google.api.http annotation contains additional_bindings, these patterns should be parsed for additional request parameters. Fields not duplicated in the top-level (or additional_bindings) pattern should be included in request parameters, encoded in the same way. Note: There is no additional annotation used for this; the presence of the key in any of the standard fields (get, post, put, patch, delete) on the google.api.http annotation is sufficient. Changelog 2020-04-21: Explicitly parse path variables missing a trailing segment. 2019-11-27: Include additional_bindings as a request parameter source. 2019-06-26: Fix wording and example of key-value pair encoding. 2019-06-20: Specify encoding of header parameters.",
    'tags': '',
    'url': '/client-libraries/4222',
  },
{
    'title': "Parsing resource names",
    'text': "Parsing resource names In resource-oriented design (AIP-121), resources represent the primary nouns within APIs, and often have resource names (AIP-122). These resource names convey information about the structure and hierarchy of the resource structure in that API. APIs accept these resource names as parameters when retrieving and modifying resources, and when referencing them in other objects. However, users may struggle to piece together resource names to send, and client libraries have the opportunity to make this easier through the use of helper components. Guidance Client libraries may provide helper classes or functions to make constructing resource names more straightforward. However, client libraries that choose to implement this feature must always accept the plain strings also, for two reasons: An existing API that adds resource descriptor annotations should be able to do so without incurring a breaking change. Resource name patterns occasionally evolve, and users need to be able to send and receive resource names that a statically-compiled client library may not yet acknowledge. Resource messages A resource in an API always has a message that describes the representation of that resource in that API. Client library generators are able to recognize these messages when they are annotated with the google.api.resource annotation: // A representation of a Topic in Pub/Sub. message Topic { option (google.api.resource) = { type: \"pubsub.googleapis.com/Topic\" pattern: \"projects/{project}/topics/{topic}\" }; // The resource\u0027s name. string name = 1; // And so on... } The type field provides the unified resource type name. Client libraries should name their helper component based on this value. The universal resource type usually (but not always) ends with a name that matches the name of the message. The pattern field provides the structure of this resource type\u0027s names. The components in braces represent variable substitutions. Client libraries implementing this feature must accept variables based on these names when building resource name strings. Variable substitution names are usually specified in snake_case, but this is not guaranteed. Client libraries should be able to accept any annotation that uses any sane case system. Patterns are usually slash-separated, but this is not guaranteed. Client libraries should use string interpolation to piece together the resource name. The defining message is expected to contain a field called name, which is the field holding the resource name. APIs are able to override the name field\u0027s name by setting the name_field property on the google.api.resource annotation. Code generators should fail with an error if a message is annotated as a resource and has no name field (either the default of name or the field provided in the name_field property of the annotation). Code generators should also fail with an error if the field is not a string). Multi-pattern resources Occasionally, a resource may have more than one pattern. The common case for this is when a resource can live under more than one parent type. In this situation, the pattern field on the annotation can be specified more than once: message LogEntry { option (google.api.resource) = { type: \"logging.googleapis.com/Log\" pattern: \"projects/{project}/logs/{log}\" pattern: \"organizations/{organization}/logs/{log}\" pattern: \"folders/{folder}/logs/{log}\" pattern: \"billingAccounts/{billing_account}/logs/{log}\" } // The resource\u0027s name. string name = 1; // And so on... } If necessary, client libraries may create a separate helper component for each pattern, and may provide a rollup component. Resources without messages Occasionally, a resource may be implicitly defined by an API service, but not have an explicit message representing that resource. (For example, the Firestore API defines databases as a common ancestor to its resources, but does not define a database message.) In this situation, APIs annotate the resource on the file instead of on a message, using the google.api.resource_definition annotation: option (google.api.resource_definition) = { type: \"firestore.googleapis.com/Database\" pattern: \"projects/{project}/databases/{database}\" }; Client library generators implementing this feature must generate the same utility components that would be generated when encountering a resource message. Referencing other resources APIs often use resource names for referencing fields defined elsewhere. This is particularly common with the request messages for the standard methods, such as Get and Update; however, resources and other structures use resource name strings as references also. Client libraries implementing this feature should also provide their helper components when resources are being referenced. Client libraries are able to recognize these fields when they are annotated with the google.api.resource_reference annotation: message GetTopicRequest { // The name of the topic to retrieve. string name = 1 [(google.api.resource_reference) = { type: \"pubsub.googleapis.com/Topic\" }]; } The resource reference references the unified resource type name. Some methods also refer to the parent of a type, and in situations where there are multiple parents, it is repetitive and error-prone to refer to each individual parent type. In these situations, API producers specify child_type rather than type: message ListLogEntriesRequest { // The collection of log entries to list. string parent = 1 [(google.api.resource_reference) = { child_type: \"logging.googleapis.com/Log\" }]; } In this situation, client library generators implementing this feature must derive the set of parent resources from the child type. Referencing an arbitrary resource Occasionally, a field may reference an arbitrary resource. In this case, APIs use the special value * in their resource reference. message GetIamPolicyRequest { string resource = 1 [(google.api.resource_reference) = { type: \"*\" }]; } In this situation, client library generators implementing this feature may provide a generic utility class or function to address that resource name. Complex resource ID path segments Warning: Complex resource ID path segments should not generally be used in new APIs. AIP-124 contains advice on handling many-to-many associations. Resource patterns may contain resource ID path segments which contain multiple pattern variables separated by a variable separator: message FeedItemTarget { option (google.api.resource) = { type: \"googleads.googleapis.com/FeedItemTarget\" pattern: \"customers/{customer}/feedItemTargets/{feed}~{feed_item}\" }; // The resource name of this event. string name = 1; // Other fields... } This is only used when the resource ID is naturally in multiple parts and it is useful for the user to be able to manipulate the separate ID parts. A variable separator is one character long, and must only one of: _, -, ., ~ (underscore, hyphen, period, tilde). A variable separator must not appear before the first pattern variable or after the last pattern variable. Backwards compatibility Client libraries implementing helper components for resources must conform to the following backwards-compatibility expectations: The addition of a google.api.resource annotation on an existing message must be a backwards-compatible change. An existing resource must be able to add new patterns (including the \"*\" wildcard pattern) without breaking changes as long as the following conditions are met: New patterns must always be appended to the list. New patterns must use a distinct sequence of collection identifiers (see AIP-122) compared with all existing patterns within this resource. The addition of a google.api.resource_reference annotation on an existing field must be a backwards-compatible change. Note: The ORIGINALLY_SINGLE_PATTERN and FUTURE_MULTI_PATTERN flags are deprecated, and must not be used. Further reading For more on resource names and patterns, see AIP-122. For more on unified resource types, see AIP-123. Changelog 2020-05-14: Added complex resource ID path segments. 2020-05-07: Updated backwards compatibility guidance. 2019-09-16: Added guidance for resources without messages.",
    'tags': '',
    'url': '/client-libraries/4231',
  },
{
    'title': "Method signatures",
    'text': "Method signatures In protocol buffer RPCs, each RPC takes exactly one argument: a message. However, sending a full message structure can be cumbersome in the case of extremely simple requests. Many RPCs provide information about which pieces of the request are important and commonly used. In many languages, functions and methods take multiple positional or keyword arguments. Guidance Some APIs provide annotations to hint how to effectively translate from a single request object to individual arguments, and client libraries may provide overloads based on these hints. However, client libraries implementing this feature must retain the default behavior of accepting the full request object. Put another way, if an API adds this annotation to an already-published API, the resulting library change must be backwards-compatible. Client library generators may also choose to provide this functionality in some cases but not others, as appropriate in the environment. For example, any of the following strategies would be permissible: Providing overloads iff all arguments in the signature are primitives. Providing overloads iff all arguments in the signature are required. Providing overloads only for the first of multiple signatures when providing more than one would produce a conflict. Any combination of the above. In all of these situations, the requirement that the request object is always accepted still applies. Furthermore, client library generators may choose to support this functionality for a subset of RPC types, those being: Unary Server Streaming Client Streaming Bi-directional Streaming Method Signatures An RPC with the google.api.method_signature annotation indicates that an overload with a flattened method signature is desired where supported. The string contains comma-separated arguments, in order. If a field\u0027s name contains a period (.) character, this indicates a nested field. An RPC can provide this annotation more than once to specify multiple signatures. Order matters here: In some situations, it may not be possible to generate an overload for every signature provided. In this situation, client library generators must follow a \"first match wins\" strategy (generate an overload for the first signature in the conflict set, and drop the rest). Note: A corollary to this is that it is only guaranteed to be a backwards-compatible change to append method signature annotations. Required Arguments Often, certain fields on the request message are consistently required, as described in AIP-203. While client libraries generally should not perform validation on this (that is the server\u0027s role), client libraries may distinguish required arguments in method signatures from optional ones if appropriate for the language. A field is considered required for this purpose if annotated with the google.api.field_behavior annotation value of REQUIRED: message TranslateTextRequest { // The text to translate. string q = 1 [(google.api.field_behavior) = REQUIRED]; } Note: The annotation for field behavior is attached to the field, not the method. Restrictions If an RPC lists a nested field in google.api.method_signature (for example, \"foo.bar.baz\"), none of the individual component fields may be repeated except for the last one (continuing the example, baz could be repeated but foo or bar could not be). Code generators implementing this feature must error with a descriptive error message if encountering a non-terminal repeated field as a field name. If any fields are required arguments, all required arguments are expected to appear before any optional ones. Code generators implementing this feature should error with a descriptive error message if encountering a required field after an optional one, and must do so if the resulting client library would not be valid. Compatibility Removing, reordering or altering an existing google.api.method_signature entry is a breaking change for client libraries. The associated generated method is either removed entirely or its signature is altered, both of which break user code. Changelog 2020-07-14: Added caveat for supporting some RPC types 2019-09-27: Added a Compatibility section.",
    'tags': '',
    'url': '/client-libraries/4232',
  },
{
    'title': "Automatic pagination",
    'text': "Automatic pagination Many API responses, particularly to list and search methods, are paginated (AIP-158). Users calling these methods are then required to implement their own pagination logic, which is common boilerplate. Guidance Client libraries may provide automatic resolution of pagination (meaning that it performs requests in the background on an as-needed basis). Pagination can be inferred for an RPC when all of the following conditions are met: The request message contains an int32 page_size field. The request message contains a string page_token field. The response message contains a string next_page_token field. The response message contains one non-primitive repeated field. Client library generators implementing this feature must ensure that it is a backwards-compatible change to add client-side pagination functionality where it was previously absent. Implementing pagination For the client library to implement pagination (as defined by AIP-158), it should use the next_page_token value from the response message to populate the page_token value of an otherwise-identical request message, continuing indefinitely until the next_page_token value is empty. Important: Client libraries that are implementing automatic resolution of pagination should only perform requests for future pages on an as-needed basis, and avoid greedily resolving potentially long and unnecessary result sets. Client libraries that are implementing automatic pagination must still provide access to the individual fields on the response message, in the usual fashion. Note: If the response message has more than one non-primitive repeated field, the first one (in order of appearance in the file and field number) is used. If the first field by order of appearance in the message and the first field by field number do not match, code generators that implement automatic pagination should fail with an error.",
    'tags': '',
    'url': '/client-libraries/4233',
  },
{
    'title': "Docker interface",
    'text': "Docker interface A consequence of using individual generators for API client library generation is that each generator has its own set of dependencies and requirements in order to run. This is reasonable for a user who wishes to generate many libraries for a single environment, but presents challenges for a user wishing to generate a single API for many languages or environments. Users need a way to generate libraries easily and quickly, with minimal ramp-up per language. Guidance Client library generators should ship Docker images providing the generator and exposing a common interface, so that generating the same API in multiple languages usually only requires substituting in the appropriate Docker image. Docker images for Google-authored generators will follow a consistent scheme. CLI usage The expected user command to invoke the code generator in a Docker image (from the proto import root, on a POSIX machine): $ docker run --rm --user $UID \\ --mount type=bind,source=`pwd`/a/b/c/v1/,destination=/in/a/b/c/v1/,readonly \\ --mount type=bind,source=/path/to/dest/,destination=/out/ \\ gcr.io/gapic-images/{GENERATOR} \\ [-- additional options...] Note: Even though each component of this is standard in the Docker ecosystem (other than the destination path issue, which is a result of how protoc handles imports), this is still a rather long command. We can provide a shortcut script to further simplify this, but such a script would be for convenience and not a replacement for this interface. Container composition Containers must include: A current version of protoc, the protocol buffer compiler. Common protos permitted to be used by all APIs (api-common-protos). The applicable code generator plugin, as well as any dependencies it requires. The code generator plugin itself should be added using an ADD or COPY statement from the host machine at build time and installed locally; it should not pull from a package manager. (This leads to catch-22 situations when cutting releases.) Images may include either a pre-compiled binary of the plugin, or the installed source code, depending on the needs of the applicable ecosystem. Installation of dependencies should use appropriate package managers. The common protos and the protoc compiler are supplied by an independent image (gcr.io/gapic-images/api-common-protos). Both protoc and the common protos can be retrieved from this image into a generator\u0027s image using the COPY --from syntax (see multi-stage builds). This is the preferred approach as it follows Docker conventions, and allows the protos to be versioned independently. Base images TL;DR: Each language probably wants language:x.y-alpine or language:x.y-slim. For example, ruby:2.5-alpine or python:3.7-slim. (Alpine images are smaller but idiosyncratic.) The following guidelines apply to selecting base images (sorted roughly from most important to least important): Images should generally be based off an official image for the latest stable version of the language in which the generator is implemented. Images should be able to install required system dependencies from a well-understood package manager. Images should be ultimately based off of Alpine, Debian, or Ubuntu. This is to ensure we benefit from GCR\u0027s vulnerability scanning. Images should endeavor to be as small as possible, in line with the general expectations of the Docker community: Use the smallest base image you can. Alpine-based images are great if possible, but may not always be reasonable. \"Slim\" Debian images are usually the next best (and probably significantly more feasible in many situations). Mount points protoc must read protos (representing the API to be generated) from disk, and must write the final output (the client library) to disk. Because the user has the API protos on the host machine, and will ultimately need the output to go to said host machine, Docker images should use two mount points. This creates a hole in the abstraction layer: the user must mount the appropriate locations on the host machine to the appropriate locations in the container. The expected locations in the container must be constant, and consistent between all generator container images: /in/: The location of the protos to be generated. This must be the import root. Example: If generating protos for the Language API, the protos in the Docker image must live in /in/google/cloud/language/v1/. /out/: The location to which the client library shall be written. Plugin options Some micro-generators support configuration provided via protoc plugin options. In such cases, the options must be routed from the CLI input to the protoc command. The ultimate protoc invocation could look like the following: protoc --proto_path {path/to/common/protos} --proto_path /in/ \\ --{LANG}_gapic_out /out/ \\ --{LANG}_gapic_opt \"go-gapic-package=GO_PACKAGE_VALUE\" \\ `find /in/ -name *.proto` A resulting invocation of the Docker image would be as follows: $ docker run --rm --user $UID \\ --mount type=bind,source=`pwd`/a/b/c/v1/,destination=/in/a/b/c/v1/,readonly \\ --mount type=bind,source=/path/to/dest/,destination=/out/ \\ gcr.io/gapic-images/{GENERATOR} \\ --go-gapic-package GO_PACKAGE_VALUE Thus shortcut scripts written to wrap the Docker image invocation must pass all options occurring after -- to the underlying docker run command. The internal Docker image must provide the conversion from usual shell syntax to the protoc option syntax. Client library generators that make use of plugin options must accept those options as either flags or key=value pairs. (If a generator receives a string without an = character, that is a flag, and the implied value is true.) If multiple options are provided, they are comma-separated, to conform with the protoc behavior if multiple --opt flags are specified. Additionally, generators should prefix all understood option keys with the target language for that generator (e.g. go-gapic-package, java-gapic-package), and should use kebab-case for keys (in order to match Docker, since protoc is inconsistent). Microgenerators must not error on option keys that they do not recognize, although they may issue a warning. Publishing images Images for Google-created generators should be published in gcr.io/gapic-images, a dedicated project in Google Container Registry. Images should follow the naming scheme: gcr.io/gapic-images/gapic-generator-{lang} CI should be configured to push a new Docker image to the registry when releases are made. When a release is tagged in GitHub (with a version number, such as 1.0.3), the CI service should build an image based on the code at that tag. The resulting image should be tagged with each component of the version number, as well as latest, and the resulting tags pushed the registry. (This is in addition to pushing to a package manager if appropriate, which is outside the scope of this AIP.) This means that a release tag of 1.0.3 in GitHub would result in pushing the following four tags to GCR: gcr.io/gapic-images/gapic-generator-{lang}:1 gcr.io/gapic-images/gapic-generator-{lang}:1.0 gcr.io/gapic-images/gapic-generator-{lang}:1.0.3 gcr.io/gapic-images/gapic-generator-{lang}:latest Note: These rules assumes that releases have ever-increasing version numbers; this process will need to be amended slightly if a generator needs to maintain multiple version streams simultaneously.",
    'tags': '',
    'url': '/client-libraries/4290',
  },
{
    'title': "API completeness",
    'text': "API completeness Our customers expect that they can be as productive in their Apps programs as they can be sitting at the UI. When they can not, this is surprising and disappointing. Historically, G Suite has not insisted on this kind of completeness. However, we want to move towards that goal, hence this requirement for a plan, while we only advise completeness itself. For major changes, however, the desire for completeness will be amplified. Guidance Each action that can be performed in the UI should be possible to do via a public API. For example, if there is a button in the UI to add a widget, there should be some way to add a widget using the API. This simplifies the user\u0027s understanding of the API, and makes it easier to record UI actions to be replayed via the API. The question of when the completeness ought to be achieved is not fixed. Each team must have a plan for API completeness, even if it is a simple statement, such as, \"When we are given resources to do so.\" (We would prefer more, but if that is your plan, then so be it.)",
    'tags': '',
    'url': '/apps/2712',
  },
{
    'title': "One team owns each type",
    'text': "One team owns each type This guidance supplements AIP-213. Sharing types is tempting, and it is possible. However, it is surrounded by some complicated issues. We will consider making shared types for classes that are useful across multiple Apps APIs, we just will not do it lightly. If you feel you have a case for this, please contact us at apps-api-reviewers@google.com. Guidance Each API owns its own types. If your API needs to reference another API\u0027s objects, your API must contain a reference (resource name or ID) that can be used to get the information from that other API. For example, if your API wants to reference a relevant Gmail message, you must store a Gmail message name, and the message itself will be accessed via the Gmail API, passing in that name. Your API must not contain an actual Gmail message object. For smaller types, it is also reasonable to make a copy of the class.",
    'tags': '',
    'url': '/apps/2713',
  },
{
    'title': "Documenting authorization changes",
    'text': "Documenting authorization changes Authorization is critical to manage well. Understanding an API includes understanding not only what operations do, but when one is allowed to do them. Authorization changes, either new authorization constructs or new uses of existing authorization constructs, should be easy to find in a design rather than scattered through the document in individual sections. In order to make it easy to see what (if any) authorization constructs are being modified in your design, we want to be able to find them in a single, clear place. Note: This is not talking about RPC-level permissions, like those covered by RpcSecurityPolicy, but about authorization constructs used by your API for its own purposes. Definitions There are a couple of common types of authorization construct: A role refers to an authorization construct which is granted to an identity or an identity group on a resource. The most well known examples of roles in G Suite are the commenter, reader, writer, and owner roles from Drive. A permission refers to an authorization construct which is used to check whether a particular identity can execute some operation. For example, to check whether the current user can delete a file, the application may check whether the user has the file.delete permission on the file. Permissions are most often assigned to roles, so that only roles are granted to identities or identity groups, but some systems allow permissions to be granted directly. Applications often only use each permission to authorize a single operation on a resource, but there are cases where an application may use a permission to authorize multiple different operations. Within an application, authorization checks are made using only one of these authorization constructs (typically permissions, if the application has that concept). For example, in order to determine if a user can read a document, an application would either check whether the user has a doc.read permission or has the reader role, but not both. Guidance If your design creates new authorization constructs or extends/modifies the use of any existing authorization constructs, you must have a separate section in your design document that describes this. You may additionally discuss these in any other place in your document. It is not important whether this is a top-level section or subsection. It is important that all such changes are listed together in a distinct section so they are easy to find and analyze. If the identifier of an authorization construct that is new or modified is visible to users or developers, the way that it is identified should also be in your document. Examples of this are: If access is granted using roles and a new role is being added, the way that the role is identified in the role granting RPCs should be in your document. If there is an API that allows permissions assigned to roles to be manipulated, the way that the permission is identified in the role manipulation RPCs should be in your document.",
    'tags': '',
    'url': '/apps/2715',
  },
{
    'title': "Standard terms in names",
    'text': "Standard terms in names APIs have a lot of identifier names (fields, constants, methods, ...), that often contain terms for things, such as url (getUrl(), doc_url, ...) or id (lookupId(), student_id). It is useful to have a standard set of terms for common concepts in these various names. This makes it easier for developers to understand new APIs based on previous experience. It is not (for example) that id is a better term than uid or other options, but it also is not worse, and having different choices in different APIs is confusing and unnecessary. This AIP defines terms to use for such common concepts. These terms should be used for the same concept in identifier names. This is supplemental to the API design guide, which lists standard field names and has other rules about identifiers. Guidance Absent other, more specific guidance, APIs should use the following standard terms (as opposed to alternatives) as parts of identifier names to refer to common concepts, and must not use them to refer to other things: uri for URIs/URLs (as opposed to url, link, href, etc.) id for a unique identifier, either globally unique or within a specified context index to indicate an ordinal number of an item within a collection, such as message_index on a message to say what place it occupies in a stream of message (unless there is a more specific name to use, such as if the number also is used as an ID, use id). APIs should avoid use of the term resource in fields that have resource names, as this is redundant. Any more specific guidance overrides these rules. For example, the AIP-122 rule to use name for the resource name overrides using the term id for unique identifiers. Fallback to schema.org If you are looking for standard terms for things, schema.org is a good place to look for terms that have been fairly widely vetted as being normal, customary, and/or clear. You should consult it when choosing identifier names when other strategies fail.",
    'tags': '',
    'url': '/apps/2716',
  },
{
    'title': "Patterns for generic fields",
    'text': "Patterns for generic fields Developers have several options for how to represent generic values in proto messages. There are reasons to choose one over the other. Understanding them will lead to better and more consistent APIs. Guidance APIs should follow a consistent application of oneof vs. map\u003cstring, Foo\u003e vs. Any vs. Struct. oneof A oneof is used to create a restriction on a set of optional fields, enforcing that only one of them may be set (these fields are still separate individual fields). A common pattern is to have a message that contains a single oneof collection of various message types. Such a oneof message is conceptually similar to a C union, or C++ std::variant. These should be used in most places where a generic message type is needed, in preference to other approaches. Note: Adding additional possible values to an existing oneof is a non-breaking change, but moving existing fields into or out of a oneof is breaking (it creates a backwards-incompatible change in Go protobuf stubs). map\u003cstring, Foo\u003e If a more generic structure is needed, a map of strings to objects may be used. Such a map is represented by a normal JSON object, such as {\"a\": \"foo\", \"b\": \"bar\"}. The downside to such maps is that they are limited to flat structures, and they can be difficult to work with because many string constants may be needed. Any An Any allows any message to be packed into the field. This is conceptually similar to a \"bytes\" field containing a serialized message. The advantage of an Any is that a user-defined proto message can be stored along with type information. The user must be able to know which kind of object is in the Any, which complicates the design. The disadvantage is that working with and debugging any protos is much more complicated since the code may or may not know how to deserialize the packed message. Also, the developer must contend with unexpected types of messages in the Any. Any should not be used as a request parameter. Request parameters will either be a fixed set of types, in which case a oneof should be used, or a type descriptor would need to be sent along, in which case a struct should be used, which achieves essentially the same thing with much simpler semantics. Struct The Struct message can be used to represent arbitrary nested JSON. For example, given the following code: Struct.Builder builder = Struct.newBuilder(); Value town = Value.newBuilder().setStringValue(\"Springfield\").build(); Value population = Value.newBuilder().setNumberValue(273).build(); builder.putFields(\"town\", town); builder.putFields(\"population\", population); Struct survey = builder.build(); survey would serialize as the actual JSON {\"town\": \"Springfield\": \"population\": 273}. This message type is fairly uncommon, and should only be used rarely.",
    'tags': '',
    'url': '/apps/2717',
  },
{
    'title': "References to objects in other APIs",
    'text': "References to objects in other APIs Your API may need to refer to objects in other APIs. For example, a Sheets cell may want to refer to the Slides deck that explains its meaning. This kind of cross reference should be as natural to use as possible with the target API. Guidance When your API refers to an object accessed via another API (the \"target\" API), the reference your API provides depends upon whether the reference is compliant with One Platform or not. If a field always holds a compliant reference to a single specific target API, the reference you provide must be a relative URI from the top level of the target API\u0027s naming hierarchy. For example, if the full URL of the object is https://koalas.googleapis.com/koalas/123435 the reference you return to it must be the relative URI koalas/123435. Further, your documentation must make clear that the reference is used with koalas.googleapis.com. This provides the developer with a natural way to use the reference, using the returned path directly. It also ensures that they know which API understands that reference. If a field always holds a compliant reference, but is not limited to a single target API, the reference you provide must be a relative URI that includes the path of its specific target API, such as koalas.googleapis.com/koalas/123435. This provides the developer with the correct target in a formalized, usable way. Otherwise, the reference you return must be chosen to be as natural to use as possible with the target API, and the API and its version must be documented. For example, if the Apiary-based Koala API uses an ID in its GetKoalaData method, you must return the ID that can be used as a parameter, as well as documenting that you are using IDs that work in Koala API 1.0. Naming For compliant references, you should avoid the use of the terms \"reference\" and \"name\" in the field name. That is, koala is preferred to koala_reference or koala_name (see [AIP-122](/122)). For other target APIs, you should echo that API\u0027s terminology in the name for clarity. For example, if the target API\u0027s GetKoalaDataRequest has a koala_num field, your field name should probably be koala_num, or it would include koala_num in its name, such as responsible_koala_num.",
    'tags': '',
    'url': '/apps/2718',
  },
{
    'title': "Actions on Google AIP Process",
    'text': "Actions on Google AIP Process This AIP extends AIP-1 with details specific to Actions on Google AIPs. Any details of AIP-1 not modified or contradicted by this AIP also apply to Actions on Google AIPs. Stakeholders As with any process there are many different stakeholders when it comes to reviewing and working with AIPs. Below is a summary of the escalation path starting with the API producer. digraph d_front_back { rankdir=BT; ranksep=0.3; node [ style=\"filled,solid\" shape=box fontname=\"Roboto\" ]; producer [ label=\"API Producer\" ]; editors [ label=\"AIP Editors\" ]; aog_editors [ label=\"Actions on Google AIP Editors\" ]; tl_infra [ label=\"Infrastructure TL\" ]; tl_design [ label=\"Design TL\" ]; tl [ label=\"TL\" ]; producer -\u003e aog_editors; aog_editors -\u003e editors; editors -\u003e tl_infra -\u003e tl; editors -\u003e tl_design -\u003e tl; } Actions on Google Editors The Actions on Google editors are the set of people who make decisions on Actions on Google AIPs before escalation to the general editors defined in AIP-1. The list of Actions on Google AIP editors is currently: Ali Ibrahim (@ahahibrahim) Richard Frankel (@rofrankel) Shuyang Chen (@Canain) The Actions on Google editors have the same responsibilities as the general editors. They also have the additional responsibility of establishing correctness of, and leadership support for, the contents of Actions on Google AIPs. Actions on Google AIP editorship is by invitation of the current Actions on Google editors.",
    'tags': '',
    'url': '/aog/3001',
  },
{
    'title': "Actions on Google Vertical Integration Webhook Format",
    'text': "Actions on Google Vertical Integration Webhook Format If an action is part of a vertical program that requires a webhook for Google to integrate with the action, the webhook format must follow this AIP. Guidance Custom method name Custom methods in a vertical program are defined by Google and implemented by third-party actions. Guidelines related to names of custom methods in AIP-136 should be applied. The name of the method should be a verb followed by a noun. The name must not contain prepositions (\u201cfor\u201d, \u201cwith\u201d, etc.). If word separation is required for the method name, lowerCamelCase should be used. Examples: getAccountBalance completeTransaction Base URL in Action Package The base URL configured in Action Package defines the common part of the actual execution URL of the webhook. The base URL may include a trailing slash, but must work if :customMethodName is appended directly. Google Cloud Functions base URLs without a trailing slash do not work, because the first segment of the path is used to identify the webhook. The endpoint must be HTTPS and must have a valid certificate. Examples: https://us-central1.cloudfunctions.net/myWebhook/ (not https://us-central1.cloudfunctions.net/myWebhook) https://test.com/assistant/api Actual execution URL The vertical program must compute the actual execution URL by appending baseUrl with :customMethodName. Examples: https://us-central1.cloudfunctions.net/myWebhook/:completeTransaction https://test.com/assistant/api:completeTransaction",
    'tags': '',
    'url': '/aog/3010',
  },
{
    'title': "BII Schema Principles",
    'text': "BII Schema Principles Built-in intents (BIIs) allow third party developers to declare what their Actions can do. When a developer registers an Action for a BII, Google can then invoke that action to fulfill user requests matching that built-in intent. Terminology In the general principles below, we use the following terms: Built-in intents (BII): Fulfillment schemas that are used to call compatible APIs to perform Actions in response to a user query. Built-in intents allow your service to express its fulfillment capabilities to Google. By registering for built-in intents and mapping intent parameters to the fulfillment, it becomes possible for the Google Assistant to invoke the service to perform a task in response to natural language queries. A BII comprises an operation (full list below) and a Schema.org entity, otherwise known as a type. For example, CREATE_RESERVATION would be a BII for initiating a new reservation; this intent applies to various domains such as airline, hotel, restaurant, and other reservations. Operation: An Action which acts as a wrapper around a type. Type: The object on which the operation is acting upon. General principles Each BII should be treated like an API. While BIIs are technically fulfillment schemas, they fill the same role as an API, in that they tell third party developers about the structure of the request that their Action handles. This AIP details principles for schema creation, with operation-specific and type-specific information, followed by a list of operations for BIIs. Schema creation Existing Schema.org types and properties should be reused whenever the semantics needed already exist. The formula for naming a BII must be: Operation + Type := VERB [\"Operation\" from list below] + \u0027_\u0027 + NOUN [\"Type\" from Schema.org]. Types can be compound nouns which have more than one token. Types with more than one token have tokens separated by \u0027_\u0027. Example: CREATE + \u0027_\u0027 + MONEY_TRANSFER = CREATE_MONEY_TRANSFER BII names must be in CAPITAL_SNAKE_CASE (e.g. VERB_NOUN_NOUN). For more detail, see here. Operations Operations comprise a small catalog of simple, generalizable verbs. These can be found at the bottom of the AIP under \"List of BII Operations.\" There must not be overlap between the scope covered by any operations (mutual exclusivity). Example: GET and CREATE do not overlap in scope; while both involve presenting an object, GET is for retrieving an existing object, while CREATE assumes no object yet exists and creates one. Operation + type combos should make semantic sense. If there is no operation that can work with the type chosen, either: Choose a new type that is in semantic scope for the Action to attach to an existing operation, with a semantically sensible result. Example: Say you want to fulfill a request for checking into a reservation. CREATE_CHECKIN does not seem to make the most semantic sense, since nothing is being created. Upon further thought, you decide to choose a different operation and call the BII UPDATE_RESERVATION instead, which makes more sense with the semantics of checking into a reservation. Or, Create a new operation. Take this step only when there is no operation in the list that can cover the Action requested for the schema. Example: Imagine you only had the operations START, STOP, and RESUME for controlling an ongoing activity. A fulfillment request comes in for temporarily stopping an ongoing activity of media playback but not terminating it. You try to create a BII called STOP_MEDIA, but then realize that this operation means the API must terminate the activity. You then create a new operation, PAUSE, which acts to \"temporarily stop/pause activity\", and does not overlap in scope with the existing operation, STOP. Your new BII is PAUSE_MEDIA. Types Types must be defined as Schema.org types. The type must be the object upon which the operation is carried out. Semantic scope of the type should be generalizable, specificity may be in properties. Example: Reservation is a type, which has a property named provider. The provider property specifies the service provider, service operator, or service performer. This ensures that any BII created using the type Reservation is generalizable to any service provider, and that the service provider information is still passed forward through Reservation\u2019s property provider. Different types should take distinctly different properties. BIIs must be specific enough to avoid semantic ambiguity when calling an API. That is, we shouldn\u2019t inadvertently trigger an Action that the user isn\u2019t expecting. Example: brokerage account vs. account: If we do not specify brokerage account, a GET_ACCOUNT BII could call an API that fulfills the Action for getting another sort of account\u2019s information, such as a social media account. GET_BROKERAGE_ACCOUNT ensures the correct scope of financial account is retrieved by the API. The function prototype/set of parameters should be bound to the operation. That is, the operation decides the fulfillment boundaries of the Action. Each BII operation must take a Schema.org type. In BII schemas, the same Schema.org type, when combined with different verbs, may take different properties. Example: GET_MESSAGE and CREATE_MESSAGE use a different but overlapping set of properties of Message. Handling User Queries Generic/unresolved search criteria at the level of an object should be passed through the Description field. If a query argument can be recognized as a property of a type, it should be passed through as a property; if, on the other hand, an argument is recognized as just a description of the type, it should be passed through Description field. Example: \"find funky blues songs on YouTube\" -\u003e get_media_object(description=\"funky blues\"). List of BII Operations | Verb | Definition | Example BII schema | | ------ | ------------------------------------------------------------- | ------------------ | | GET | retrieve \u0026 present an object; if ambiguous, a list of objects | GET_CALL_HISTORY | | CREATE | create an object | CREATE_ORDER | | DELETE | remove or terminate an existing object | DELETE_RESERVATION | | START | control an ongoing activity: start activity | START_GAME | | STOP | control an ongoing activity: stop activity | STOP_ALARM | | PAUSE | control an ongoing activity: temporarily stop/pause activity | PAUSE_SONG | | RESUME | control an ongoing activity: continue activity | RESUME_TIMER |",
    'tags': '',
    'url': '/aog/3020',
  },
{
    'title': "Type protos in Actions on Google APIs",
    'text': "Type protos in Actions on Google APIs Many Actions on Google fulfillment APIs need to represent typed data (datetime, money, etc.). In some cases, there are common components for representing these types. Guidance Fulfillment APIs must use the Actions on Google common types when applicable, and must not use alternative type protos. For example, an API which needs to represent a monetary amount must use google.type.Money, and must not use an alternative representation. APIs may wrap existing types in new protos. This may be useful in order to define compound types, provide additional metadata, provide semantic signals (if the typed value was obtained from a user query), etc. Actions on Google common types The Actions on Google common types include all the protobuf types and API types defined in AIP-213, as well as all the protos in google.actions.type.*. Adding new types If a given API needs a type for which there is no existing common type, and the type is not conceptually specific to that API, and the type is well understood enough to be modeled in a permanent/unversioned way, then API author should consider proposing a new Actions on Google common type in google.actions.type.*. The guidance in the appendix of AIP-213 also applies to creating new Actions on Google common types. Specifically, API authors proposing new types should consider whether a new type should be a Google-wide common type rather than an Actions on Google common type. One exception to this is that new Actions on Google common types are not proposed by opening a GitHub ticket. Instead, Actions on Google API authors who want to create a new type should email the owners of the //google/actions/type directory directly.",
    'tags': '',
    'url': '/aog/3021',
  },
{
    'title': "Built-in intent arguments and fulfillment APIs",
    'text': "Built-in intent arguments and fulfillment APIs Actions on Google\u0027s built-in intents (BIIs) are a fulfillment schema, and use Schema.org as a foreign vocabulary. BIIs are not a fulfillment API, and do not use the Actions on Google common types defined in AIP-3021. Actions on Google has two types of generic fulfillment APIs: URI-based APIs like App Actions, which can only support string arguments. Google standard APIs, which support JSON primitive types like string and the Actions on Google common types. These APIs do not support Schema.org JSON-LD objects. These APIs should support BII arguments by mapping them, or their properties, to the argument type schema they do support. For example, a BII argument of type MonetaryAmount may be mapped to an API field of type Money. BII argument paths Only certain Schema.org entity types should be mapped to a given common type. In order to support BII arguments with types that cannot be mapped to an appropriate type, APIs may support configuration via BII argument paths, strings which allow users to specify a property of a Schema.org entity which can be mapped to an appropriate type. APIs which support BII argument paths should use the syntax defined in this section. BII argument paths are dot-delimited strings that identify a specific Schema.org entity within the list of arguments to the BII. For example, take the following hypothetical BII arguments grant and date: { \"grant\": { \"@context\": \"http://schema.org\", \"@type\": \"MonetaryGrant\", \"funder\": { \"@type\": \"Organization\", \"name\": \"Google\" }, \"amount\": { \"@type\": \"MonetaryAmount\", \"currency\": \"USD\", \"value\": 100 } }, \"date\": \"2000-01-01\" } There is no common type to which MonetaryGrant can be mapped, but the grant argument contains an amount property of type MonetaryAmount, which can be mapped to Money. This property can be referenced with the path string \"grant.amount\". Similarly, grant.name can be mapped to a string field. A URI-based API which does not support Money would instead need to use the path strings \"grant.amount.currency\" and \"grant.amount.value\" to map grant.amount to two separate URI parameters. On the other hand, date can be mapped to DateTime, and so the path string \"date\" would be sufficient for either URI-based APIs or string fields in JSON APIs. Properties with multiple values Since any Schema.org property may have multiple values, values other than the first may be referenced by indexing with square brackets. For example, take this hypothetical BII argument: { \"menuItem\": { \"@context\": \"http://schema.org\", \"@type\": \"MenuItem\", \"name\": \"pizza\", \"menuAddOn\": { \"@type\": \"MenuItem\", \"name\": \"pineapple\" }, \"menuAddOn\": { \"@type\": \"MenuItem\", \"name\": \"extra cheese\" } }, \"date\": \"2000-01-01\" } In this example, the path \"menuItem.menuAddOn[1].name\" would evaluate to \"extra cheese\". When there are no square brackets, the first value is assumed; using [0] is a no-op. That is, \"menuItem.menuAddOn.name\" and \"menuItem.menuAddOn[0].name\" are equivalent, and would both evaluate to \"pineapple\". BII argument to common type mappings Google standard APIs which support BII argument mapping should support at least these type mappings from Schema.org entity type to Actions on Google common types: | Common type | Schema.org entity types | | ----------------- | ------------------------------------------------------------ | | Date | Date | | DateTime | DateTime | | TimeOfDay | Time | | Duration | Duration | | Money | MonetaryAmount | | PostalAddress | Place, PostalAddress | BII argument to JSON type mappings Google standard APIs which support BII argument mapping should support at least these type mappings from Schema.org entity type to JSON type: | JSON type | Schema.org entity types | | --------- | ------------------------- | | string | Text | | number | Number | | bool | Boolean | BII argument to string mappings URI-based fulfillment APIs like App Actions can only map BII arguments to strings (URI parameters). These APIs should support mapping at least the following Schema.org entity types to URI parameters: Text Number Boolean Date DateTime Time",
    'tags': '',
    'url': '/aog/3022',
  },
]};